{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuring-pandas\" data-toc-modified-id=\"Configuring-pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuring pandas</a></span></li><li><span><a href=\"#데이터의-조합,-연관,-재형성\" data-toc-modified-id=\"데이터의-조합,-연관,-재형성-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>데이터의 조합, 연관, 재형성</a></span></li><li><span><a href=\"#pd.concat()-:-복수-객체의-데이터-접합\" data-toc-modified-id=\"pd.concat()-:-복수-객체의-데이터-접합-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><code>pd.concat()</code> : 복수 객체의 데이터 접합</a></span><ul class=\"toc-item\"><li><span><a href=\"#Concatenating-data\" data-toc-modified-id=\"Concatenating-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Concatenating data</a></span></li><li><span><a href=\"#Series-간의-접합\" data-toc-modified-id=\"Series-간의-접합-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><code>Series</code> 간의 접합</a></span></li><li><span><a href=\"#DataFrame간의-접합\" data-toc-modified-id=\"DataFrame간의-접합-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><code>DataFrame</code>간의 접합</a></span><ul class=\"toc-item\"><li><span><a href=\"#없는-칼럼에-등장하는-NaN\" data-toc-modified-id=\"없는-칼럼에-등장하는-NaN-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>없는 칼럼에 등장하는 <code>NaN</code></a></span></li><li><span><a href=\"#(keys-=-[])-:-접합된-데이터를-구분하는-계층형-인덱스-생성\" data-toc-modified-id=\"(keys-=-[])-:-접합된-데이터를-구분하는-계층형-인덱스-생성-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span><code>(keys = [])</code> : 접합된 데이터를 구분하는 계층형 인덱스 생성</a></span></li><li><span><a href=\"#(axis-=-)-:-정렬-기준의-축의-전환\" data-toc-modified-id=\"(axis-=-)-:-정렬-기준의-축의-전환-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span><code>(axis = )</code> : 정렬 기준의 축의 전환</a></span><ul class=\"toc-item\"><li><span><a href=\"#칼럼으로-붙는-방향:-우선-로우-인덱스-레이블-기준-정렬\" data-toc-modified-id=\"칼럼으로-붙는-방향:-우선-로우-인덱스-레이블-기준-정렬-3.3.3.1\"><span class=\"toc-item-num\">3.3.3.1&nbsp;&nbsp;</span>칼럼으로 붙는 방향: 우선 로우 인덱스 레이블 기준 정렬</a></span></li></ul></li></ul></li><li><span><a href=\"#(join-=-'inner|(default)outer')조인-유형-지정\" data-toc-modified-id=\"(join-=-'inner|(default)outer')조인-유형-지정-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>(join = 'inner|(default)outer')</code>조인 유형 지정</a></span><ul class=\"toc-item\"><li><span><a href=\"#axis=1-일-때-keys-:-각-DataFrame의-레이블이-칼럼-그룹에-붙음\" data-toc-modified-id=\"axis=1-일-때-keys-:-각-DataFrame의-레이블이-칼럼-그룹에-붙음-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span><code>axis=1</code> 일 때 <code>keys</code> : 각 <code>DataFrame</code>의 레이블이 칼럼 그룹에 붙음</a></span></li></ul></li><li><span><a href=\"#.append()-:-데이터-덧붙이기\" data-toc-modified-id=\".append()-:-데이터-덧붙이기-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span><code>.append()</code> : 데이터 덧붙이기</a></span><ul class=\"toc-item\"><li><span><a href=\"#.append(ignore_index-=-True)-:-인덱스-레이블의-무시\" data-toc-modified-id=\".append(ignore_index-=-True)-:-인덱스-레이블의-무시-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span><code>.append(ignore_index = True)</code> : 인덱스 레이블의 무시</a></span></li></ul></li></ul></li><li><span><a href=\"#pd.merge(),-.join()-:-데이터-병합과-조인\" data-toc-modified-id=\"pd.merge(),-.join()-:-데이터-병합과-조인-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span><code>pd.merge()</code>, <code>.join()</code> : 데이터 병합과 조인</a></span><ul class=\"toc-item\"><li><span><a href=\"#pd.merge()-:-여러-pandas-객체로부터의-데이터-병합\" data-toc-modified-id=\"pd.merge()-:-여러-pandas-객체로부터의-데이터-병합-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><code>pd.merge()</code> : 여러 pandas 객체로부터의 데이터 병합</a></span><ul class=\"toc-item\"><li><span><a href=\"#on-=-:-키-칼럼-지정하기\" data-toc-modified-id=\"on-=-:-키-칼럼-지정하기-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span><code>on =</code> : 키 칼럼 지정하기</a></span></li><li><span><a href=\"#left|right_index-=-True-:-로우-인덱스-레이블-기준-병합\" data-toc-modified-id=\"left|right_index-=-True-:-로우-인덱스-레이블-기준-병합-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span><code>left|right_index = True</code> : 로우 인덱스 레이블 기준 병합</a></span></li><li><span><a href=\"#suffixes-=-:-유래-데이터-프레임-식별하기\" data-toc-modified-id=\"suffixes-=-:-유래-데이터-프레임-식별하기-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span><code>suffixes =</code> : 유래 데이터 프레임 식별하기</a></span></li></ul></li><li><span><a href=\"#how-=:--Specifying-the-join-semantics-of-a-merge-operation\" data-toc-modified-id=\"how-=:--Specifying-the-join-semantics-of-a-merge-operation-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span><code>how =</code>:  Specifying the join semantics of a merge operation</a></span><ul class=\"toc-item\"><li><span><a href=\"#how-=-'outer'\" data-toc-modified-id=\"how-=-'outer'-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span><code>how = 'outer'</code></a></span></li><li><span><a href=\"#how-=-'left'\" data-toc-modified-id=\"how-=-'left'-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span><code>how = 'left'</code></a></span></li><li><span><a href=\"#how-=-'right'\" data-toc-modified-id=\"how-=-'right'-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span><code>how = 'right'</code></a></span></li></ul></li><li><span><a href=\"#.join()-:-인덱스-레이블을-기준으로-병합시\" data-toc-modified-id=\".join()-:-인덱스-레이블을-기준으로-병합시-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span><code>.join()</code> : 인덱스 레이블을 기준으로 병합시</a></span><ul class=\"toc-item\"><li><span><a href=\"#.join(how-=-)\" data-toc-modified-id=\".join(how-=-)-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span><code>.join(how = )</code></a></span></li></ul></li></ul></li><li><span><a href=\"#.pivot()-:-Pivoting\" data-toc-modified-id=\".pivot()-:-Pivoting-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span><code>.pivot()</code> : Pivoting</a></span></li><li><span><a href=\"#.stack(),-.unstack()-:-스태킹과-언스태킹\" data-toc-modified-id=\".stack(),-.unstack()-:-스태킹과-언스태킹-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span><code>.stack()</code>, <code>.unstack()</code> : 스태킹과 언스태킹</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stacking-using-non-hierarchical-indexes\" data-toc-modified-id=\"Stacking-using-non-hierarchical-indexes-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Stacking using non-hierarchical indexes</a></span><ul class=\"toc-item\"><li><span><a href=\"#.stack()\" data-toc-modified-id=\".stack()-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span><code>.stack()</code></a></span></li><li><span><a href=\"#계층형-로우-인덱스-값-접근\" data-toc-modified-id=\"계층형-로우-인덱스-값-접근-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>계층형 로우 인덱스 값 접근</a></span></li></ul></li><li><span><a href=\"#Unstacking-using-hierarchical-indexes\" data-toc-modified-id=\"Unstacking-using-hierarchical-indexes-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Unstacking using hierarchical indexes</a></span><ul class=\"toc-item\"><li><span><a href=\"#.unstack()\" data-toc-modified-id=\".unstack()-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span><code>.unstack()</code></a></span></li><li><span><a href=\"#특정-레벨-언스태킹\" data-toc-modified-id=\"특정-레벨-언스태킹-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>특정 레벨 언스태킹</a></span><ul class=\"toc-item\"><li><span><a href=\"#(1)-level-사용\" data-toc-modified-id=\"(1)-level-사용-6.2.2.1\"><span class=\"toc-item-num\">6.2.2.1&nbsp;&nbsp;</span>(1) <code>level</code> 사용</a></span></li><li><span><a href=\"#(2)-인덱스-레벨-이름-리스트-사용\" data-toc-modified-id=\"(2)-인덱스-레벨-이름-리스트-사용-6.2.2.2\"><span class=\"toc-item-num\">6.2.2.2&nbsp;&nbsp;</span>(2) 인덱스 레벨 이름 리스트 사용</a></span></li></ul></li><li><span><a href=\"#언스태킹-후-스태킹\" data-toc-modified-id=\"언스태킹-후-스태킹-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>언스태킹 후 스태킹</a></span></li></ul></li><li><span><a href=\"#알아둘-점\" data-toc-modified-id=\"알아둘-점-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>알아둘 점</a></span></li></ul></li><li><span><a href=\"#.melt()-:-Melting\" data-toc-modified-id=\".melt()-:-Melting-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span><code>.melt()</code> : Melting</a></span></li><li><span><a href=\"#Performance-benefits-of-stacked-data\" data-toc-modified-id=\"Performance-benefits-of-stacked-data-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Performance benefits of stacked data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "1.22.4\n",
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# used for dates\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set some pandas options controlling output format\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 60)\n",
    "\n",
    "# bring in matplotlib for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# version check\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터의 조합, 연관, 재형성\n",
    "---\n",
    "데이터는 흔히 이름(속성/변수)으로 참조되는 관련 값들의 논리적 구조인 엔티티(entity)의 집합으로 모델링되며, 여러 로우로 조직화된 다수의 표본이나 인스턴스를 포함한다.  \n",
    "엔티티는 사람이나 사물 인터넷(IoT)에서의 센서 등 실제 세계의 개체를 대변한다. 각 특정 엔티티와 측정치는 하나의 `DataFrame`을 사용해 모델링된다.  \n",
    "\n",
    "보통은 모델 안의 엔티티들에 대한 갖가지 작업이 필요하다. 예를 들어 여러 지역의 여러 고객 엔티티를 조합해 하나의 pandas 객체로 만들어야 할 수 있다. 고객과 주문 엔티티는 배송 주소를 찾기 위해 연결될 수 있다.  \n",
    "또한 하나의 모델에 저장된 데이터를 다른 모델로 재형성시킬 필요도 있는데, 동일한 타입의 엔티티라도 소스가 다르다면 다르게 모델링돼야 하기 때문이다. \n",
    "\n",
    "11장에서는 모델 안에서의 데이터 조합, 연관, 재형성과 관련된 작업을 알아본다.  \n",
    "- 복수 객체의 데이터 접합\n",
    "- 복수 객체의 데이터 병합\n",
    "- 병합 시 조인 유형 지정\n",
    "- 인덱스와 값 사이의 pivoting\n",
    "- 데이터 stacking과 unstacking\n",
    "- 넓은 포맷과 긴 포맷 사이의 데이터 melting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pd.concat()` : 복수 객체의 데이터 접합\n",
    "---\n",
    "pandas에서 접합(concatenation)은 둘 이상의 pandas 객체로부터 가져온 데이터를 연결해 새 객체로 만드는 과정을 말한다.  \n",
    "\n",
    "`Series` 접합의 경우 단순히 두 `Series`의 값이 연결된 새 `Series`가 만들어진다.  \n",
    "\n",
    "`DataFrame` 객체의 접합은 조금 복잡한데,  \n",
    "(1) `DataFrame`의 어느 축(행, 열)을 기준으로 하든 접합할 수 있으며,  \n",
    "(2) pandas는 그 축에 따라 인덱스 레이블에 **관계형 조인 로직**을 수행한다.  \n",
    "(3) 그다음엔 나머지 축을 따라 레이블을 정렬하고 결측 값을 채운다.  \n",
    "\n",
    "접합의 경우 고려해야 할 요소가 많으므로 나누어본다. \n",
    "- 접합의 기본 의미\n",
    "- 정렬을 위한 기준 축 전환\n",
    "- 조인 유형 지정\n",
    "- 데이터 덧붙이기\n",
    "- 인덱스 레이블의 무시\n",
    "\n",
    "\n",
    "## Concatenating data\n",
    "접합의 기본 의미  \n",
    "\n",
    "접합은 pandas의 `pd.concat()`함수를 통해 가능하며, 이 함수에 접합하고자 하는 객체의 리스트를 전달하는 것이 기본적인 문법이다. \n",
    "\n",
    "## `Series` 간의 접합\n",
    "기본적으로 행 방향으로 이어붙여지게 된다.  \n",
    "**정렬 작업이 일어나지 않았으므로 인덱스 레이블이 중복된 결과를 보여준다.**  \n",
    "\n",
    "`axis = 1` 옵션으로 칼럼 방향으로 시리즈를 붙일 수 있다.  \n",
    "모든 데이터를 보존하면서 붙이기 때문에 없는 위치의 경우 `NaN`이 표시된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two Series objects to concatenate\n",
    "s1 = pd.Series(np.arange(0, 4))\n",
    "s2 = pd.Series(np.arange(5, 8))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    6\n",
       "2    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "0    5\n",
       "1    6\n",
       "2    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate them\n",
    "pd.concat([s1, s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   0    1\n",
       "0  0  5.0\n",
       "1  1  6.0\n",
       "2  2  7.0\n",
       "3  3  NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 시리즈를 축을 달리 하여 붙인다면? \n",
    "pd.concat([s1, s2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame`간의 접합\n",
    "0\\~8 수와 9\\~17 수로 이루어진 두 데이터 프레임을 콘캣해본다.  \n",
    "아무 조건 없이 하면 행 방향으로 콘캣이 이루어진다. (기본적으로 로우가 연결되며 인덱스 레이블이 중복됨)  \n",
    "\n",
    "`pd.concat(ignore_index = True)` 옵션을 사용하면 접합 후의 순서에 따라 `Int64Index` 타입의 인덱스 레이블이 새로 붙게 된다.  \n",
    "\n",
    "### 없는 칼럼에 등장하는 `NaN`\n",
    "칼럼 레이블은 두 DataFrame 객체의 칼럼 레이블이 통합되는데, 두 개 이상이 될 수 있는 모든 소스 객체에 대해 정렬 작업이 일어나기 때문이다.  \n",
    "pandas는 총합된 결과에 현재 처리하고 있는 `DataFrame`에는 없었던 칼럼이 존재할 경우에는 `NaN`값을 삽입하게 된다.  \n",
    "즉 공통의 칼럼과 그렇지 않은 칼럼이 다 존재할 때는 `NaN`이 존재하게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  0  1  2\n",
       "1  3  4  5\n",
       "2  6  7  8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two DataFrame objects to concatenate\n",
    "# using the same index labels and column names, \n",
    "# but different values\n",
    "df1 = pd.DataFrame(np.arange(9).reshape(3, 3), \n",
    "                   columns = ['a', 'b', 'c'])\n",
    "#df2 has 9 .. 18\n",
    "df2 = pd.DataFrame(np.arange(9, 18).reshape(3, 3), \n",
    "                   columns = ['a', 'b', 'c'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c\n",
       "0   9  10  11\n",
       "1  12  13  14\n",
       "2  15  16  17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c\n",
       "0   0   1   2\n",
       "1   3   4   5\n",
       "2   6   7   8\n",
       "0   9  10  11\n",
       "1  12  13  14\n",
       "2  15  16  17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the concat\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "콘캣 시 없는 서로 존재하지 않는 칼럼에 대해 `NaN`이 나타나는 결과이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  0  1  2\n",
       "1  3  4  5\n",
       "2  6  7  8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate concatenating two DataFrame objects with\n",
    "# different columns\n",
    "df1 = pd.DataFrame(np.arange(9).reshape(3, 3), \n",
    "                   columns = ['a', 'b', 'c'])\n",
    "df2 = pd.DataFrame(np.arange(9, 18).reshape(3, 3), \n",
    "                   columns = ['a', 'c', 'd'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   c   d\n",
       "0   9  10  11\n",
       "1  12  13  14\n",
       "2  15  16  17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a    b   c     d\n",
       "0   0  1.0   2   NaN\n",
       "1   3  4.0   5   NaN\n",
       "2   6  7.0   8   NaN\n",
       "0   9  NaN  10  11.0\n",
       "1  12  NaN  13  14.0\n",
       "2  15  NaN  16  17.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the concat, NaN's will be filled in for\n",
    "# the d column for df1 and b column for df2\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `(keys = [])` : 접합된 데이터를 구분하는 계층형 인덱스 생성\n",
    "접합된 데이터를 구분할 수 있게 `keys=` 파라미터를 사용하여 각 그룹에 이름을 지정할 수 있다.  \n",
    "이 파라미터는 계층형 인덱스를 생성함으로써 `DataFrame`의 `.loc`속성을 통해 각 데이터 그룹을 개별적으로 참조할 수 있게 해준다.  \n",
    "이는 나중에 결과 `DataFrame`에서 어느 데이터가 어느 소스에서 왔는지를 판별할 수 있게 하는 편리한 방법이다.  \n",
    "\n",
    "다음은 원래의 각 `DataFrame` 객체에 이름을 부여하고, 접합한 다음, df2 객체로부터 유래한 로우만 확인하는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           a    b   c     d\n",
       "first  0   0  1.0   2   NaN\n",
       "       1   3  4.0   5   NaN\n",
       "       2   6  7.0   8   NaN\n",
       "second 0   9  NaN  10  11.0\n",
       "       1  12  NaN  13  14.0\n",
       "       2  15  NaN  16  17.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat the two objects, but create an index using the\n",
    "# given keys \n",
    "df_concated = pd.concat([df1, df2], keys = ['first', 'second'])\n",
    "\n",
    "# note in the labeling of the rows in the output\n",
    "df_concated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부여했던 키를 사용하여 특정 데이터 서브셋만 조회할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c     d\n",
       "0   9 NaN  10  11.0\n",
       "1  12 NaN  13  14.0\n",
       "2  15 NaN  16  17.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can extract the data originating from\n",
    "# the first or second source DataFrame\n",
    "df_concated.loc['second']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `(axis = )` : 정렬 기준의 축의 전환\n",
    "접합 시의 정렬 기준이 되는 축을 지정할 수 있다.  \n",
    "\n",
    "#### 칼럼으로 붙는 방향: 우선 로우 인덱스 레이블 기준 정렬 \n",
    "다음은 두 `DataFrame`객체를 칼럼 축을 기준으로 접합시킴으로써 로우 인덱스에 대해 정렬이 되게 만든 예시이다.  \n",
    "이때 칼럼이 중복되어 존재하게 된다.  \n",
    "이는 먼저 각 `DataFrame`이 **로우 인덱스 레이블을 기준으로 정렬**되고, 첫 번째 `DataFrame`의 칼럼 다음에 두 번째 `DataFrame` 칼럼이 붙여졌기 때문이다.  \n",
    "따라서 중복되는 인덱스 레이블에 대해서 정렬이 일어나며 칼럼 별로 붙여지기 때문이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c   a   c   d\n",
       "0  0  1  2   9  10  11\n",
       "1  3  4  5  12  13  14\n",
       "2  6  7  8  15  16  17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat df1 and df2 along columns\n",
    "# aligns on row labels, has duplicate columns\n",
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 공통의 로우 인덱스 레이블[2]과 그렇지 않은 인덱스 레이블이 둘 다 있는 경우를 보여준다.  \n",
    "공통인 인덱스 레이블에 관해서는 모든 칼럼의 값이 존재하지만, 그렇지 않은 것에 대해서는 `NaN`이 등장하며 칼럼방향으로 붙었다.  \n",
    "\n",
    "로우 인덱스 레이블을 기준으로 정렬되므로 칼럼은 중복돼 나타났다. 원래 객체에 없던 칼럼에 대해서는 `NaN`이 등장했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   d\n",
       "2  20  21\n",
       "3  22  23\n",
       "4  24  25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a new DataFrame to merge with df1\n",
    "# this has two common row labels (2, 3) \n",
    "# common columns (a) and one disjoint column\n",
    "# in each (b in df1 and d in df2)\n",
    "df3 = pd.DataFrame(np.arange(20, 26).reshape(3, 2), \n",
    "                   columns = ['a', 'd'], \n",
    "                   index = [2, 3, 4])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a    b    c     a     d\n",
       "0  0.0  1.0  2.0   NaN   NaN\n",
       "1  3.0  4.0  5.0   NaN   NaN\n",
       "2  6.0  7.0  8.0  20.0  21.0\n",
       "3  NaN  NaN  NaN  22.0  23.0\n",
       "4  NaN  NaN  NaN  24.0  25.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat them. Alignment is along row labels\n",
    "# columns first from df1 and then df3, with duplicates.\n",
    "# NaN filled in where those columns do not exist in the source\n",
    "pd.concat([df1, df3], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `(join = 'inner|(default)outer')`조인 유형 지정 \n",
    "\n",
    "접합의 조인 유형은 기본적으로 인덱스 레이블을 따라 수행되는 외부 조인(outer join) 방식이다.  \n",
    "이는 인덱스 레이블의 **합집합**이 데이터셋에 포함되는 것과 마찬가지다.  \n",
    "\n",
    "조인 유형을 내부 조인(inner join)으로 바꾸고 싶다면 `join = 'inner'` 파라미터를 지정하면 된다.  \n",
    "내부 조인은 논리적으로 인덱스 레이블의 합집합이 아닌 **교집합**에 대해서 접합이 수행된다는 의미다.  \n",
    "\n",
    "다음은 df1과 df2를 내부 조인으로 접합했을 때이다. 같은 인덱스 레이블인 [2]에 해당하는 하나의 로우만 나타나게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c   a   d\n",
       "2  6  7  8  20  21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do an inner join instead of outer\n",
    "# results in one row\n",
    "pd.concat([df1, df3], axis = 1, join = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `axis=1` 일 때 `keys` : 각 `DataFrame`의 레이블이 칼럼 그룹에 붙음\n",
    "`axis=1`을 지정하면서 `keys` 파라미터도 함께 사용하게 되면 레이블을 칼럼 그룹에 붙이는 일이 가능하다.  \n",
    "이럴때 `.loc[:, '계층형 칼럼 이름']` 속성과 슬라이싱을 이용해 원하는 칼럼 그룹을 조회할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  df1       df2        \n",
       "    a  b  c   a   c   d\n",
       "0   0  1  2   9  10  11\n",
       "1   3  4  5  12  13  14\n",
       "2   6  7  8  15  16  17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add keys to the columns\n",
    "df = pd.concat([df1, df2], \n",
    "               axis = 1,\n",
    "               keys = ['df1', 'df2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   c   d\n",
       "0   9  10  11\n",
       "1  12  13  14\n",
       "2  15  16  17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve the data that originated from the \n",
    "# DataFrame with key 'df2'\n",
    "df.loc[:, 'df2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.append()` : 데이터 덧붙이기\n",
    "`DataFrame`(또는 `Series`)에도 데이터를 덧붙일 수 있는 `.append()`메서드가 있다.  \n",
    "이 메서드는 지정한 두 `DataFrame`을 **로우 인덱스 레이블에 따라** 덧붙인다.  \n",
    "\n",
    "이는 `pd.concat()`처럼 중복 발생과 관계 없이 인덱스 레이블을 따라 (로우 방향으로) 로우를 덧붙이며, 칼럼 레이블은 중복이 발생하지 않게 통합된다.  \n",
    "버전에 의해 추루에는 삭제가 될 예정이라고 한다. concat을 쓰자. \n",
    "\n",
    "```\n",
    "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_12663/3653760109.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1.append(df2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    a    b   c     d\n",
       "0   0  1.0   2   NaN\n",
       "1   3  4.0   5   NaN\n",
       "2   6  7.0   8   NaN\n",
       "0   9  NaN  10  11.0\n",
       "1  12  NaN  13  14.0\n",
       "2  15  NaN  16  17.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append does a concatenate along axis=0 \n",
    "# duplicate row index labels can result\n",
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.append(ignore_index = True)` : 인덱스 레이블의 무시\n",
    "\n",
    "두 `DataFrame`을 합친 결과게 인덱스를 중복시키지 않고 싶다면 `ignore_index = True` 파라미터를 사용하면 된다.  \n",
    "이는 이 파라미터를 지정하지 않은 경우와 동일한 결과를 반환하지만 `Int64Index`타입의 새 인덱스를 갖는다.  \n",
    "(데이터 접합 후 새로 정렬이 일어난다고 보면 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_12663/3225454747.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1.append(df2, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    a    b   c     d\n",
       "0   0  1.0   2   NaN\n",
       "1   3  4.0   5   NaN\n",
       "2   6  7.0   8   NaN\n",
       "3   9  NaN  10  11.0\n",
       "4  12  NaN  13  14.0\n",
       "5  15  NaN  16  17.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates in the result index by ignoring the \n",
    "# index labels in the source DataFrame objects\n",
    "df1.append(df2, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pd.merge()`, `.join()` : 데이터 병합과 조인\n",
    "---\n",
    "\n",
    "pandas는 `pd.merge()`나 `DataFrame`의 `.merge()`를 통해 데이터베이스 식의 조인을 사용하는 병합(merging)기능을 지원한다.  \n",
    "\n",
    "병합이란 두 pandas 객체 사이에 일치하는 하나 이상의 칼럼이나 로우 인덱스를 찾아 통합시키는 작업을 말한다.  \n",
    "그다음엔 관계형 데이터베이스 식의 조인 방식을 기준으로 두 객체의 데이터가 조합된 새 객체를 반환한다.  \n",
    "\n",
    "병합은 서로 다른 `DataFrame` 객체에 **동일하게 존재하는 값을 통해 양쪽 데이터를 연관 지어 하나의 `DataFrame`으로 모델링 할 수 있는 유용한 방법**이다.  \n",
    "\n",
    "## `pd.merge()` : 여러 pandas 객체로부터의 데이터 병합\n",
    "\n",
    "`pd.merge()`는 기본적으로 내부 조인을 지원한다. \n",
    "\n",
    "병합에 대한 실전 예제로 주문 데이터로부터 고객을 찾아내는 작업을 해볼 것이다\\!  \n",
    "이를 위해 다음과 같이 두 `DataFrame`을 사용한다. 하나는 고객 정보를 나타내며, 나머지 하나는 주문 정보를 나타낸다.  \n",
    "두 객체는 'CustomerID'라는 칼럼을 통해 서로 연관될 것이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID    Name             Address\n",
       "0          10    Mike    Address for Mike\n",
       "1          11  Marcia  Address for Marcia"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are our customers\n",
    "customers = {'CustomerID': [10, 11],\n",
    "             'Name': ['Mike', 'Marcia'],\n",
    "             'Address': ['Address for Mike',\n",
    "                         'Address for Marcia']}\n",
    "customers = pd.DataFrame(customers)\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID   OrderDate\n",
       "0          10  2014-12-01\n",
       "1          11  2014-12-01\n",
       "2          10  2014-12-01"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and these are the orders made by our customers\n",
    "# they are related to customers by CustomerID\n",
    "orders = {'CustomerID': [10, 11, 10],\n",
    "          'OrderDate': [date(2014, 12, 1),\n",
    "                        date(2014, 12, 1),\n",
    "                        date(2014, 12, 1)]}\n",
    "orders = pd.DataFrame(orders)\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID    Name             Address   OrderDate\n",
       "0          10    Mike    Address for Mike  2014-12-01\n",
       "1          10    Mike    Address for Mike  2014-12-01\n",
       "2          11  Marcia  Address for Marcia  2014-12-01"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge customers and orders so we can ship the items\n",
    "customers.merge(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 고객이 주문한 제품을 발송하려는데, orders 데이터와 customers 데이터를 병합해 각 주문별 수령지 주소를 찾아야 한다.  \n",
    "`.merge()` 메서드를 사용해 쉽게 할 수 있다.  \n",
    "\n",
    "pandas는 아주 간단한! 이 코드 하나로! 이와 같은 작업이 가능하도록 했다.  \n",
    "(1) 먼저 두 객체를 파악해 모두 존재하는 공통의 칼럼이 있는지 파악한다. 이 칼럼은 조인을 수행하기 위한 **키**로 취급된다. \n",
    "(2) 'CustomerID'를 알아냈으며, 이렇게 식별한 키에 해당하는 칼럼과 두 객체의 나머지 칼럼을 모두 포함하는 새 `DataFrame` 객체를 만든다.\n",
    "(3) 두 객체의 키 칼럼에 속한 값들을 일치시킨다.  \n",
    "(4) 일치된 값에 따른 각 로우를 생성시킨다.  \n",
    "(5) 두 객체로부터 일치되는 로우의 데이터를 복사해 해당 로우와 칼럼에 할당한다.  \n",
    "(6) `int64Index` 타입의 새 인덱스를 할당한다.  \n",
    "\n",
    "**키 칼럼이 여러 개일 경우에는 그 키 칼럼의 값이 모두 일치하지 않는 로우는 병합에서 제외**된다.  \n",
    "이를 확인하기 위해 다음과 같이 'key1'과 'key2' 칼럼을 모두 갖는 두 `DataFrame`을 병합한 결과를 보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1\n",
       "0    a    x      0\n",
       "1    b    y      1\n",
       "2    c    z      2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data to be used in the remainder of this section's examples\n",
    "left_data = {'key1': ['a', 'b', 'c'], \n",
    "            'key2': ['x', 'y', 'z'],\n",
    "            'lval1': [ 0, 1, 2]}\n",
    "right_data = {'key1': ['a', 'b', 'c'],\n",
    "              'key2': ['x', 'a', 'z'], \n",
    "              'rval1': [ 6, 7, 8 ]}\n",
    "left = pd.DataFrame(left_data, index = [0, 1, 2])\n",
    "right = pd.DataFrame(right_data, index = [1, 2, 3])\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  rval1\n",
       "1    a    x      6\n",
       "2    b    a      7\n",
       "3    c    z      8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0      6\n",
       "1    c    z      2      8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate merge without specifying columns to merge\n",
    "# this will implicitly merge on all common columns\n",
    "left.merge(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우 두 `DataFrame`에 공통으로 존재하는 칼럼인 key1과 key2가 식별이 되었을 것인데, 문제는 두 키 칼럼의 값이 모두 일치하는 로우는 (a, x), (c, z) 만 있으므로 그 결과에는 두 개의 로우만 포함되었다.  \n",
    "\n",
    "### `on = ` : 키 칼럼 지정하기\n",
    "값을 일치시킬 칼럼, 즉 객체 사이의 연관 칼럼을 명시적으로 지정하고 싶다면 `on = 'keyname'`파라미터를 사용하면 된다.  \n",
    "이 파라미터에 전달하는 칼럼은 병합할 객체 모두에 존재하는 칼럼이어야 한다.  \n",
    "\n",
    "서로 다른 이름의 칼럼을 기준으로 병합하고자 한다면 `left_on` 이나 `right_on` 파라미터에 해당 칼럼명을 전달해 호출하면 된다.  \n",
    "key1과 key2 로 붙였더니, left에서 key1이 a인 것과 right에서 key2가 a인 것을 기준으로 데이터를 병합한 것을 볼 수 있다!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2_x  lval1 key2_y  rval1\n",
       "0    a      x      0      x      6\n",
       "1    b      y      1      a      7\n",
       "2    c      z      2      z      8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate merge using an explicit column\n",
    "# on needs the value to be in both DataFrame objects\n",
    "left.merge(right, on = 'key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0      6\n",
       "1    c    z      2      8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge explicitly using two columns\n",
    "left.merge(right, on = ['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_x key2_x  lval1 key1_y key2_y  rval1\n",
       "0      a      x      0      b      a      7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left.merge(right, left_on = 'key1', right_on = 'key2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `left|right_index = True` : 로우 인덱스 레이블 기준 병합\n",
    "두 `DataFrame`을 **로우 인덱스 레이블을 기준으로 병합**하고자 한다면 `left_index = True`와 `right_index = True` 파라미터를 사용한다.  \n",
    "이 경우 두 파라미터를 모두 지정해야 한다.  \n",
    "\n",
    "여기서 두 `DataFrame`에 있어 공통의 인덱스 레이블은 [1], [2]이므로 그 인덱스와 해당 값을 갖는 두 개의 로우가 만들어졌다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_x key2_x  lval1 key1_y key2_y  rval1\n",
       "1      b      y      1      a      x      6\n",
       "2      c      z      2      b      a      7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join on the row indices of both matrices\n",
    "pd.merge(left, right, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `suffixes = ` : 유래 데이터 프레임 식별하기 \n",
    "두 `DataFrame`에 key로 시작하는 같은 이름의 칼럼이 존재하므로, 어느 `DataFrame`으로부터 유래했는지 식별할 수 있게 \\_x, \\_y라는 접미사가 자동으로 붙었다.  \n",
    "직접 지정하고 싶다면 `suffixes = ` 파라미터를 사용한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_df1 key2_df1  lval1 key1_df2 key2_df2  rval1\n",
       "1        b        y      1        a        x      6\n",
       "2        c        z      2        b        a      7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left, right, left_index = True, right_index = True, suffixes = ['_df1', '_df2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `how = `:  Specifying the join semantics of a merge operation\n",
    "병합의 조인 유형 지정\n",
    "\n",
    "`pd.merge()`는 기본적으로 **내부 조인을 사용**한다.  \n",
    "다른 조인 유형을 사용하고 싶다면 `pd.merge()`(또는 `DataFrame`의 `.merge()`)에 `how` 파라미터를 전달한다.  \n",
    "\n",
    "지정할 수 있는 조인 유형을 다음과 같다.  \n",
    "- `inner` : 두 `DataFrame` 객체의 동일한 키(교집합)만 사용한다. \n",
    "- `outer` : 두 `DataFrame` 객체의 모든 키(합집합)을 사용한다. \n",
    "- `left` : 왼쪽 `DataFrame`의 키만 사용한다. \n",
    "- `right` : 오른쪽 `DataFrame`의 키만 사용한다.  \n",
    "\n",
    "앞에서 봤듯이 병합의 기본 값은 내부 조인이며, 이 경우 두 `DataFrame`의 **키 칼럼 값이 일치되는 로우의 데이터만** 반환된다.  \n",
    "그에 반해 외부 조인의 경우에는 왼쪽과 오른쪽 `DataFrame`에 있어서 **일치하는 로우와 그렇지 않은 로우가 모두 병합**된다.  \n",
    "\n",
    "\n",
    "### `how = 'outer'` \n",
    "일치하는 모든 키에 대하여, b-y(left df), b-a(right df) 조합이 둘 다 나왔다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x    0.0    6.0\n",
       "1    b    y    1.0    NaN\n",
       "2    c    z    2.0    8.0\n",
       "3    b    a    NaN    7.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outer join, merges all matched data, \n",
    "# and fills unmatched items with NaN\n",
    "left.merge(right, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `how = 'left'` \n",
    "왼쪽의 키 칼럼만 기준으로 병합된다. 그래서 b-y 조합은 나왔지만 b-a 조합은 나오지 않았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0    6.0\n",
       "1    b    y      1    NaN\n",
       "2    c    z      2    8.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left join, merges all matched data, and only fills unmatched \n",
    "# items from the left dataframe with NaN filled for the \n",
    "# unmatched items in the result \n",
    "# rows with labels 0 and 2 \n",
    "# match on key1 and key2 the row with label 1 is from left\n",
    "\n",
    "left.merge(right, how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `how = 'right'`\n",
    "오른쪽 조인의 경우 오른쪽, 후자의 `DataFrame`의 키 칼럼만 기준으로 병합된다.  \n",
    "b-a 조합은 나왔으나 b-y 조합은 나오지 않았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x    0.0      6\n",
       "1    b    a    NaN      7\n",
       "2    c    z    2.0      8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# right join, merges all matched data, and only fills unmatched\n",
    "# item from the right with NaN filled for the unmatched items\n",
    "# in the result \n",
    "# rows with labels 0 and 2 match on key1 and key2\n",
    "# the row with label 1 is from right\n",
    "left.merge(right, how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.join()` : 인덱스 레이블을 기준으로 병합시\n",
    "pandas 라이브러리는 두 `DataFrame`객체의 칼럼 값이 아닌 인덱스 레이블을 사용해 조인을 수행하는 `.join()`이라는 메서드도 제공한다.  \n",
    "단! 두 `DataFrame` 객체에 **동일한 칼럼명이 존재한다면 반드시 `lsuffix`와 `rssuffix` 파라미터를 사용해 접미사를 지정해야** 한다.  \n",
    "병합의 경우와는 달리 조인에서는 자동으로 접미사를 붙여주지 않기 때문이다.  \n",
    "\n",
    "다음은 접미사 지정과 함께 두 객체의 조인을 수행하는 예다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_left key2_left  lval1 key1_right key2_right  rval1\n",
       "0         a         x      0        NaN        NaN    NaN\n",
       "1         b         y      1          a          x    6.0\n",
       "2         c         z      2          b          a    7.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join left with right (default method is outer)\n",
    "# and since these DataFrame objects have duplicate column names\n",
    "# we just specify lsuffix and rsuffix\n",
    "left.join(right, lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.join(how = )` \n",
    "`.join()`은 기본적으로 외부 조인이다. 기본 조인 유형이 내부 조인인 `.merge()` 메서드와 다르다.  \n",
    "\n",
    "조인 유형을 내부 조인으로 바꾸고자 하면 `how='inner'` 옵션을 사용한다.  \n",
    "물론 'left', 'right' 도 사용 가능하다.  \n",
    "\n",
    "아래는 이전에 `.merge()`를 이용하여 실행했던 것과 같다. \n",
    "```\n",
    "pd.merge(left, right, left_index = True, right_index = True, suffixes = ['_df1', '_df2'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_df1 key2_df1  lval1 key1_df2 key2_df2  rval1\n",
       "1        b        y      1        a        x      6\n",
       "2        c        z      2        b        a      7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join left with right with an inner join\n",
    "left.join(right, lsuffix = '_df1', rsuffix = '_df2', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.pivot()` : Pivoting\n",
    "---\n",
    "데이터 피버팅\n",
    "\n",
    "데이터는 흔히 스택 양식(stacked format)으로 저장된다. 이를 레코드 양식(record format)이라고도 하는데, 데이터베이스, `.csv` 파일, 엑셀 스프레드 시트 등에서 일반적인 방식이다.  \n",
    "스택 양식의 데이터는 종종 정규화돼 있지 못하며, 여러 칼럼에서 값이 반복되거나 또는 논리적으로 다른 테이블에 있어야 할 값이 존재하기도 한다.  \n",
    "이는 이전에 설명했던 tidy data의 개념에도 위배된다.  \n",
    "\n",
    "예제로, 가속도계의 data stream을 나타내는 데이터이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    interval axis  reading\n",
       "0          0    X      0.0\n",
       "1          0    Y      0.5\n",
       "2          0    Z      1.0\n",
       "3          1    X      0.1\n",
       "4          1    Y      0.4\n",
       "..       ...  ...      ...\n",
       "7          2    Y      0.3\n",
       "8          2    Z      0.8\n",
       "9          3    X      0.3\n",
       "10         3    Y      0.2\n",
       "11         3    Z      0.7\n",
       "\n",
       "[12 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in accelerometer data\n",
    "sensor_readings = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/accel.csv\")\n",
    "sensor_readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 구조상 이슈가 있을 수 있다. 만약 축 X나 Y 특정한 한 축의 데이터 스트림만을 보고 싶다면 어떻게 해야 할까?  \n",
    "    그렇다면 단순히 불리언선택을 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   interval axis  reading\n",
       "0         0    X      0.0\n",
       "3         1    X      0.1\n",
       "6         2    X      0.2\n",
       "9         3    X      0.3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract X-axis readings\n",
    "sensor_readings[sensor_readings['axis'] == 'X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순히 X 축 뿐만 아니라 모든 축에 대한 각각의 시간별 데이터 변화를 보고 싶다면 어떻게 해야할까.  \n",
    "각 축에 대해 불리언 선택일 개별적으로 수행할 수도 있지만, 그는 반복적인 코드가 만들어질 뿐만 아니라, `DataFrame`에 새로운 축의 값이 추가될 때마다 코드를 수정해야 하는 문제가 생긴다.  \n",
    "\n",
    "이런 경우 좀 더 나은 방법은 **각 고윳값 자체를 칼럼으로 표현하는 것**이다. `.pivot()`함수를 사용하면 그와 같은 칼럼 변환이 가능하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "axis        X    Y    Z\n",
       "interval               \n",
       "0         0.0  0.5  1.0\n",
       "1         0.1  0.4  0.9\n",
       "2         0.2  0.3  0.8\n",
       "3         0.3  0.2  0.7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot the data.  Interval becomes the index, the columns are\n",
    "# the current axes values, and use the readings as values\n",
    "sensor_readings.pivot(index='interval', \n",
    "                     columns='axis', \n",
    "                     values='reading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 axis 칼럼에 있는 모든 고윳값을 칼럼으로 보냈고, 원래의 `DataFrame`안에 있던 값을 적절한 칼럼에 채웠다.  \n",
    "이로써 새 `DataFrame`을 통해 *시간별*로 *axis*별 센서 값을 쉽게 읽을 수 있게 되었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.stack()`, `.unstack()` : 스태킹과 언스태킹\n",
    "---\n",
    "\n",
    "피벗 함수와 유사한 `.stack()`과 `.unstack()` 메서드가 있다.  \n",
    "스태킹은 칼럼 레이블과 그 값이 로우 인덱스와 값으로 회전됨을 의미한다.  \n",
    "언스태킹은 그 반대로, 로우 인덱스와 값이 칼럼 레이블과 값으로 회전됨을 의미한다.  \n",
    "\n",
    "스태킹과 언스태킹이 피버팅과 다른 점  \n",
    "- 스태킹과 언스태킹은 계층형 인덱스의 특정 수준도 회전시킬 수 있다는 점\n",
    "- 피버팅의 경우 인덱스 레벨 수가 유지되지만, 스태킹과 언스태킹은 항상 한 축의 인덱스 레벨 수를 증가시키고 다른 축의 인덱스 레벨 수는 감소시킨다.  \n",
    "\n",
    "## Stacking using non-hierarchical indexes\n",
    "비계층형 인덱스에서의 스태킹\n",
    "\n",
    "먼저 non-hierarchical index 의 `DataFrame` 객체를 사용본다.  \n",
    "무슨 문제인지 인덱스가 인덱스 순서대로 먹지 않는다... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       a\n",
       "three  1\n",
       "one    2\n",
       "two    3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple DataFrame with one column\n",
    "df = pd.DataFrame({'a': [1, 2, 3]}, index = {'one', 'two', 'three'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.stack()`\n",
    "`.stack()`을 사용하면 칼럼 인덱스가 로우 인덱스의 한 레벨로 이동된다.  \n",
    "따라서 레벨이 하나만 있었던 이 `DataFrame`은 계층형 로우 인덱스를 갖는 `Series`로 전락한다(표현 참...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "three  a    1\n",
       "one    a    2\n",
       "two    a    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push the column to another level of the index\n",
    "# the result is a Series where values are looked up through\n",
    "# a multi-index\n",
    "stacked1 = df.stack()\n",
    "stacked1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계층형 로우 인덱스 값 접근\n",
    "이제 이 `Series`에 접근하려면 각 레벨 값을 **튜플**로 전달하면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup one / a using just the index via a tuple\n",
    "stacked1[('one', 'a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`DataFrame`이 여러 개의 칼럼을 갖고 있다면 모든 칼럼 인덱스는 새 `Series` 객체의 동일한 인덱스 레벨로 이동된다.  \n",
    "마찬가지로 튜플로 값에 접근한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a  b  c\n",
       "one  1  3  5\n",
       "two  2  4  6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame with two columns\n",
    "df = pd.DataFrame({'a': [1, 2],\n",
    "                   'b': [3, 4],\n",
    "                   'c': [5, 6]}, \n",
    "                  index={'one', 'two'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one  a    1\n",
       "     b    3\n",
       "     c    5\n",
       "two  a    2\n",
       "     b    4\n",
       "     c    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push the two columns into a single level of the index\n",
    "stacked2 = df.stack()\n",
    "stacked2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup value with index of one / b\n",
    "stacked2[('one', 'a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstacking using hierarchical indexes\n",
    "계층형 인덱스에서의 언스태킹\n",
    "\n",
    "계층형 인덱스에서에서의 언스태킹을 보기 위해 위에서의 센서 데이터를 가져온다.  \n",
    "측정한 사람이 여럿이라고 가정할 때의 데이터이다. 사람에 따라 잰 데이터의 스케일이 다른 상황을 가정하기 위해 100배를 해주었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      reading\n",
       "who    interval axis         \n",
       "Mike   0        X         0.0\n",
       "                Y         0.5\n",
       "                Z         1.0\n",
       "       1        X         0.1\n",
       "                Y         0.4\n",
       "...                       ...\n",
       "Mikael 2        Y        30.0\n",
       "                Z        80.0\n",
       "       3        X        30.0\n",
       "                Y        20.0\n",
       "                Z        70.0\n",
       "\n",
       "[24 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make two copies of the sensor data, one for each user\n",
    "user1 = sensor_readings.copy()\n",
    "user2 = sensor_readings.copy()\n",
    "# add names to the two copies\n",
    "user1['who'] = 'Mike'\n",
    "user2['who'] = 'Mikael'\n",
    "# for demonstration, lets scale user2's readings\n",
    "user2['reading'] *= 100\n",
    "# and reorganize this to have a hierarchical row index\n",
    "multi_user_sensor_data = pd.concat([user1, user2]) \\\n",
    "                                    .set_index(['who', 'interval', 'axis'])\n",
    "multi_user_sensor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 구조에서 특정 사람이 측정한 데이터를 보고 싶다면 다음과 같이 인덱스를 사용하는 방법이 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               reading\n",
       "interval axis         \n",
       "0        X         0.0\n",
       "         Y         0.5\n",
       "         Z         1.0\n",
       "1        X         0.1\n",
       "         Y         0.4\n",
       "...                ...\n",
       "2        Y         0.3\n",
       "         Z         0.8\n",
       "3        X         0.3\n",
       "         Y         0.2\n",
       "         Z         0.7\n",
       "\n",
       "[12 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup user data for Mike using just the index\n",
    "multi_user_sensor_data.loc['Mike']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 interval 1에서, 모든 사람이 측정한 모든 축의 데이터를 알고 싶다면 `.xs()`를 사용하여 이렇게 구할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             reading\n",
       "who    axis         \n",
       "Mike   X         0.1\n",
       "       Y         0.4\n",
       "       Z         0.9\n",
       "Mikael X        10.0\n",
       "       Y        40.0\n",
       "       Z        90.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readings for all users and axes at interval 1\n",
    "multi_user_sensor_data.xs(1, level='interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.unstack()`\n",
    "\n",
    "언스태킹은 로우 인덱스의 **마지막 레벨**을 새 칼럼 인덱스로 이동시킴으로써 결과적으로 다중 인덱스를 갖는 칼럼을 만든다.   \n",
    "다음은 인덱스의 마지막 레벨(가장 안쪽)인 'axis'가 언스태킹되어 칼럼으로 이동된 모습을 보여준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                reading             \n",
       "axis                  X     Y      Z\n",
       "who    interval                     \n",
       "Mikael 0            0.0  50.0  100.0\n",
       "       1           10.0  40.0   90.0\n",
       "       2           20.0  30.0   80.0\n",
       "       3           30.0  20.0   70.0\n",
       "Mike   0            0.0   0.5    1.0\n",
       "       1            0.1   0.4    0.9\n",
       "       2            0.2   0.3    0.8\n",
       "       3            0.3   0.2    0.7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack the who level\n",
    "multi_user_sensor_data.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특정 레벨 언스태킹\n",
    "#### (1) `level` 사용\n",
    "특정 레벨에 대해 언스태킹하고 싶다면 `level = ` 파라미터를 사용하면 된다.  \n",
    "첫 번째 인덱스 레벨은 0으로 시작한다.  \n",
    "'who'가 첫번째 인덱스 레벨이므로 이를 언스태킹하기 위해서 다음과 같이 쓸 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              reading     \n",
       "who            Mikael Mike\n",
       "interval axis             \n",
       "0        X        0.0  0.0\n",
       "         Y       50.0  0.5\n",
       "         Z      100.0  1.0\n",
       "1        X       10.0  0.1\n",
       "         Y       40.0  0.4\n",
       "...               ...  ...\n",
       "2        Y       30.0  0.3\n",
       "         Z       80.0  0.8\n",
       "3        X       30.0  0.3\n",
       "         Y       20.0  0.2\n",
       "         Z       70.0  0.7\n",
       "\n",
       "[12 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack at level=0\n",
    "multi_user_sensor_data.unstack(level = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 인덱스 레벨 이름 리스트 사용\n",
    "`.unstack()`에 레벨 리스트를 전달함으로써 여러 레벨에 대해 동시에 언스태킹을 수행할 수 있다.  \n",
    "또한 레벨에 이름이 있는 한 레벨 포지션 대신 이름을 지정할 수 있다.  \n",
    "레벨의 제로베이스 정수를 사용할 수도 있다!\n",
    "\n",
    "'who'와 'axis' 레벨을 이름으로 지정해 언스태킹해본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         reading                              \n",
       "who         Mike           Mikael             \n",
       "axis           X    Y    Z      X     Y      Z\n",
       "interval                                      \n",
       "0            0.0  0.5  1.0    0.0  50.0  100.0\n",
       "1            0.1  0.4  0.9   10.0  40.0   90.0\n",
       "2            0.2  0.3  0.8   20.0  30.0   80.0\n",
       "3            0.3  0.2  0.7   30.0  20.0   70.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack who and axis levels\n",
    "unstacked = multi_user_sensor_data.unstack(['who', 'axis'])\n",
    "unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         reading                                        \n",
       "who         Mike                Mikael                  \n",
       "interval       0    1    2    3      0     1     2     3\n",
       "axis                                                    \n",
       "X            0.0  0.1  0.2  0.3    0.0  10.0  20.0  30.0\n",
       "Y            0.5  0.4  0.3  0.2   50.0  40.0  30.0  20.0\n",
       "Z            1.0  0.9  0.8  0.7  100.0  90.0  80.0  70.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstacked = multi_user_sensor_data.unstack([0, 1])\n",
    "unstacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 언스태킹 후 스태킹\n",
    "다시 스태킹하는 경우도 가능하다.  \n",
    "스태킹을 통해서 'unstacked' 객체에서 'who'를 다시 인덱스로 올리는 경우다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            reading                  \n",
       "interval          0     1     2     3\n",
       "axis who                             \n",
       "X    Mikael     0.0  10.0  20.0  30.0\n",
       "     Mike       0.0   0.1   0.2   0.3\n",
       "Y    Mikael    50.0  40.0  30.0  20.0\n",
       "     Mike       0.5   0.4   0.3   0.2\n",
       "Z    Mikael   100.0  90.0  80.0  70.0\n",
       "     Mike       1.0   0.9   0.8   0.7"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we can of course stack what we have unstacked\n",
    "# this re-stacks who\n",
    "unstacked.stack(level = 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 알아둘 점\n",
    "\n",
    "1. 스태킹과 언스태킹은 **항상 마지막 레벨로 이동**시킨다.  \n",
    "    앞의 예에서 원래는 가장 첫 번째(바깥) 레벨이었던 'who'레벨이 꺼냈다가 다시 넣으면서 로우 인덱스의 마지막 레벨인 점을 보면 알 수 있다.  \n",
    "    레벨의 위치가 바뀌기 때문에 이는 인덱스를 통해 데이터에 접근하는 코드에도 영향을 주게 된다.  \n",
    "    레벨을 원하는 위치로 옮기고 싶다면 스태킹과 언스태킹이 아닌 다른 수단을 사용해 인덱스를 재구성해야 한다.  \n",
    "\n",
    "2. 스태킹과 언스태킹, 피버팅으로 아무리 데이터가 이동된다 하더라도 **데이터의 유실은 일어나지 않는다.**  \n",
    "    데이터의 구조와 접근 방법만 달라지는 것 뿐이다. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.melt()` : Melting\n",
    "---\n",
    "데이터 멜팅\n",
    "\n",
    "멜팅(melting)은 언피버팅(unpivoting)의 일종이다. 보통 `DataFrame` 객체를 넓은 포맷(wide format)에서 긴 포맷(long format)으로 바꾸는 작업을 말한다.  \n",
    "다양한 통계분석에 있어서 일반적으로 통용되는 포맷이므로, 우리가 수집한 데이터가 이미 멜팅된 상태일 가능성이 높다. 그렇지 않다면 멜팅 작업을 직접 해야 할 필요가 있다.  \n",
    "\n",
    "기술적으로 멜팅은 둘 이상의 칼럼에서 레이블은 `variable` 칼럼으로, 데이터는 `value` 칼럼으로 이동(unpivoting)시킴으로써 하나의 `DataFrame`을 재형성시키는 과정이다.  \n",
    "언피버팅 대상이 아닌 나머지 칼럼들은 데이터의 설명을 도와주는 식별자 칼럼이 된다.  \n",
    "\n",
    "예시로, 두 변수의 측정치를 데이터로 갖는 `DataFrame`객체가 있다. 사람을 나타내는 이름, 키, 몸무게가 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Name  Height  Weight\n",
       "0    Mike     6.1     220\n",
       "1  Mikael     6.0     185"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will demonstrate melting with this DataFrame\n",
    "data = pd.DataFrame({'Name' : ['Mike', 'Mikael'],\n",
    "                     'Height' : [6.1, 6.0],\n",
    "                     'Weight' : [220, 185]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 `DataFrame`의 'name'을 식별자 (역할의) 칼럼으로, 키와 몸무게는 측정된 변수 칼럼으로서 멜팅하는 과정이다.  \n",
    "그 결과 이름 칼럼은 남아있으며, 키와 몸무게는 변수 역할 칼럼으로 언피버팅된다. 그 다음에 원래 두 칼럼에 있던 값이 이름과 변수 종류에 따라 조합에 맞는 value 칼럼으로 재배치된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Name variable  value\n",
       "0    Mike   Height    6.1\n",
       "1  Mikael   Height    6.0\n",
       "2    Mike   Weight  220.0\n",
       "3  Mikael   Weight  185.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melt it, use Name as the id's, \n",
    "# Height and Weight columns as the variables\n",
    "pd.melt(data, \n",
    "        id_vars = ['Name'],\n",
    "        value_vars = ['Height', 'Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 재구성되면서 variable 칼럼과 Name 칼럼의 어떤 조합으로도 쉽게 값을 추출할 수 있게 되었다.  \n",
    "게다가 새 변수와 측정치를 추가하는 일도 쉬워졌다.  \n",
    "\n",
    "새 칼럼을 만듦으로써 데이터 프레임의 구조를 변경할 필요 없이 단순히 데이터를 새 로우로 추가하면 되기 때문이다.  \n",
    "\n",
    "# Performance benefits of stacked data\n",
    "---\n",
    "스택 데이터의 성능상 이점\n",
    "\n",
    "마지막은 왜 데이터를 스태킹하는지, 즉 스택 양식의 데이터를 사용하려는 이유에 대하여 알아본다.  \n",
    "\n",
    "스택 데이터는 단일 레벨의 인덱스를 통한 검색보다 더욱 효율적인 칼럼 검색이 가능하다.  \n",
    "또한 로우와 칼럼의 위치를 지정하는 `.iloc[]` 검색에 비해서도 크게 나쁘지 않다.  \n",
    "\n",
    "스택된 데이터에서 r1, 스택되지 않은 데이터의 'one' 에서 a를 찾는 r2, 정수인덱스로 위치를 찾는 r3를 비교한다.   \n",
    "\n",
    "결과상, 특히, `DataFrame` 안에 있는 대량의 스칼라 값에 반복적으로 접근하는 경우에 있어서 극대화된 성능상의 이점을 보여준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a  b  c\n",
       "one  1  3  5\n",
       "two  2  4  6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "three  a    1\n",
       "one    a    2\n",
       "two    a    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7338453080000011, 1.1848618909999988, 0.28890419699999725)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacked scalar access can be a lot faster than\n",
    "# column access\n",
    "\n",
    "# time the different methods\n",
    "import timeit\n",
    "t = timeit.Timer(\"stacked1[('one', 'a')]\", \n",
    "                 \"from __main__ import stacked1, df\")\n",
    "r1 = timeit.timeit(lambda: stacked1.loc[('one', 'a')], \n",
    "                   number=10000)\n",
    "r2 = timeit.timeit(lambda: df.loc['one']['a'], \n",
    "                   number=10000)\n",
    "r3 = timeit.timeit(lambda: df.iloc[1, 0], \n",
    "                   number=10000)\n",
    "\n",
    "# and the results are...  Yes, it's the fastest of the three\n",
    "r1, r2, r3"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
