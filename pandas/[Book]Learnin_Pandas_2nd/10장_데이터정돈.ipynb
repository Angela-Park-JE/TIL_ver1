{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuring-pandas\" data-toc-modified-id=\"Configuring-pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuring pandas</a></span></li><li><span><a href=\"#데이터-정돈\" data-toc-modified-id=\"데이터-정돈-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>데이터 정돈</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-정돈이란\" data-toc-modified-id=\"데이터-정돈이란-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>데이터 정돈이란</a></span></li></ul></li><li><span><a href=\"#Working-with-missing-data\" data-toc-modified-id=\"Working-with-missing-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Working with missing data</a></span><ul class=\"toc-item\"><li><span><a href=\"#NaN-값-찾기-:-Determining-NaN-values-in-Series-and-DataFrame-objects\" data-toc-modified-id=\"NaN-값-찾기-:-Determining-NaN-values-in-Series-and-DataFrame-objects-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>NaN</code> 값 찾기 : Determining NaN values in Series and DataFrame objects</a></span><ul class=\"toc-item\"><li><span><a href=\"#.isnull()\" data-toc-modified-id=\".isnull()-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span><code>.isnull()</code></a></span></li><li><span><a href=\"#.count()\" data-toc-modified-id=\".count()-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span><code>.count()</code></a></span></li><li><span><a href=\"#.notnull()\" data-toc-modified-id=\".notnull()-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span><code>.notnull()</code></a></span></li></ul></li><li><span><a href=\"#Selecting-out-or-dropping-missing-data\" data-toc-modified-id=\"Selecting-out-or-dropping-missing-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Selecting out or dropping missing data</a></span><ul class=\"toc-item\"><li><span><a href=\"#.isnull(),-.notnull()-로-NaN값을-추출하는-불리언-선택\" data-toc-modified-id=\".isnull(),-.notnull()-로-NaN값을-추출하는-불리언-선택-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span><code>.isnull()</code>, <code>.notnull()</code> 로 <code>NaN</code>값을 추출하는 불리언 선택</a></span></li><li><span><a href=\"#🧪-.dropna()\" data-toc-modified-id=\"🧪-.dropna()-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>🧪 <code>.dropna()</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#.dropna(how-=-,-axis-=-)\" data-toc-modified-id=\".dropna(how-=-,-axis-=-)-3.2.2.1\"><span class=\"toc-item-num\">3.2.2.1&nbsp;&nbsp;</span><code>.dropna(how = , axis = )</code></a></span></li><li><span><a href=\"#.dropna(thresh-=-)\" data-toc-modified-id=\".dropna(thresh-=-)-3.2.2.2\"><span class=\"toc-item-num\">3.2.2.2&nbsp;&nbsp;</span><code>.dropna(thresh = )</code></a></span></li></ul></li></ul></li><li><span><a href=\"#How-pandas-handles-NaN’s-in-mathematical-operations\" data-toc-modified-id=\"How-pandas-handles-NaN’s-in-mathematical-operations-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>How pandas handles NaN’s in mathematical operations</a></span></li><li><span><a href=\"#.fillna(n)-Filling-in-missing-data-with-'n'\" data-toc-modified-id=\".fillna(n)-Filling-in-missing-data-with-'n'-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>.fillna(n)</code> Filling in missing data with 'n'</a></span></li><li><span><a href=\"#.fillna(method-=-'ffill'|'bfill'):-Forward-and-backwards-filling-of-missing-values\" data-toc-modified-id=\".fillna(method-=-'ffill'|'bfill'):-Forward-and-backwards-filling-of-missing-values-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span><code>.fillna(method = 'ffill'|'bfill')</code>: Forward and backwards filling of missing values</a></span></li><li><span><a href=\"#.fillna(fill_values)-:-Filling-using-index-labels\" data-toc-modified-id=\".fillna(fill_values)-:-Filling-using-index-labels-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>.fillna(fill_values) : Filling using index labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#🧪.fillna(.mean()-)\" data-toc-modified-id=\"🧪.fillna(.mean()-)-3.6.1\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>🧪<code>.fillna(.mean() )</code></a></span></li></ul></li><li><span><a href=\"#.interpolate()-:-Interpolation-of-missing-values\" data-toc-modified-id=\".interpolate()-:-Interpolation-of-missing-values-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span><code>.interpolate()</code> : Interpolation of missing values</a></span><ul class=\"toc-item\"><li><span><a href=\"#.interpolate(method-=-'time')\" data-toc-modified-id=\".interpolate(method-=-'time')-3.7.1\"><span class=\"toc-item-num\">3.7.1&nbsp;&nbsp;</span><code>.interpolate(method = 'time')</code></a></span></li><li><span><a href=\"#.interpolate(methd-=-'values')\" data-toc-modified-id=\".interpolate(methd-=-'values')-3.7.2\"><span class=\"toc-item-num\">3.7.2&nbsp;&nbsp;</span><code>.interpolate(methd = 'values')</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Handling-Duplicate-Data\" data-toc-modified-id=\"Handling-Duplicate-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Handling Duplicate Data</a></span></li><li><span><a href=\"#Mapping\" data-toc-modified-id=\"Mapping-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Mapping</a></span></li><li><span><a href=\"#Replacing-values\" data-toc-modified-id=\"Replacing-values-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Replacing values</a></span></li><li><span><a href=\"#Applying-functions-to-transform-data\" data-toc-modified-id=\"Applying-functions-to-transform-data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Applying functions to transform data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "1.22.4\n",
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# used for dates\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set some pandas options controlling output format\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 60)\n",
    "\n",
    "# bring in matplotlib for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import web crawling libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# version check\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정돈\n",
    "\n",
    "이제, 데이터 처리의 파이프라인에서 우리가 수집한 데이터를 들여다보고, 분석 중에 나타날 수 있는 비정상적인 부분에 대해 고심해야 할 지점에 왔다. 그런 비정상이 존재하는 원인은 다양하다. \n",
    "- 데이터의 특정 부분이 기록되지 않았거나 \n",
    "- 유실됐거나\n",
    "- 데이터의 단위가 우리 시스템의 단위와 맞지 않거나\n",
    "- 많은 경우, 특정 데이터 지점이 중복됐거나\n",
    "\n",
    "그와 같은 비정상 데이터를 다루는 과정을 데이터 정돈(data tidying)이라고 하는데, 데이터 정돈은 아무리 간단한 분석 작업이라 할지라도 그 전에 상당한 시간을 쏟아야 하는 매우 중요한 단계다.  \n",
    "\n",
    "데이터 정돈은 지루한 작업이 될 수 있다. 특히 사용하고 있는 프로그래밍 툴이 데이터 정제와 관련된 특정 작업을 지원하지 않는 경우에 더욱 그렇다. 다행히 pandas는 그런 이슈를 다룰 수 있는 다양한 도구를 제공한다. \n",
    "\n",
    "- 데이터 정돈의 개념\n",
    "- 결측 데이터 다루기\n",
    "- `NaN` 찾기\n",
    "- 결측 데이터 거르기(삭제)\n",
    "- pandas가 결측 값을 다루는 방법\n",
    "- 알 수 없는 값의 판별, 삭제, 수정\n",
    "- 보간법을 사용한 결측 값 채우기\n",
    "- 중복 데이터의 식별과 삭제\n",
    "- 매핑, 대체, 함수 적용을 통한 데이터 변형(이라기 보다 수정이 아닐까)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 정돈이란\n",
    "\n",
    "tidy data란 말은 해들리 위컴(Hadley Wickham)의 논문인 \\<Tidy Data> 에서 만들어진 용어다. 이논문은 따로 보길 추천(http://vita.had.co.nz/papers/tidy-data.pdf).  \n",
    "이 논문은 타이디 데이터를 만드는 과정을 상세히 설명한다. 타이디 데이터란 **어떤 뜻밖의 상황에도 안전하며 즉시 분석 준비가 된 완전히 정돈된 최종 데이터**를 말한다.  \n",
    "\n",
    "뜻밖의 상황, 다음과 같은 상황에 대처하기 위해서이다.  \n",
    "- 요청했던 변수와는 다른 이름의 변수가 얻어졌다.\n",
    "- 결측 데이터가 존재한다. \n",
    "- 요청했던 단위의 값이 아니다.\n",
    "- 원하는 기간의 표본이 아디ㅏ.\n",
    "- 양적 데이터가 필요하지만 변수가 범주형이다.\n",
    "- 데이터에 잡음(noise)이 존재한다. \n",
    "- 정보의 데이터 타입이 잘못돼 있다.\n",
    "- 데이터가 잘못된 축을 기준으로 조직돼 있다.\n",
    "- 데이터의 정규화 수준이 잘못 되어 있다.\n",
    "- 데이터가 중복된다. \n",
    "\n",
    "이게 전부는 아니지만, 앞으로 분명 마주칠 이슈들이다. 이런 이슈들은 이를 명시적으로 지원하지 않는 툴이나 언어를 사용할 경우에는 해결하기가 매우 곤란하다.  \n",
    "이를 어떻게 해결할 수 있는지 보도록 한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with missing data\n",
    "---\n",
    "결측 데이터 다루기\n",
    "\n",
    "pandas에서는 `NaN`(Numpy에서는 `np.nan`)의 값을 갖는 데이터를 누락된 데이터, 즉 missing 데이터라고 한다. 이 `NaN` 값은 `Series`의 특정 인덱스 레이블에 할당된 값이 없음을 의미하는데, 왜 발생하는 걸까? 원인은 다음과 같이 다양하다.  \n",
    "- 조인하는 두 데이터셋에 서로 대응되는 값이 없다.\n",
    "- 외부 소스로부터 가져온 데이터가 불완전하다.\n",
    "- 나중에 채워질 값이므로, 주어진 시점에서는 값이 없다.\n",
    "- 값을 가져오는 데 오류가 있으나, 이벤트는 계속 발생해 기록됐다.\n",
    "- 리인덱싱을 한 결과로 값이 없는 인덱스가 만들어졌다. \n",
    "- 데이터 재형성(reshape)당시에는 확인되지 않았으나, 새 칼럼이나 로우가 추가돼 데이터의 모양이 바뀌었다. \n",
    "\n",
    "이 외에도 더 많은 원인들이 있겠지만, 중요한 점은 발생할 수 밖에 없고, 데이터 분석을 위해 대처를 할 수 있어야 한다는 점이다.  \n",
    "\n",
    "예시 데이터 프레임을 만들어본다. 그리고 일부 데이터를 변경하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   c1  c2  c3\n",
       "a   0   1   2\n",
       "b   3   4   5\n",
       "c   6   7   8\n",
       "d   9  10  11\n",
       "e  12  13  14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with 5 rows and 3 columns\n",
    "df = pd.DataFrame(np.arange(0, 15).reshape(5, 3), \n",
    "                   index = ['a', 'b', 'c', 'd', 'e'], \n",
    "                   columns = ['c1', 'c2', 'c3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add some columns and rows to the DataFrame\n",
    "# 추가 : column c4 with NaN values\n",
    "df['c4'] = np.nan\n",
    "# 추가 : row 'f' with 15 through 18 \n",
    "df.loc['f'] = np.arange(15, 19) \n",
    "# 추가 : row 'g' will all NaN\n",
    "df.loc['g'] = np.nan\n",
    "# 추가 : column 'C5' with NaN's\n",
    "df['c5'] = np.nan\n",
    "# 추가변경 : change value in col 'c4' row 'a'\n",
    "df['c4']['a'] = 20\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 `DataFrame`에는 결측 데이터가 존재하며, 다음과 같은 특징을 보여준다. \n",
    "\n",
    "- 오직 `NaN`값으로만 된 로우 하나와, 칼럼 하나가 있다. \n",
    "- 숫자 값과 `NaN` 값이 혼합된 로우와 칼럼이 여러 개 있다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NaN` 값 찾기 : Determining NaN values in Series and DataFrame objects\n",
    "\n",
    "### `.isnull()`\n",
    "데이터 프레임 객체에서의 `NaN` 값 찾기 값은 `.isnull()` 메서드로 찾아낼 수 있다. 이 메서드가 `True`를 반환한 해당 위치의 아이템은 `NaN` 값이라는 뜻이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4    c5\n",
       "a  False  False  False  False  True\n",
       "b  False  False  False   True  True\n",
       "c  False  False  False   True  True\n",
       "d  False  False  False   True  True\n",
       "e  False  False  False   True  True\n",
       "f  False  False  False  False  True\n",
       "g   True   True   True   True  True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are NaN?\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결과에 `.sum()` 을 적용하면 이 `DataFrame`에 있는 `NaN`값의 총 개수를 알 수 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    1\n",
       "c2    1\n",
       "c3    1\n",
       "c4    5\n",
       "c5    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of NaN's in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total count of NaN values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 누락된 데이터를 초기에 식별하는 편리한 방법이다. 완전한 데이터가 필요한 경우, 이 방법으로 확인해 0이 아닌 값이 나온다면 좀 더 데이터를 살펴봐야 하는 상황인 것이다.  \n",
    "\n",
    "### `.count()`\n",
    "결측 데이터 개수를 확인하는 또 다른 방법으로 `Series`, `DataFrame`의 `.count()` 메서드가 있다.  \n",
    "- `Series`에서 이 메서드는 `NaN`이 **아닌 값의 개수**를 반환한다. \n",
    "- `DataFrame`에서는 각 **칼럼 별로 `NaN`이 아닌 값의 개수**를 반환한다. \n",
    "\n",
    "그 다음에는 거꾸로, 이를 전체 로우에서 뺀다음 모두 합하면 `NaN`의 개수를 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['c4'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6\n",
       "c2    6\n",
       "c3    6\n",
       "c4    2\n",
       "c5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of non-NaN values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and this counts the number of NaN's too\n",
    "(len(df) - df.count()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.notnull()`\n",
    "\n",
    "`.notnull()`메서드를 사용해도 `NaN`이 아닌 아이템을 식별할 수 있다. `.isnull()`의 반대 개념이며, 이 메서드는 반환값이 `True`일 경우 해당 값이 `NaN`이 아니라는 의미이며, `False`이면 그 반대이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4     c5\n",
       "a   True   True   True   True  False\n",
       "b   True   True   True  False  False\n",
       "c   True   True   True  False  False\n",
       "d   True   True   True  False  False\n",
       "e   True   True   True  False  False\n",
       "f   True   True   True   True  False\n",
       "g  False  False  False  False  False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are not null?\n",
    "df.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting out or dropping missing data\n",
    "결측 데이터의 판별과 삭제\n",
    "\n",
    "결측 데이터를 처리하는 한 가지 방법은 단순히 데이터셋에서 삭제 하는 것이다.  \n",
    "이는 정기적으로 표본을 수집하지만 기기가 일시적으로 오프라인이 돼 일부 데이터가 기록되지 못하는 상황에서 가능한 시나리오라고 한다.  \n",
    "\n",
    "### `.isnull()`, `.notnull()` 로 `NaN`값을 추출하는 불리언 선택\n",
    "pandas에서는 이와 관련해 다양한 기법을 사용할 수 있는데, 그 중 하나는 `.isnull()`, `.notnull()`을 사용하여 `NaN`이나 `NaN`이 아닌 값을 추출하는 일이다.  \n",
    "\n",
    "예를 들어 'c4' 칼럼에서 `NaN`이 아닌 값만 추출한다면 이렇다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the non-NaN items in column c4\n",
    "# c4에서\n",
    "df.c4[df.c4.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 `.dropna()`\n",
    "`.dropna()`는 `Series`로 부터 값이 `NaN`인 값을 삭제한다.  \n",
    "실제로는 사본을 반환하게 되므로, 원본이 변형되지 않는다.  \n",
    "옵션에 `inplace`가 있으므로 원본을 변형하고자 한다면 `inplace=True`옵션을 사용하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .dropna will also return non NaN values\n",
    "# this gets all non NaN items in column c4\n",
    "df.c4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna returns a copy with the values dropped\n",
    "# the source DataFrame / column is not changed\n",
    "df.c4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.dropna()`가 `DataFrame`에 사용될 경우에는 `NaN` 값이 최소한 하나라도 있는 로우가 모두 삭제된다.  \n",
    "임의로 만든 df는 모든 로우에 최소 하나 이상의 `NaN`값을 가지고 있으므로(c5 칼럼이 전부 `NaN`임) 그 결과 모든 로우가 삭제된 채 반환된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [c1, c2, c3, c4, c5]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on a DataFrame this will drop entire rows\n",
    "# where there is at least one NaN\n",
    "# in this case, that is all rows\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.dropna(how = , axis = )`\n",
    "모든 값이 `NaN`인 로우만 삭제하고 싶다면 `how = 'all'` 파라미터를 사용하면 된다.  \n",
    "(만약 하나라도 `NaN`인 경우를 삭제하고 싶다면 `how = 'any'` 파라미터를 사용한다.)  \n",
    "df의 인덱스가 g인 로우는 `NaN`로만 이루어져 있기 때문에 해당 로우를 삭제한다.  \n",
    "\n",
    "만약 로우가 아니라 칼럼에 적용하고자 한다면 `axis = 1` 파라미터를 전달한다.  \n",
    "그러면 c5 칼럼은 `NaN`로만 이루어져 있기 때문에 해당 칼럼을 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using how='all', only rows that have all values\n",
    "# as NaN will be dropped\n",
    "df.dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4\n",
       "a   0.0   1.0   2.0  20.0\n",
       "b   3.0   4.0   5.0   NaN\n",
       "c   6.0   7.0   8.0   NaN\n",
       "d   9.0  10.0  11.0   NaN\n",
       "e  12.0  13.0  14.0   NaN\n",
       "f  15.0  16.0  17.0  18.0\n",
       "g   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flip to drop columns instead of rows\n",
    "df.dropna(how = 'all', axis = 1) # say goodbye to c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.dropna(thresh = )`\n",
    "`.dropna()`에는 `thresh`라는 파라미터가 있다. 이 파라미터는 삭제 대상의 최소 `NaN` 값 개수를 지정한다.  \n",
    "\n",
    "예를 들어 c4, c5 칼럼처럼 5개 이상의 `NaN`값이 있는 칼럼을 모두 삭제하도록 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   0.0   NaN   0.0   NaN NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시를 만들기 위해 c1, c3칼럼의 값을 조금 변경한다. \n",
    "\n",
    "# make a copy of df\n",
    "df2 = df.copy()\n",
    "# replace two NaN cells with values\n",
    "df2.loc['g'].c1 = 0\n",
    "df2.loc['g'].c3 = 0\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비교해본다면, 하나라도 `NaN`인 칼럼을 지운 경우와, 그 아래는 5개이상 `NaN`인 칼럼만 지운 경우이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c3\n",
       "a   0.0   2.0\n",
       "b   3.0   5.0\n",
       "c   6.0   8.0\n",
       "d   9.0  11.0\n",
       "e  12.0  14.0\n",
       "f  15.0  17.0\n",
       "g   0.0   0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now drop columns with any NaN values\n",
    "df2.dropna(how = 'any', axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3\n",
       "a   0.0   1.0   2.0\n",
       "b   3.0   4.0   5.0\n",
       "c   6.0   7.0   8.0\n",
       "d   9.0  10.0  11.0\n",
       "e  12.0  13.0  14.0\n",
       "f  15.0  16.0  17.0\n",
       "g   NaN   NaN   NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only drop columns with at least 5 NaN values\n",
    "df.dropna(thresh=5, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How pandas handles NaN’s in mathematical operations\n",
    "수학 연산에서의 `NaN`  처리 방식\n",
    "\n",
    "pandas의 `NaN`처리 방식은 NumPy와 다르다.  \n",
    "예를 들어 NumPy는 `NaN`을 만나면 `NaN`을 반환하게 되어있다. 반면 pandas는 `NaN`값을 `Series`의 일부로 취급하지 않고 제외(무시)하면서 연산을 진행한다.  \n",
    "\n",
    "    pandas가 계산한 식은, (1+2+3)/3 이다. `NaN`이 무시될 뿐만 아니라 counting 에서도 제외된 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2. nan  3.]\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    NaN\n",
      "3    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create a NumPy array with one NaN value\n",
    "a = np.array([1, 2, np.nan, 3])\n",
    "# create a Series from the array\n",
    "s = pd.Series(a)\n",
    "print(a)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 2.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the mean of each is different\n",
    "a.mean(), s.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좀 더 구체적으로 살펴본다면 pandas는 다음과 같은 방식으로 `NaN` 값을 처리한다. \n",
    "- 합산에 있어서 `NaN`을 0으로 취급\n",
    "- 모든 값이 `NaN`일 경우에만 결과가 `NaN`\n",
    "- `.cumsum()`이나 `.cumprod()`와 같은 메서드는 계산 시에 `NaN` 값을 무시하지만, 그 결과 목록에는 유지시킴  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate sum, mean and cumsum handling of NaN\n",
    "# get one column\n",
    "s = df.c4\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.0,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sum(), # NaN's treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean() # NaN also treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    38.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as 0 in the cumsum, but NaN's preserved in result Series\n",
    "# 누적합에는 `NaN`이 그대로 있으면서 연산에 결과를 미치지 않는다.\n",
    "s.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전통적인 수학 기호를 사용할 경우 0으로 취급되지 않고 그대로 유지된다. 말그대로 알 수 없는 값이기 때문아닐까."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    21.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    19.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in arithmetic, a NaN value will result in NaN\n",
    "df.c4 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.fillna(n)` Filling in missing data with 'n'\n",
    "결측 데이터 보강\n",
    "\n",
    "`NaN`값을 무시하거나 유지하는 대신, 특정 값을 대체하고 싶다면 `.fillna()`메서드를 사용하면 된다.  \n",
    "`.fillna()`또한 `inplace` 옵션이 있어서, 원본은 유지한 채 복제된 것을 반환한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  0.0\n",
       "d   9.0  10.0  11.0   0.0  0.0\n",
       "e  12.0  13.0  14.0   0.0  0.0\n",
       "f  15.0  16.0  17.0  18.0  0.0\n",
       "g   0.0   0.0   0.0   0.0  0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a new DataFrame with NaN's filled with 0\n",
    "df_filled = df.fillna(0)\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 바꾸었을 경우 `NaN`은 더이상 `NaN`이 아니라 0이다. 셈이 달라지는 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1     7.5\n",
       "c2     8.5\n",
       "c3     9.5\n",
       "c4    19.0\n",
       "c5     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN's don't count as an item in calculating\n",
    "# the means\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6.428571\n",
       "c2    7.285714\n",
       "c3    8.142857\n",
       "c4    5.428571\n",
       "c5    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having replaced NaN with 0 can make\n",
    "# operations such as mean have different results\n",
    "df_filled.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.fillna(method = 'ffill'|'bfill')`: Forward and backwards filling of missing values\n",
    "결측 값 채우는 일을 `Series`안의 `NaN`이 아닌 값으로 결측 값을 채울 수 있다. (이 역시 `inplace`옵션이 제공된다.)\n",
    "\n",
    "**정방향 채우기(forward filling)**를 적용한 예시로는, 결측이 발견되기 바로 전의 값으로 채우는 것이다.  \n",
    "\n",
    "    시계열 데이터에 대한 이와 같은 기법을 흔히 '마지막 유효 값(last known value)'이라고 한다. (13장에서 다시 확인)\n",
    "\n",
    "반대로 **역방향 채우기(backward filling)**은 결측이 발견된 후 바로 나중의 값으로 채우는 것이다.  \n",
    "\n",
    "    타이핑 수를 줄이기 위해 pandas에서는 제공하는 `pd.ffill()`, `pd.bfill()`을 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    20.0\n",
       "c    20.0\n",
       "d    20.0\n",
       "e    20.0\n",
       "f    18.0\n",
       "g    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the c4 column and fill NaNs forward\n",
    "df.c4.fillna(method = \"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a backwards fill\n",
    "df.c4.fillna(method = \"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 같은 결과\n",
    "df['c4'].bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .fillna(fill_values) : Filling using index labels\n",
    "인덱스 레이블을 사용한 채우기\n",
    "\n",
    "`Series`의 레이블이나 파이썬 딕셔너리의 키를 사용해 데이터를 채울 수 있다. 이 경우 인덱스 레이블에 기초해 각 요소에 서로 다른 값을 지정할 수 있다.  \n",
    "각 인덱스를 지정한 하나의 시리즈를 통해, `NaN`인 곳에 파라미터로 주어진 해당 인덱스로 지정된 값을 채운다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100\n",
       "e    101\n",
       "g    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new Series of values to be \n",
    "# used to fill NaN's where index label matches\n",
    "fill_values = pd.Series([100, 101, 102], index = ['a', 'e', 'g'])\n",
    "fill_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a 인덱스는 `NaN`이 아니기 때문에 바뀌지 않은 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     20.0\n",
       "b      NaN\n",
       "c      NaN\n",
       "d      NaN\n",
       "e    101.0\n",
       "f     18.0\n",
       "g    102.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using c4, fill using fill_values\n",
    "# a, e and g will be filled with matching values\n",
    "df.c4.fillna(fill_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪`.fillna(.mean() )`\n",
    "흔히 사용되는 또 다른 방법은 `NaN`을 해당 칼럼의 평균 값으로 채우는 것이다.  \n",
    "\n",
    "이는 결측값을 0으로 채울 때보다 통계적으로 덜 왜곡되게 만들 수 있는 편리한 방법이다.  \n",
    "또한 통계 분석에서 0 값 때문에 너무 커진 편차로 인한 거짓 오류(false failure), 즉 실제로는 오류가 아니지만 오류로 인식될 수 있는 상황을 예방하는데 특히 유용하다.  \n",
    "\n",
    "`DataFrame`에 적용했을 경우 각각의 칼럼의 평균 값으로 채워지는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0  19.0 NaN\n",
       "c   6.0   7.0   8.0  19.0 NaN\n",
       "d   9.0  10.0  11.0  19.0 NaN\n",
       "e  12.0  13.0  14.0  19.0 NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   7.5   8.5   9.5  19.0 NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NaN values in each column with the \n",
    "# mean of the values in that column\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.interpolate()` : Interpolation of missing values\n",
    "보간법을 사용한 결측 값 채우기\n",
    "\n",
    "`DataFrame`과 `Series`에 있는 `.interpolate()` 메서드는 기본적으로 결측 값에 대해 선형 보간법을 사용한다.  \n",
    "\n",
    "보간법은 연속된 `NaN`의 앞의 값과 뒤의 값을 통해 계산된 차이 값을 차례대로 더해 `NaN`을 대체하는 방식이다.  \n",
    "\n",
    "1과 `NaN`, 2로 이루어져있을 경우 각각 같은 간격이 존재하도록 0.25씩 증가시켜 `NaN`을 채우는 예시이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.00\n",
       "1    1.25\n",
       "2    1.50\n",
       "3    1.75\n",
       "4    2.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate the NaN values from 1 through 2\n",
    "s = pd.Series([1, np.nan, np.nan, np.nan, 2])\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보간법은 중요한 기법이다. 예를 들어 낮동안 올라가는 시간별 기온을 나타내는 데이터가 있는데, 센서 고장으로 중간에 데이터가 기록되지 않았다면 보간법을 사용해 추측되는 기온으로 데이터를 채울 수 있다. 이는 0으로 채우는 것보다 훨씬 의미가 있다!  \n",
    "\n",
    "\n",
    "### `.interpolate(method = 'time')`\n",
    "`.interpolate()`메서드는 보간법의 특정 방식을 지정할 수 있는 기능을 제공한다. 흔히 사용되는 방식 중 하나는 시간에 기반을 둔 보간법이다.  \n",
    "다음 예에서, 날짜와 값으로 이루어진 `Series`가 있을 때 생각해본다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    NaN\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a time series, but missing one date in the Series\n",
    "ts = pd.Series([1, np.nan, 2], \n",
    "            index=[datetime(2014, 1, 1), \n",
    "                   datetime(2014, 2, 1),                   \n",
    "                   datetime(2014, 4, 1)])\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그대로 보간법을 사용할 경우 예상대로 그 결과는 1.5가 채워진다.  \n",
    "\n",
    "그러나 중요한 점은 2014-03-01 데이터도 누락되어있다는 사실이다. 따라서 값을 추측해야할 대상은 2014-02-01, 2014-03-01 에 대한 데이터이므로 계산식에서의 분모는 3이 됐어야 한다.  \n",
    "이때 `.interpilate(method = 'time')` 으로 지정하여 해결할 수 있다.  \n",
    "(그렇다고 하여 2014-03-01, 없는 인덱스가 생성되지는 않는다. 보간법 계산에만 관여됐을 뿐이다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    1.5\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate based on number of items in the Series\n",
    "ts.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.000000\n",
       "2014-02-01    1.344444\n",
       "2014-04-01    2.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this accounts for the fact that we don't have\n",
    "# an entry for 2014-03-01\n",
    "ts.interpolate(method= 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.interpolate(methd = 'values')`\n",
    "\n",
    "인덱스 레이블이 **숫자인 경우라면 그 인덱스 레이블에 따라 상대적으로 값이 계산되는 보간법**을 사용할 수도 있다.  \n",
    "\n",
    "예를 들어 다음과 같은 `Series`가 있을 때 선형 보간법(일반적인 보간법)을 사용한다면 50이 채워질 것이다.  \n",
    "그러나 인덱스 값에 따라 상대적으로 값을 부여하고 싶다면 `method = 'values'`를 지정하면 된다.  \n",
    "인덱스 레이블에 따라 상대적인 위치에 맞게 값이 계산되는데, 인덱스 레이블은 0에서 10 사이에 1/10 위치이므로 0 + (100-0)/10 으로 계산되어 그 값이 10이 할당 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       NaN\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a Series to demonstrate index label based interpolation\n",
    "s = pd.Series([0, np.nan, 100], index=[0, 1, 10])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      50.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      10.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate based upon the values in the index\n",
    "s.interpolate(method = 'values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "360px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
