{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuring-pandas\" data-toc-modified-id=\"Configuring-pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuring pandas</a></span></li><li><span><a href=\"#데이터-정돈\" data-toc-modified-id=\"데이터-정돈-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>데이터 정돈</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-정돈이란\" data-toc-modified-id=\"데이터-정돈이란-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>데이터 정돈이란</a></span></li></ul></li><li><span><a href=\"#Working-with-missing-data\" data-toc-modified-id=\"Working-with-missing-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Working with missing data</a></span><ul class=\"toc-item\"><li><span><a href=\"#NaN-값-찾기-:-Determining-NaN-values-in-Series-and-DataFrame-objects\" data-toc-modified-id=\"NaN-값-찾기-:-Determining-NaN-values-in-Series-and-DataFrame-objects-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>NaN</code> 값 찾기 : Determining NaN values in Series and DataFrame objects</a></span><ul class=\"toc-item\"><li><span><a href=\"#.isnull()\" data-toc-modified-id=\".isnull()-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span><code>.isnull()</code></a></span></li><li><span><a href=\"#.count()\" data-toc-modified-id=\".count()-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span><code>.count()</code></a></span></li><li><span><a href=\"#.notnull()\" data-toc-modified-id=\".notnull()-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span><code>.notnull()</code></a></span></li></ul></li><li><span><a href=\"#Selecting-out-or-dropping-missing-data\" data-toc-modified-id=\"Selecting-out-or-dropping-missing-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Selecting out or dropping missing data</a></span><ul class=\"toc-item\"><li><span><a href=\"#.isnull(),-.notnull()-로-NaN값을-추출하는-불리언-선택\" data-toc-modified-id=\".isnull(),-.notnull()-로-NaN값을-추출하는-불리언-선택-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span><code>.isnull()</code>, <code>.notnull()</code> 로 <code>NaN</code>값을 추출하는 불리언 선택</a></span></li><li><span><a href=\"#🧪-.dropna()\" data-toc-modified-id=\"🧪-.dropna()-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>🧪 <code>.dropna()</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#.dropna(how-=-,-axis-=-)\" data-toc-modified-id=\".dropna(how-=-,-axis-=-)-3.2.2.1\"><span class=\"toc-item-num\">3.2.2.1&nbsp;&nbsp;</span><code>.dropna(how = , axis = )</code></a></span></li><li><span><a href=\"#.dropna(thresh-=-)\" data-toc-modified-id=\".dropna(thresh-=-)-3.2.2.2\"><span class=\"toc-item-num\">3.2.2.2&nbsp;&nbsp;</span><code>.dropna(thresh = )</code></a></span></li></ul></li></ul></li><li><span><a href=\"#How-pandas-handles-NaN’s-in-mathematical-operations\" data-toc-modified-id=\"How-pandas-handles-NaN’s-in-mathematical-operations-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>How pandas handles NaN’s in mathematical operations</a></span></li><li><span><a href=\"#.fillna(n)-Filling-in-missing-data-with-'n'\" data-toc-modified-id=\".fillna(n)-Filling-in-missing-data-with-'n'-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>.fillna(n)</code> Filling in missing data with 'n'</a></span></li><li><span><a href=\"#.fillna(method-=-'ffill'|'bfill'):-Forward-and-backwards-filling-of-missing-values\" data-toc-modified-id=\".fillna(method-=-'ffill'|'bfill'):-Forward-and-backwards-filling-of-missing-values-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span><code>.fillna(method = 'ffill'|'bfill')</code>: Forward and backwards filling of missing values</a></span></li><li><span><a href=\"#.fillna(fill_values)-:-Filling-using-index-labels\" data-toc-modified-id=\".fillna(fill_values)-:-Filling-using-index-labels-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>.fillna(fill_values) : Filling using index labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#🧪.fillna(.mean()-)\" data-toc-modified-id=\"🧪.fillna(.mean()-)-3.6.1\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>🧪<code>.fillna(.mean() )</code></a></span></li></ul></li><li><span><a href=\"#.interpolate()-:-Interpolation-of-missing-values\" data-toc-modified-id=\".interpolate()-:-Interpolation-of-missing-values-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span><code>.interpolate()</code> : Interpolation of missing values</a></span><ul class=\"toc-item\"><li><span><a href=\"#.interpolate(method-=-'time')\" data-toc-modified-id=\".interpolate(method-=-'time')-3.7.1\"><span class=\"toc-item-num\">3.7.1&nbsp;&nbsp;</span><code>.interpolate(method = 'time')</code></a></span></li><li><span><a href=\"#.interpolate(methd-=-'values')\" data-toc-modified-id=\".interpolate(methd-=-'values')-3.7.2\"><span class=\"toc-item-num\">3.7.2&nbsp;&nbsp;</span><code>.interpolate(methd = 'values')</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Handling-Duplicate-Data\" data-toc-modified-id=\"Handling-Duplicate-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Handling Duplicate Data</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#.duplicate()-:-중복-데이터-찾기\" data-toc-modified-id=\".duplicate()-:-중복-데이터-찾기-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span><code>.duplicate()</code> : 중복 데이터 찾기</a></span></li><li><span><a href=\"#.drop_duplicates()-:-중복-로우-삭제하기\" data-toc-modified-id=\".drop_duplicates()-:-중복-로우-삭제하기-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span><code>.drop_duplicates()</code> : 중복 로우 삭제하기</a></span></li><li><span><a href=\"#중복-데이터-삭제-방식-선택하기\" data-toc-modified-id=\"중복-데이터-삭제-방식-선택하기-4.0.3\"><span class=\"toc-item-num\">4.0.3&nbsp;&nbsp;</span>중복 데이터 삭제 방식 선택하기</a></span></li></ul></li></ul></li><li><span><a href=\"#데이터-변형\" data-toc-modified-id=\"데이터-변형-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>데이터 변형</a></span><ul class=\"toc-item\"><li><span><a href=\"#.map()-:-Mapping\" data-toc-modified-id=\".map()-:-Mapping-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><code>.map()</code> : Mapping</a></span></li><li><span><a href=\"#.replace()-:-Replacing-values\" data-toc-modified-id=\".replace()-:-Replacing-values-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span><code>.replace()</code> : Replacing values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series에서-개별-값-하나를-다른-값으로-대체\" data-toc-modified-id=\"Series에서-개별-값-하나를-다른-값으로-대체-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span><code>Series</code>에서 개별 값 하나를 다른 값으로 대체</a></span></li><li><span><a href=\"#리스트를-활용하여-여러-값을-여러-다른-값으로-대체\" data-toc-modified-id=\"리스트를-활용하여-여러-값을-여러-다른-값으로-대체-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>리스트를 활용하여 여러 값을 여러 다른 값으로 대체</a></span></li><li><span><a href=\"#딕셔너리를-활용하여-여러-값을-여러-다른-값으로-대체\" data-toc-modified-id=\"딕셔너리를-활용하여-여러-값을-여러-다른-값으로-대체-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>딕셔너리를 활용하여 여러 값을 여러 다른 값으로 대체</a></span></li><li><span><a href=\"#DataFrame에서의-특정-값-변경\" data-toc-modified-id=\"DataFrame에서의-특정-값-변경-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;</span><code>DataFrame</code>에서의 특정 값 변경</a></span></li><li><span><a href=\"#method-=-파라미터-:-인덱스-포지션으로-다른-값-채우기\" data-toc-modified-id=\"method-=-파라미터-:-인덱스-포지션으로-다른-값-채우기-5.2.5\"><span class=\"toc-item-num\">5.2.5&nbsp;&nbsp;</span><code>method =</code> 파라미터 : 인덱스 포지션으로 다른 값 채우기</a></span></li><li><span><a href=\"#추가:-만약-조건으로-바꾸고자-한다면\" data-toc-modified-id=\"추가:-만약-조건으로-바꾸고자-한다면-5.2.6\"><span class=\"toc-item-num\">5.2.6&nbsp;&nbsp;</span>추가: 만약 조건으로 바꾸고자 한다면</a></span></li></ul></li></ul></li><li><span><a href=\"#.apply(lambda-)-:-Applying-functions-to-transform-data\" data-toc-modified-id=\".apply(lambda-)-:-Applying-functions-to-transform-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span><code>.apply(lambda )</code> : Applying functions to transform data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series에-람다-함수-적용\" data-toc-modified-id=\"Series에-람다-함수-적용-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span><code>Series</code>에 람다 함수 적용</a></span></li><li><span><a href=\"#DataFrame에-람다-함수-적용\" data-toc-modified-id=\"DataFrame에-람다-함수-적용-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span><code>DataFrame</code>에 람다 함수 적용</a></span></li><li><span><a href=\"#.applymap()-:-모든-개별-값에-함수-적용\" data-toc-modified-id=\".applymap()-:-모든-개별-값에-함수-적용-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span><code>.applymap()</code> : 모든 개별 값에 함수 적용</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "1.22.4\n",
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# used for dates\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set some pandas options controlling output format\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 60)\n",
    "\n",
    "# bring in matplotlib for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import web crawling libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# version check\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정돈\n",
    "\n",
    "이제, 데이터 처리의 파이프라인에서 우리가 수집한 데이터를 들여다보고, 분석 중에 나타날 수 있는 비정상적인 부분에 대해 고심해야 할 지점에 왔다. 그런 비정상이 존재하는 원인은 다양하다. \n",
    "- 데이터의 특정 부분이 기록되지 않았거나 \n",
    "- 유실됐거나\n",
    "- 데이터의 단위가 우리 시스템의 단위와 맞지 않거나\n",
    "- 많은 경우, 특정 데이터 지점이 중복됐거나\n",
    "\n",
    "그와 같은 비정상 데이터를 다루는 과정을 데이터 정돈(data tidying)이라고 하는데, 데이터 정돈은 아무리 간단한 분석 작업이라 할지라도 그 전에 상당한 시간을 쏟아야 하는 매우 중요한 단계다.  \n",
    "\n",
    "데이터 정돈은 지루한 작업이 될 수 있다. 특히 사용하고 있는 프로그래밍 툴이 데이터 정제와 관련된 특정 작업을 지원하지 않는 경우에 더욱 그렇다. 다행히 pandas는 그런 이슈를 다룰 수 있는 다양한 도구를 제공한다. \n",
    "\n",
    "- 데이터 정돈의 개념\n",
    "- 결측 데이터 다루기\n",
    "- `NaN` 찾기\n",
    "- 결측 데이터 거르기(삭제)\n",
    "- pandas가 결측 값을 다루는 방법\n",
    "- 알 수 없는 값의 판별, 삭제, 수정\n",
    "- 보간법을 사용한 결측 값 채우기\n",
    "- 중복 데이터의 식별과 삭제\n",
    "- 매핑, 대체, 함수 적용을 통한 데이터 변형(이라기 보다 수정이 아닐까)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 정돈이란\n",
    "\n",
    "tidy data란 말은 해들리 위컴(Hadley Wickham)의 논문인 \\<Tidy Data> 에서 만들어진 용어다. 이논문은 따로 보길 추천(http://vita.had.co.nz/papers/tidy-data.pdf).  \n",
    "이 논문은 타이디 데이터를 만드는 과정을 상세히 설명한다. 타이디 데이터란 **어떤 뜻밖의 상황에도 안전하며 즉시 분석 준비가 된 완전히 정돈된 최종 데이터**를 말한다.  \n",
    "\n",
    "뜻밖의 상황, 다음과 같은 상황에 대처하기 위해서이다.  \n",
    "- 요청했던 변수와는 다른 이름의 변수가 얻어졌다.\n",
    "- 결측 데이터가 존재한다. \n",
    "- 요청했던 단위의 값이 아니다.\n",
    "- 원하는 기간의 표본이 아디ㅏ.\n",
    "- 양적 데이터가 필요하지만 변수가 범주형이다.\n",
    "- 데이터에 잡음(noise)이 존재한다. \n",
    "- 정보의 데이터 타입이 잘못돼 있다.\n",
    "- 데이터가 잘못된 축을 기준으로 조직돼 있다.\n",
    "- 데이터의 정규화 수준이 잘못 되어 있다.\n",
    "- 데이터가 중복된다. \n",
    "\n",
    "이게 전부는 아니지만, 앞으로 분명 마주칠 이슈들이다. 이런 이슈들은 이를 명시적으로 지원하지 않는 툴이나 언어를 사용할 경우에는 해결하기가 매우 곤란하다.  \n",
    "이를 어떻게 해결할 수 있는지 보도록 한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with missing data\n",
    "---\n",
    "결측 데이터 다루기\n",
    "\n",
    "pandas에서는 `NaN`(Numpy에서는 `np.nan`)의 값을 갖는 데이터를 누락된 데이터, 즉 missing 데이터라고 한다. 이 `NaN` 값은 `Series`의 특정 인덱스 레이블에 할당된 값이 없음을 의미하는데, 왜 발생하는 걸까? 원인은 다음과 같이 다양하다.  \n",
    "- 조인하는 두 데이터셋에 서로 대응되는 값이 없다.\n",
    "- 외부 소스로부터 가져온 데이터가 불완전하다.\n",
    "- 나중에 채워질 값이므로, 주어진 시점에서는 값이 없다.\n",
    "- 값을 가져오는 데 오류가 있으나, 이벤트는 계속 발생해 기록됐다.\n",
    "- 리인덱싱을 한 결과로 값이 없는 인덱스가 만들어졌다. \n",
    "- 데이터 재형성(reshape)당시에는 확인되지 않았으나, 새 칼럼이나 로우가 추가돼 데이터의 모양이 바뀌었다. \n",
    "\n",
    "이 외에도 더 많은 원인들이 있겠지만, 중요한 점은 발생할 수 밖에 없고, 데이터 분석을 위해 대처를 할 수 있어야 한다는 점이다.  \n",
    "\n",
    "예시 데이터 프레임을 만들어본다. 그리고 일부 데이터를 변경하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   c1  c2  c3\n",
       "a   0   1   2\n",
       "b   3   4   5\n",
       "c   6   7   8\n",
       "d   9  10  11\n",
       "e  12  13  14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with 5 rows and 3 columns\n",
    "df = pd.DataFrame(np.arange(0, 15).reshape(5, 3), \n",
    "                   index = ['a', 'b', 'c', 'd', 'e'], \n",
    "                   columns = ['c1', 'c2', 'c3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add some columns and rows to the DataFrame\n",
    "# 추가 : column c4 with NaN values\n",
    "df['c4'] = np.nan\n",
    "# 추가 : row 'f' with 15 through 18 \n",
    "df.loc['f'] = np.arange(15, 19) \n",
    "# 추가 : row 'g' will all NaN\n",
    "df.loc['g'] = np.nan\n",
    "# 추가 : column 'C5' with NaN's\n",
    "df['c5'] = np.nan\n",
    "# 추가변경 : change value in col 'c4' row 'a'\n",
    "df['c4']['a'] = 20\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 `DataFrame`에는 결측 데이터가 존재하며, 다음과 같은 특징을 보여준다. \n",
    "\n",
    "- 오직 `NaN`값으로만 된 로우 하나와, 칼럼 하나가 있다. \n",
    "- 숫자 값과 `NaN` 값이 혼합된 로우와 칼럼이 여러 개 있다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NaN` 값 찾기 : Determining NaN values in Series and DataFrame objects\n",
    "\n",
    "### `.isnull()`\n",
    "데이터 프레임 객체에서의 `NaN` 값 찾기 값은 `.isnull()` 메서드로 찾아낼 수 있다. 이 메서드가 `True`를 반환한 해당 위치의 아이템은 `NaN` 값이라는 뜻이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4    c5\n",
       "a  False  False  False  False  True\n",
       "b  False  False  False   True  True\n",
       "c  False  False  False   True  True\n",
       "d  False  False  False   True  True\n",
       "e  False  False  False   True  True\n",
       "f  False  False  False  False  True\n",
       "g   True   True   True   True  True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are NaN?\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결과에 `.sum()` 을 적용하면 이 `DataFrame`에 있는 `NaN`값의 총 개수를 알 수 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    1\n",
       "c2    1\n",
       "c3    1\n",
       "c4    5\n",
       "c5    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of NaN's in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total count of NaN values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 누락된 데이터를 초기에 식별하는 편리한 방법이다. 완전한 데이터가 필요한 경우, 이 방법으로 확인해 0이 아닌 값이 나온다면 좀 더 데이터를 살펴봐야 하는 상황인 것이다.  \n",
    "\n",
    "### `.count()`\n",
    "결측 데이터 개수를 확인하는 또 다른 방법으로 `Series`, `DataFrame`의 `.count()` 메서드가 있다.  \n",
    "- `Series`에서 이 메서드는 `NaN`이 **아닌 값의 개수**를 반환한다. \n",
    "- `DataFrame`에서는 각 **칼럼 별로 `NaN`이 아닌 값의 개수**를 반환한다. \n",
    "\n",
    "그 다음에는 거꾸로, 이를 전체 로우에서 뺀다음 모두 합하면 `NaN`의 개수를 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['c4'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6\n",
       "c2    6\n",
       "c3    6\n",
       "c4    2\n",
       "c5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of non-NaN values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and this counts the number of NaN's too\n",
    "(len(df) - df.count()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.notnull()`\n",
    "\n",
    "`.notnull()`메서드를 사용해도 `NaN`이 아닌 아이템을 식별할 수 있다. `.isnull()`의 반대 개념이며, 이 메서드는 반환값이 `True`일 경우 해당 값이 `NaN`이 아니라는 의미이며, `False`이면 그 반대이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4     c5\n",
       "a   True   True   True   True  False\n",
       "b   True   True   True  False  False\n",
       "c   True   True   True  False  False\n",
       "d   True   True   True  False  False\n",
       "e   True   True   True  False  False\n",
       "f   True   True   True   True  False\n",
       "g  False  False  False  False  False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are not null?\n",
    "df.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting out or dropping missing data\n",
    "결측 데이터의 판별과 삭제\n",
    "\n",
    "결측 데이터를 처리하는 한 가지 방법은 단순히 데이터셋에서 삭제 하는 것이다.  \n",
    "이는 정기적으로 표본을 수집하지만 기기가 일시적으로 오프라인이 돼 일부 데이터가 기록되지 못하는 상황에서 가능한 시나리오라고 한다.  \n",
    "\n",
    "### `.isnull()`, `.notnull()` 로 `NaN`값을 추출하는 불리언 선택\n",
    "pandas에서는 이와 관련해 다양한 기법을 사용할 수 있는데, 그 중 하나는 `.isnull()`, `.notnull()`을 사용하여 `NaN`이나 `NaN`이 아닌 값을 추출하는 일이다.  \n",
    "\n",
    "예를 들어 'c4' 칼럼에서 `NaN`이 아닌 값만 추출한다면 이렇다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the non-NaN items in column c4\n",
    "# c4에서\n",
    "df.c4[df.c4.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 `.dropna()`\n",
    "`.dropna()`는 `Series`로 부터 값이 `NaN`인 값을 삭제한다.  \n",
    "실제로는 사본을 반환하게 되므로, 원본이 변형되지 않는다.  \n",
    "옵션에 `inplace`가 있으므로 원본을 변형하고자 한다면 `inplace=True`옵션을 사용하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .dropna will also return non NaN values\n",
    "# this gets all non NaN items in column c4\n",
    "df.c4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna returns a copy with the values dropped\n",
    "# the source DataFrame / column is not changed\n",
    "df.c4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.dropna()`가 `DataFrame`에 사용될 경우에는 `NaN` 값이 최소한 하나라도 있는 로우가 모두 삭제된다.  \n",
    "임의로 만든 df는 모든 로우에 최소 하나 이상의 `NaN`값을 가지고 있으므로(c5 칼럼이 전부 `NaN`임) 그 결과 모든 로우가 삭제된 채 반환된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [c1, c2, c3, c4, c5]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on a DataFrame this will drop entire rows\n",
    "# where there is at least one NaN\n",
    "# in this case, that is all rows\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.dropna(how = , axis = )`\n",
    "모든 값이 `NaN`인 로우만 삭제하고 싶다면 `how = 'all'` 파라미터를 사용하면 된다.  \n",
    "(만약 하나라도 `NaN`인 경우를 삭제하고 싶다면 `how = 'any'` 파라미터를 사용한다.)  \n",
    "df의 인덱스가 g인 로우는 `NaN`로만 이루어져 있기 때문에 해당 로우를 삭제한다.  \n",
    "\n",
    "만약 로우가 아니라 칼럼에 적용하고자 한다면 `axis = 1` 파라미터를 전달한다.  \n",
    "그러면 c5 칼럼은 `NaN`로만 이루어져 있기 때문에 해당 칼럼을 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using how='all', only rows that have all values\n",
    "# as NaN will be dropped\n",
    "df.dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4\n",
       "a   0.0   1.0   2.0  20.0\n",
       "b   3.0   4.0   5.0   NaN\n",
       "c   6.0   7.0   8.0   NaN\n",
       "d   9.0  10.0  11.0   NaN\n",
       "e  12.0  13.0  14.0   NaN\n",
       "f  15.0  16.0  17.0  18.0\n",
       "g   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flip to drop columns instead of rows\n",
    "df.dropna(how = 'all', axis = 1) # say goodbye to c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.dropna(thresh = )`\n",
    "`.dropna()`에는 `thresh`라는 파라미터가 있다. 이 파라미터는 삭제 대상의 최소 `NaN` 값 개수를 지정한다.  \n",
    "\n",
    "예를 들어 c4, c5 칼럼처럼 5개 이상의 `NaN`값이 있는 칼럼을 모두 삭제하도록 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   0.0   NaN   0.0   NaN NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시를 만들기 위해 c1, c3칼럼의 값을 조금 변경한다. \n",
    "\n",
    "# make a copy of df\n",
    "df2 = df.copy()\n",
    "# replace two NaN cells with values\n",
    "df2.loc['g'].c1 = 0\n",
    "df2.loc['g'].c3 = 0\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비교해본다면, 하나라도 `NaN`인 칼럼을 지운 경우와, 그 아래는 5개이상 `NaN`인 칼럼만 지운 경우이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c3\n",
       "a   0.0   2.0\n",
       "b   3.0   5.0\n",
       "c   6.0   8.0\n",
       "d   9.0  11.0\n",
       "e  12.0  14.0\n",
       "f  15.0  17.0\n",
       "g   0.0   0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now drop columns with any NaN values\n",
    "df2.dropna(how = 'any', axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3\n",
       "a   0.0   1.0   2.0\n",
       "b   3.0   4.0   5.0\n",
       "c   6.0   7.0   8.0\n",
       "d   9.0  10.0  11.0\n",
       "e  12.0  13.0  14.0\n",
       "f  15.0  16.0  17.0\n",
       "g   NaN   NaN   NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only drop columns with at least 5 NaN values\n",
    "df.dropna(thresh=5, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How pandas handles NaN’s in mathematical operations\n",
    "수학 연산에서의 `NaN`  처리 방식\n",
    "\n",
    "pandas의 `NaN`처리 방식은 NumPy와 다르다.  \n",
    "예를 들어 NumPy는 `NaN`을 만나면 `NaN`을 반환하게 되어있다. 반면 pandas는 `NaN`값을 `Series`의 일부로 취급하지 않고 제외(무시)하면서 연산을 진행한다.  \n",
    "\n",
    "    pandas가 계산한 식은, (1+2+3)/3 이다. `NaN`이 무시될 뿐만 아니라 counting 에서도 제외된 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2. nan  3.]\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    NaN\n",
      "3    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create a NumPy array with one NaN value\n",
    "a = np.array([1, 2, np.nan, 3])\n",
    "# create a Series from the array\n",
    "s = pd.Series(a)\n",
    "print(a)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 2.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the mean of each is different\n",
    "a.mean(), s.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좀 더 구체적으로 살펴본다면 pandas는 다음과 같은 방식으로 `NaN` 값을 처리한다. \n",
    "- 합산에 있어서 `NaN`을 0으로 취급\n",
    "- 모든 값이 `NaN`일 경우에만 결과가 `NaN`\n",
    "- `.cumsum()`이나 `.cumprod()`와 같은 메서드는 계산 시에 `NaN` 값을 무시하지만, 그 결과 목록에는 유지시킴  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate sum, mean and cumsum handling of NaN\n",
    "# get one column\n",
    "s = df.c4\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.0,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sum(), # NaN's treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean() # NaN also treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    38.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as 0 in the cumsum, but NaN's preserved in result Series\n",
    "# 누적합에는 `NaN`이 그대로 있으면서 연산에 결과를 미치지 않는다.\n",
    "s.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전통적인 수학 기호를 사용할 경우 0으로 취급되지 않고 그대로 유지된다. 말그대로 알 수 없는 값이기 때문아닐까."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    21.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    19.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in arithmetic, a NaN value will result in NaN\n",
    "df.c4 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.fillna(n)` Filling in missing data with 'n'\n",
    "결측 데이터 보강\n",
    "\n",
    "`NaN`값을 무시하거나 유지하는 대신, 특정 값을 대체하고 싶다면 `.fillna()`메서드를 사용하면 된다.  \n",
    "`.fillna()`또한 `inplace` 옵션이 있어서, 원본은 유지한 채 복제된 것을 반환한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  0.0\n",
       "d   9.0  10.0  11.0   0.0  0.0\n",
       "e  12.0  13.0  14.0   0.0  0.0\n",
       "f  15.0  16.0  17.0  18.0  0.0\n",
       "g   0.0   0.0   0.0   0.0  0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a new DataFrame with NaN's filled with 0\n",
    "df_filled = df.fillna(0)\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 바꾸었을 경우 `NaN`은 더이상 `NaN`이 아니라 0이다. 셈이 달라지는 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1     7.5\n",
       "c2     8.5\n",
       "c3     9.5\n",
       "c4    19.0\n",
       "c5     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN's don't count as an item in calculating\n",
    "# the means\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6.428571\n",
       "c2    7.285714\n",
       "c3    8.142857\n",
       "c4    5.428571\n",
       "c5    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having replaced NaN with 0 can make\n",
    "# operations such as mean have different results\n",
    "df_filled.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.fillna(method = 'ffill'|'bfill')`: Forward and backwards filling of missing values\n",
    "결측 값 채우는 일을 `Series`안의 `NaN`이 아닌 값으로 결측 값을 채울 수 있다. (이 역시 `inplace`옵션이 제공된다.)\n",
    "\n",
    "**정방향 채우기(forward filling)**를 적용한 예시로는, 결측이 발견되기 바로 전의 값으로 채우는 것이다.  \n",
    "\n",
    "    시계열 데이터에 대한 이와 같은 기법을 흔히 '마지막 유효 값(last known value)'이라고 한다. (13장에서 다시 확인)\n",
    "\n",
    "반대로 **역방향 채우기(backward filling)**은 결측이 발견된 후 바로 나중의 값으로 채우는 것이다.  \n",
    "\n",
    "    타이핑 수를 줄이기 위해 pandas에서는 제공하는 `pd.ffill()`, `pd.bfill()`을 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    20.0\n",
       "c    20.0\n",
       "d    20.0\n",
       "e    20.0\n",
       "f    18.0\n",
       "g    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the c4 column and fill NaNs forward\n",
    "df.c4.fillna(method = \"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a backwards fill\n",
    "df.c4.fillna(method = \"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 같은 결과\n",
    "df['c4'].bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .fillna(fill_values) : Filling using index labels\n",
    "인덱스 레이블을 사용한 채우기\n",
    "\n",
    "`Series`의 레이블이나 파이썬 딕셔너리의 키를 사용해 데이터를 채울 수 있다. 이 경우 인덱스 레이블에 기초해 각 요소에 서로 다른 값을 지정할 수 있다.  \n",
    "각 인덱스를 지정한 하나의 시리즈를 통해, `NaN`인 곳에 파라미터로 주어진 해당 인덱스로 지정된 값을 채운다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100\n",
       "e    101\n",
       "g    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new Series of values to be \n",
    "# used to fill NaN's where index label matches\n",
    "fill_values = pd.Series([100, 101, 102], index = ['a', 'e', 'g'])\n",
    "fill_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a 인덱스는 `NaN`이 아니기 때문에 바뀌지 않은 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     20.0\n",
       "b      NaN\n",
       "c      NaN\n",
       "d      NaN\n",
       "e    101.0\n",
       "f     18.0\n",
       "g    102.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using c4, fill using fill_values\n",
    "# a, e and g will be filled with matching values\n",
    "df.c4.fillna(fill_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪`.fillna(.mean() )`\n",
    "흔히 사용되는 또 다른 방법은 `NaN`을 해당 칼럼의 평균 값으로 채우는 것이다.  \n",
    "\n",
    "이는 결측값을 0으로 채울 때보다 통계적으로 덜 왜곡되게 만들 수 있는 편리한 방법이다.  \n",
    "또한 통계 분석에서 0 값 때문에 너무 커진 편차로 인한 거짓 오류(false failure), 즉 실제로는 오류가 아니지만 오류로 인식될 수 있는 상황을 예방하는데 특히 유용하다.  \n",
    "\n",
    "`DataFrame`에 적용했을 경우 각각의 칼럼의 평균 값으로 채워지는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0  19.0 NaN\n",
       "c   6.0   7.0   8.0  19.0 NaN\n",
       "d   9.0  10.0  11.0  19.0 NaN\n",
       "e  12.0  13.0  14.0  19.0 NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   7.5   8.5   9.5  19.0 NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NaN values in each column with the \n",
    "# mean of the values in that column\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.interpolate()` : Interpolation of missing values\n",
    "보간법을 사용한 결측 값 채우기\n",
    "\n",
    "`DataFrame`과 `Series`에 있는 `.interpolate()` 메서드는 기본적으로 결측 값에 대해 선형 보간법을 사용한다.  \n",
    "\n",
    "보간법은 연속된 `NaN`의 앞의 값과 뒤의 값을 통해 계산된 차이 값을 차례대로 더해 `NaN`을 대체하는 방식이다.  \n",
    "\n",
    "1과 `NaN`, 2로 이루어져있을 경우 각각 같은 간격이 존재하도록 0.25씩 증가시켜 `NaN`을 채우는 예시이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.00\n",
       "1    1.25\n",
       "2    1.50\n",
       "3    1.75\n",
       "4    2.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate the NaN values from 1 through 2\n",
    "s = pd.Series([1, np.nan, np.nan, np.nan, 2])\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보간법은 중요한 기법이다. 예를 들어 낮동안 올라가는 시간별 기온을 나타내는 데이터가 있는데, 센서 고장으로 중간에 데이터가 기록되지 않았다면 보간법을 사용해 추측되는 기온으로 데이터를 채울 수 있다. 이는 0으로 채우는 것보다 훨씬 의미가 있다!  \n",
    "\n",
    "\n",
    "### `.interpolate(method = 'time')`\n",
    "`.interpolate()`메서드는 보간법의 특정 방식을 지정할 수 있는 기능을 제공한다. 흔히 사용되는 방식 중 하나는 시간에 기반을 둔 보간법이다.  \n",
    "다음 예에서, 날짜와 값으로 이루어진 `Series`가 있을 때 생각해본다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    NaN\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a time series, but missing one date in the Series\n",
    "ts = pd.Series([1, np.nan, 2], \n",
    "            index=[datetime(2014, 1, 1), \n",
    "                   datetime(2014, 2, 1),                   \n",
    "                   datetime(2014, 4, 1)])\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그대로 보간법을 사용할 경우 예상대로 그 결과는 1.5가 채워진다.  \n",
    "\n",
    "그러나 중요한 점은 2014-03-01 데이터도 누락되어있다는 사실이다. 따라서 값을 추측해야할 대상은 2014-02-01, 2014-03-01 에 대한 데이터이므로 계산식에서의 분모는 3이 됐어야 한다.  \n",
    "이때 `.interpilate(method = 'time')` 으로 지정하여 해결할 수 있다.  \n",
    "(그렇다고 하여 2014-03-01, 없는 인덱스가 생성되지는 않는다. 보간법 계산에만 관여됐을 뿐이다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    1.5\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate based on number of items in the Series\n",
    "ts.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.000000\n",
       "2014-02-01    1.344444\n",
       "2014-04-01    2.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this accounts for the fact that we don't have\n",
    "# an entry for 2014-03-01\n",
    "ts.interpolate(method= 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.interpolate(methd = 'values')`\n",
    "\n",
    "인덱스 레이블이 **숫자인 경우라면 그 인덱스 레이블에 따라 상대적으로 값이 계산되는 보간법**을 사용할 수도 있다.  \n",
    "\n",
    "예를 들어 다음과 같은 `Series`가 있을 때 선형 보간법(일반적인 보간법)을 사용한다면 50이 채워질 것이다.  \n",
    "그러나 인덱스 값에 따라 상대적으로 값을 부여하고 싶다면 `method = 'values'`를 지정하면 된다.  \n",
    "인덱스 레이블에 따라 상대적인 위치에 맞게 값이 계산되는데, 인덱스 레이블은 0에서 10 사이에 1/10 위치이므로 0 + (100-0)/10 으로 계산되어 그 값이 10이 할당 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       NaN\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a Series to demonstrate index label based interpolation\n",
    "s = pd.Series([0, np.nan, 100], index=[0, 1, 10])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      50.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      10.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate based upon the values in the index\n",
    "s.interpolate(method = 'values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Duplicate Data\n",
    "---\n",
    "중복 데이터 다루기\n",
    "\n",
    "표본 데이터에는 종종 중복된 로우가 존재하기도 한다. 이는 자동으로 수집된 데이터 뿐만 아니라 수동으로 수집한 데이터에 있어서도 실제로 발생한다. 종종 중복 데이터의 존재는 결측 데이터가 있는 경우 보다는 나은 상황으로 여겨진다. 특히 데이터가 멱등성(idempotence)을 갖는 경우, 즉 계산 결과에 영향이 없는 상황에서는 더욱 그렇다.  \n",
    "그러나 중복 데이터는 데이터셋의 크기를 증가시키며, 멱등성이 없는 데이터의 경우에 중복 데이터를 그대로 두는 일은 적절하지 않다.  \n",
    "\n",
    "### `.duplicate()` : 중복 데이터 찾기\n",
    "pandas는 중복 데이터를 찾아주는 `.duplicate()`메서드를 제공한다.  \n",
    "이 메서드는 중복된 로우인지의 여부를 나타내는 불리언 값으로 된 `Series`를 반환한다.  \n",
    "반환 값이 True 라면 현재 데이터 프레임 안에서 **완전히 동일한**로우가 이전에 있었다는 의미다. \n",
    "\n",
    "예시 데이터를 만들어본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "1  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "4  y  3\n",
       "5  y  4\n",
       "6  y  4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a DataFrame with lots of duplicate data\n",
    "data = pd.DataFrame({'a': ['x'] * 3 + ['y'] * 4, \n",
    "                     'b': [1, 1, 2, 3, 3, 4, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복된 로우는 이렇게 찾을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reports which rows are duplicates based upon\n",
    "# if the data in all columns was seen before\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.drop_duplicates()` : 중복 로우 삭제하기\n",
    "중복된 로우는 `.drop_duplicates()` 메서드로 삭제할 수 있다. 이 메서드는 중복된 로우가 제거된 `DataFrame` 사본을 반환한다.  \n",
    "이 메서드의 `inplace = True` 옵션을 사용하면 사본 대신 원본의 중복 로우를 즉석에서 삭제한다. (원본 변경 일어남)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "5  y  4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows retaining first row of the duplicates\n",
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터 삭제 방식 선택하기\n",
    "\n",
    "중복 데이터를 삭제함으로써 그 결과에 영향이 있음을 알아야 한다.  \n",
    "중복된 레코드는 다른 인덱스 레이블을 가졌을 것이며, 그 인덱스 레이블은 중복 데이터를 판별할 때 고려되지 않는다. 따라서, 어떤 데이터가 유지되는지에 따라 결과 `DataFrame`의 레이블이 달라질 수 있다.  \n",
    "\n",
    "(1) 기본적으로 중복된 로우 중 가장 첫 로우만 유지된다.  \n",
    "만약 마지막 로우를 유지하고 싶다면 `keep = 'last'` 파라미터를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "1  x  1\n",
       "2  x  2\n",
       "4  y  3\n",
       "6  y  4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows, only keeping the first \n",
    "# instance of any data\n",
    "# 바로 위의 셀의 결과와 인덱스 레이블이 다르다.\n",
    "data.drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 일부 칼럼에 대해서만 중복 데이터를 확인하고 싶다면 **칼럼명 리스트를 전달**하면 된다. (`subset = []` 옵션)\n",
    "\n",
    "아래 예시에서는 중복 로우가 없는 c칼럼을 추가한 뒤에, a, b 칼럼에 대해서만 중복 데이터를 삭제하는 예시이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column c with values 0..6\n",
    "# this makes .duplicated() report no duplicate rows\n",
    "data['c'] = range(7)\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  x  1  0\n",
       "2  x  2  2\n",
       "3  y  3  3\n",
       "5  y  4  5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but if we specify duplicates to be dropped only in columns a & b\n",
    "# they will be dropped\n",
    "data.drop_duplicates(['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  x  1  0\n",
       "1  x  1  1\n",
       "2  x  2  2\n",
       "3  y  3  3\n",
       "4  y  3  4\n",
       "5  y  4  5\n",
       "6  y  4  6"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 c를 포함해서 찾게되면 중복이 없는 것으로 나온다.\n",
    "data.drop_duplicates(subset = ['b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 변형\n",
    "---\n",
    "데이터 정돈에 있어서 또 다른 한 부분은 기존 데이터를 다른 모양으로 변형하는 일이다. 보통 다음과 같은 경우가 데이터 변형을 하는 이유다.  \n",
    "- 값의 단위가 올바르지 않은 경우\n",
    "- 질적 데이터를 적당한 숫자 값으로 변환해야 하는 경우\n",
    "- 메모리다 처리 시간을 소비하는, 또는 단지 포함되는 것만으로도 결과에 영향을 줄 수 있는 불필요한 데이터가 있을 경우\n",
    "\n",
    "그런 상황을 바로 잡기 위해서는 다음과 같은 작업들이 하나 이상 필요할 수 있다.  \n",
    "- 테이블 검색을 사용해 데이터를 다른 인덱스에 매핑한다. \n",
    "- 명시적으로 특정 값을 다른 값으로, 또는 다른 데이터 타입으로 대체한다. \n",
    "- 알고리즘에 기초해 값을 변형시키는 메서드를 적용한다. \n",
    "- 단순히 불필요한 칼럼이나 로우를 삭제한다.  \n",
    "\n",
    "칼럼이나 로우를 삭제하는 방법은 앞에 했고, 변형을 위해 데이터 매핑, 대체, 함수 적용 기능을 알아보자.  \n",
    "\n",
    "## `.map()` : Mapping\n",
    "데이터를 다른 인덱스에 매핑\n",
    "\n",
    "데이터 변형에 있어서 기본적인 작업 중 하나는 한 데이터셋을 다른 데이터셋에 매핑하는 일이다.  \n",
    "pandas는 파이썬 딕셔너리나 pandas `Series`를 통한 테이블 검색으로 값을 매핑해주는 `.map()`메서드를 제공한다.  \n",
    "\n",
    "이 메서드는 먼저 외부 `Sereis`의 값을 내부 `Series`의 인덱스 레이블에 일치시킨다.  \n",
    "그 후 *외부 `Series`의 인덱스 레이블*과 *내부 `Series`의 값*을 갖는 새로운 `Series`를 반환한다.  \n",
    "\n",
    "다음 예제에서는 y라는 내부 `Series`의 값을 x라는 외부 `Series`의 인덱스 레이블에 매핑하는 방식이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      1\n",
       "two      2\n",
       "three    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two Series objects to demonstrate mapping\n",
    "x = pd.Series({\"one\": 1, \"two\": 2, \"three\": 3})\n",
    "y = pd.Series({1: \"a\", 2: \"b\", 3: \"c\"})\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    a\n",
       "2    b\n",
       "3    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x에 map을 y를 시킨 결과는 다음처럼 일치하는 값에 따라서, x의 인덱스와 y의 값을 갖는 `Series`가 나왔다.  \n",
    "다시 말해, 외부 것의 값이 내부의 인덱스 레이블과 매핑된 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      a\n",
       "two      b\n",
       "three    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map values in x to values in y \n",
    "x.map(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 정렬 작업에서와 마찬가지로, 외부 `Series`의 값을 내부 `Series`의 인덱스 레이블에 일치시키지 못하는 경우에는 `NaN`을 반환한다.  \n",
    "\n",
    "외부 `Series`의 3과 일치하는 내부 `Series`의 인덱스 레이블이 없어서, 값을 알 수 없으므로 `NaN`이 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one        a\n",
       "two        b\n",
       "three    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three in x will not align / map to a value in y\n",
    "x = pd.Series({\"one\": 1, \"two\": 2, \"three\": 3})\n",
    "y = pd.Series({1: \"a\", 2: \"b\"})\n",
    "x.map(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.replace()` : Replacing values\n",
    "데이터 대체 : `DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')` \n",
    "\n",
    "`.fillna()`를 통해 `NaN`을 원하는 값으로 대체하는 방법을 알고 있다. `.fillna()` 메서드는 특정 값을 `NaN`의 인덱스에 매핑해주는 `.map()`메서드의 특수한 형태라고 생각해도 된다.  \n",
    "\n",
    "포괄적으로 본다면, `.fillna()` 자체는 `.replace()`메서드가 제공하는 대체 기능을 특별하게 구현한 메서드라고 봐도 좋다. `.replace()`메서드는 `NaN` 을 포함하여 어떤 값이든 간에 다른 값으로 대체할 수 있는 유연함을 제공한다.  \n",
    "\n",
    "이 역시 `inplace` 옵션이 있으므로 원본을 즉석에서 바꾸길 원한다면 사용한다!!!\n",
    "\n",
    "### `Series`에서 개별 값 하나를 다른 값으로 대체\n",
    "`.replace(to_replace = , value = )` 메서드에 원본 값과 바꿀 값으로 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    3.0\n",
       "4    2.0\n",
       "5    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Series to demonstrate replace\n",
    "s = pd.Series([0., 1., 2., 3., 2., 4.])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    5.0\n",
       "3    3.0\n",
       "4    5.0\n",
       "5    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all items with index label 2 with value 5\n",
    "s.replace(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리스트를 활용하여 여러 값을 여러 다른 값으로 대체\n",
    "`.replace()` 메서드에 두 개의 리스트를 전달하면, 첫 번째 리스트의 값들이 두 번째 리스트의 값들로 대체된다.  \n",
    "\n",
    "판다스 공식문서에 써있듯, **if to_replace and value are both lists, they must be the same length.**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "1    3.0\n",
       "2    2.0\n",
       "3    1.0\n",
       "4    2.0\n",
       "5    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all items with new values\n",
    "s.replace([0, 1, 2, 3, 4], [4, 3, 2, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딕셔너리를 활용하여 여러 값을 여러 다른 값으로 대체\n",
    "Dicts can be used to specify different replacement values.  \n",
    "{키:값} 의 구조에서, 키에 원본 값을, 값에 바꿀 값으로 전달하면 대체된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     10.0\n",
       "1    100.0\n",
       "2      2.0\n",
       "3      3.0\n",
       "4      2.0\n",
       "5      4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace using entries in a dictionary\n",
    "s.replace({0: 10, 1: 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame`에서의 특정 값 변경\n",
    "\n",
    "예시 데이터 프레임은 두 칼럼으로 이루어진 데이터프레임이다. \n",
    "`.replace({칼럼:값, 칼럼:값, ...}, 바꿀 값)` 형식으로 각 칼럼과 원본 값을 딕셔너리 형태로 전달한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  0  5\n",
       "1  1  6\n",
       "2  2  7\n",
       "3  3  8\n",
       "4  4  9"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame with two columns\n",
    "df = pd.DataFrame({'a': [0, 1, 2, 3, 4], 'b': [5, 6, 7, 8, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a DataFrame a dict can specify that different values  \n",
    "should be replaced in different columns.  \n",
    "The value parameter should not be None in this case.   \n",
    "\n",
    " {'a': 1, 'b': 'z'} 가 칼럼 a의 값1, 칼럼 b의 값 z의 경우, `value=` 파라미터를 주어서 해당 위치에 해당하는 값을 대체한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a    b\n",
       "0    0    5\n",
       "1  100    6\n",
       "2    2    7\n",
       "3    3  100\n",
       "4    4    9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify different replacement values for each column\n",
    "df.replace({'a': 1, 'b': 8}, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicts can be used to specify different replacement values.  \n",
    "\n",
    "만약 `df.replace({key:val})`으로 직접 한다면, key라는 모든 값은 val으로 변경된다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b\n",
       "0  10  50\n",
       "1   1   6\n",
       "2   2   7\n",
       "3   3   8\n",
       "4   4   9"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace({0:10, 5:50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b       c\n",
       "0  0  5       a\n",
       "1  1  6       a\n",
       "2  2  7   bread\n",
       "3  3  8  cheeze\n",
       "4  4  9  cheeze"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'a': [0, 1, 2, 3, 4], 'b': [5, 6, 7, 8, 9], 'c' : ['a', 'a', 'bread', 'cheeze', 'cheeze']})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b       c\n",
       "0  0  5   apple\n",
       "1  1  6   apple\n",
       "2  2  7   bread\n",
       "3  3  8  cheeze\n",
       "4  4  9  cheeze"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a가 잘못 적힌거라고 간주하고, a만 바꿔본다.\n",
    "# value 파라미터를 따로 주지 말아야 하며, a칼럼의 apple을 찾는게 아닌 a라는 모든 값을 찾아 apple로 바꾼다.\n",
    "df2.replace({'a':'apple'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금 변형하여 이런식도 가능하다.  \n",
    "\n",
    "For a DataFrame nested dictionaries, e.g.,\n",
    "{'a': {'b': np.nan}}, are read as follows: look in column ‘a’ for the value ‘b’ and replace it with NaN. The value parameter should be None to use a nested dict in this way.  \n",
    "\n",
    "`.replace({'a': {'b': np.nan}})`은 'a'라는 칼럼에 'b'라는 값을 'np.nan'으로 바꾸는 식이다. 만약 예시로 본다면 이렇게 가능하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  0  5  a\n",
       "1  1  6  a\n",
       "2  2  7  b\n",
       "3  3  8  c\n",
       "4  4  9  c"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bread 과 cheeze 가 잘못 된 거라 간주한다면 이렇게 칼럼 지정후 해당 값들을 바꾸는 것이 가능하다.\n",
    "df2.replace({'c': {'cheeze' : 'c', 'bread': 'b'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `method = ` 파라미터 : 인덱스 포지션으로 다른 값 채우기\n",
    "마치 결측 값을 채우는 경우처럼 특정 인덱스 포지션의 아이템을 대체할 수도 있다.  \n",
    "\n",
    "다음은 `.replace(인덱스포지션리스트, method = 'pad')`를 이용하여인덱스 포지션 0에 해당하는 값으로 1, 2, 3에 위치에 정방향으로 채우는 예시이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1     1.0\n",
       "2     2.0\n",
       "3     3.0\n",
       "4     2.0\n",
       "5     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate replacement with pad method\n",
    "# set first item to 10, to have a distinct replacement value\n",
    "s[0] = 10\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1    10.0\n",
       "2    10.0\n",
       "3    10.0\n",
       "4    10.0\n",
       "5     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace items with index label 1, 2, 3, using fill from the\n",
    "# most recent value prior to the specified labels (10)\n",
    "s.replace([1, 2, 3], method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1    10.0\n",
       "2    10.0\n",
       "3     3.0\n",
       "4     3.0\n",
       "5     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 포워드필과 백워드 필을 실행해본다. \n",
    "# 포워드 필은 1, 2 자리의 앞에 있는 0번째 값으로 1, 2 자리에 채우게 된다. \n",
    "s.replace([1, 2], method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1     3.0\n",
       "2     3.0\n",
       "3     3.0\n",
       "4     4.0\n",
       "5     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 백워드 필은 1, 2 자리의 뒤에 있는 3번째 값으로 1, 2 자리에 채우게된다.\n",
    "s.replace([1, 2], method = 'bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가: 만약 조건으로 바꾸고자 한다면\n",
    "\n",
    "`Series.where` : Replace values based on boolean condition.  \n",
    "(공식 문서: [https://pandas.pydata.org/pandas-docs/version/1.3/reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where])\n",
    "\n",
    "`DataFrame.where(cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=NoDefault.no_default)`  \n",
    "`where()` 메서드는 조건을 주어서, 해당 조건에 따라 값이 바뀌도록 할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1     1.0\n",
       "2     2.0\n",
       "3     3.0\n",
       "4     2.0\n",
       "5     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    NaN\n",
       "4    2.0\n",
       "5    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cond에 맞는 값만 그대로, 나머지는 NaN이 출력된다. \n",
    "s.where(cond = s<3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    110.0\n",
       "1      1.0\n",
       "2      2.0\n",
       "3    103.0\n",
       "4      2.0\n",
       "5    104.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cond에 맞는 값만 그대로, 나머지는 특정 값이 출력되도록 한다.\n",
    "s.where(cond = s<3, other = s+100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b       c\n",
       "0  0  5       a\n",
       "1  1  6       a\n",
       "2  2  7   bread\n",
       "3  3  8  cheeze\n",
       "4  4  9  cheeze"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b    c\n",
       "0  0  5    a\n",
       "1 -1 -6  NaN\n",
       "2 -2 -7  NaN\n",
       "3 -3 -8  NaN\n",
       "4 -4 -9  NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 프레임에도 그대로 적용할 수 있다. \n",
    "cond1 = df2['c'] == 'a'\n",
    "cond2 = df2['b'] == 5\n",
    "df2.where(cond = cond1&cond2, other = -df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.apply(lambda )` : Applying functions to transform data\n",
    "데이터 변형을 위한 함수 적용\n",
    "\n",
    "데이터를 직접 매핑하거나 대체하는 방법으로 충분하지 않은 상황이라면 특정 알고리즘을 수행하는 함수를 데이터에 적용하는 방법이 있다.  \n",
    "pandas는 개별 아이템이나 칼럼 또는 로우에 통째로 함수를 적용할 수 있는 유연한 변형 기능을 제공한다.  \n",
    "\n",
    "함수는 `.apply()`메서드를 사용해 적용할 수 있다.  \n",
    "`Series`의 경우엔 각 값이 주어진 파이썬 함수에 전달된다.  \n",
    "`DataFrame`의 경우엔 각 칼럼이 `Sereis`로 전달되며, `axis=1` 옵션을 사용한다면 각 로우가 `Series`로 전달된다. \n",
    "\n",
    "## `Series`에 람다 함수 적용\n",
    "`Series`의 아이템에 함수를 적용하는 경우 인덱스 레이블이나 인덱스 값이 아닌 각 아이템의 값만 함수에 전달된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "2    4\n",
       "3    6\n",
       "4    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a function to every item of a Series\n",
    "s = pd.Series(np.arange(0, 5))\n",
    "s.apply(lambda v: v * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame`에 람다 함수 적용\n",
    "`DataFrame`에 함수를 적용하는 경우 기본적으로 각 칼럼에 함수가 적용된다.  \n",
    "pandas는 모든 칼럼을 돌며 각각을 `Series`로 함수에 전달한다.  \n",
    "그 결과 칼럼명과 동일한 인덱스 레이블, 그리고 함수의 결과를 값으로 갖는 `Series` 객체를 반환한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c\n",
       "0  0   1   2\n",
       "1  3   4   5\n",
       "2  6   7   8\n",
       "3  9  10  11"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a sum on each column\n",
    "df = pd.DataFrame(np.arange(12).reshape(4, 3), \n",
    "                  columns=['a', 'b', 'c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 컬렴별로 합을 구하는 것으로 `Series`가 반환되었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    18\n",
       "b    22\n",
       "c    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cumulative sum of items in each column\n",
    "df.apply(lambda col: col.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 칼럼 별이 아닌 로우 별로, 적용을 한다면 `axis = 1` 옵션을 활용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1    12\n",
       "2    21\n",
       "3    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate sum of items in each row\n",
    "df.apply(lambda row: row.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 활용 사례는 함수의 적용 결과를 새 칼럼으로 데이터 프레임에 추가하는 것이다.  \n",
    "이는 한 번 이상의 연이은 계산 결과를 `DataFrame`에 계속 덧붙임으로써 각 결과가 점진적으로 변화된 모습을 확인할 수 있다는 점에서 유용하다.  \n",
    "\n",
    "다음은 a, b칼럼의 각 로우 별 데이터를 곱한 결과를 새 칼럼으로 추가하는 것이다.  \n",
    "그리고 해당 칼럼을 c칼럼과 더한 결과를 새 칼럼으로 추가하는 과정이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c  interim\n",
       "0  0   1   2        0\n",
       "1  3   4   5       12\n",
       "2  6   7   8       42\n",
       "3  9  10  11       90"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column 'interim' with a * b\n",
    "df['interim'] = df.apply(lambda r: r.a * r.b, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c  interim  result\n",
       "0  0   1   2        0       2\n",
       "1  3   4   5       12      17\n",
       "2  6   7   8       42      50\n",
       "3  9  10  11       90     101"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now a 'result' column with 'interim' + 'c'\n",
    "df['result'] = df.apply(lambda r: r.interim + r.c, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 칼럼 값을 바꾸고 싶다면 단순히 계산 결과를 그 칼럼에 할당 하면된다.  \n",
    "다음은 칼럼 a값을 각 로우의 합으로 바꾸는 예시이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c  interim  result\n",
       "0   3   1   2        0       2\n",
       "1  12   4   5       12      17\n",
       "2  21   7   8       42      50\n",
       "3  30  10  11       90     101"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace column a with the sum of columns a, b and c\n",
    "df.a = df.a + df.b + df.c\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관례상 기존 칼럼을 완전히 새로운 값으로 대체하는 일은 좋은 방법이 아니며, 잃어버린 데이터로 인해 디버깅을 곤란하게 만듦으로써 종종 일시적/지속적 문제를 야기할 수 있다.  \n",
    "따라서 pandas에서는 그냥 새 로우나 칼럼, 또는 완전히 새로운 객체로 추가하는 것이 일반적이며 더 나은 관행이다. \n",
    "(나중에 메모리나 성능의 이슈가 생긴다면 그에 따른 최적화를 수행하면 됨)  \n",
    "\n",
    "유념해야 할 또 다른 사항은 pandas의 `DataFrame`은 스프레드시트가 아니라는 점.  \n",
    "스프레드시트에서는 수식 자체도 셀에 할당되며, 참조하는 셀의 값이 변경될 경우 수식이 자동으로 다시 계산된다. pandas에서는 그렇게 값이 바뀌어서 다시 계산하고자 한다면 일일이 수동으로 해야한다. 뒤집어 생각하면 성능상 이게 나을 수 있는데, 어떤 데이터의 변경이라도 그에 따른 모든 계산 작업을 연쇄적으로 일으키지 않기 때문이다.  \n",
    "\n",
    "`.apply()`메서드는 `Series`, 칼럼, 로우의 모든 아이템에 대해 함수를 적용한다.  \n",
    "특정 데이터 서브셋에만 함수를 적용하고 싶다면 먼저 불리언 선택을 통해 처리 대상을 추려야 한다.  \n",
    "\n",
    "다음은 `NaN`값을 추가한 데이터프레임에서, `NaN`이 아닌 모든 값에 함수를 적용하는 예시이다.  \n",
    "`.dropna()`를 사용하면서 [1]번 인덱스의 로우가 사라지게되고, 남은 [0], [2]번 인덱스에만 함수가 적용된 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    0   1     2   3   4\n",
       "0   0   1   2.0   3   4\n",
       "1   5   6   NaN   8   9\n",
       "2  10  11  12.0  13  14"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 3x5 DataFrame\n",
    "# only second row has a NaN\n",
    "df = pd.DataFrame(np.arange(0, 15).reshape(3,5))\n",
    "df.loc[1, 2] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "2    60.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a function to only rows having\n",
    "# a count of 0 NaN values\n",
    "df.dropna().apply(lambda x: x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.applymap()` : 모든 개별 값에 함수 적용\n",
    "`.apply()` 메서드가 항상 로우나 칼럼에 통째로 함수를 적용하는 반면, `.applymap()` 메서드는 모든 개별 값에 함수를 적용한다.  \n",
    "\n",
    "여기서 각 값들에 소수점 자리를 적용하는 예시이다.  \n",
    "아 물론 데이터 타입은 ... 우리가 원하는 형태에서 벗어나게 된 방식이다...\n",
    "\n",
    "만약 정수를 소수로 표현하고 싶다면 나라면, int를 사용하겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       0      1      2      3      4\n",
       "0   0.00   1.00   2.00   3.00   4.00\n",
       "1   5.00   6.00    nan   8.00   9.00\n",
       "2  10.00  11.00  12.00  13.00  14.00"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use applymap to format all items of the DataFrame\n",
    "df.applymap(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       3 non-null      object\n",
      " 1   1       3 non-null      object\n",
      " 2   2       3 non-null      object\n",
      " 3   3       3 non-null      object\n",
      " 4   4       3 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 248.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# 데이터타입이 object이다\n",
    "df.applymap(lambda x: '%.2f' % x).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      0     1     2     3     4\n",
       "0   0.0   1.0   2.0   3.0   4.0\n",
       "1   5.0   6.0   NaN   8.0   9.0\n",
       "2  10.0  11.0  12.0  13.0  14.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 꼭 두자리 해야하는 게 아니면 그러지말고.. 이렇게\n",
    "df.applymap(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       3 non-null      float64\n",
      " 1   1       3 non-null      float64\n",
      " 2   2       2 non-null      float64\n",
      " 3   3       3 non-null      float64\n",
      " 4   4       3 non-null      float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 248.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.applymap(lambda x: float(x)).info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
