{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configuring-pandas\" data-toc-modified-id=\"Configuring-pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configuring pandas</a></span></li><li><span><a href=\"#데이터-접근\" data-toc-modified-id=\"데이터-접근-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>데이터 접근</a></span></li><li><span><a href=\"#로컬-파일\" data-toc-modified-id=\"로컬-파일-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>로컬 파일</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#CSV-데이터셋-예제:-msft.csv\" data-toc-modified-id=\"CSV-데이터셋-예제:-msft.csv-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>CSV 데이터셋 예제: msft.csv</a></span></li></ul></li><li><span><a href=\"#Reading-a-CSV-into-a-DataFrame\" data-toc-modified-id=\"Reading-a-CSV-into-a-DataFrame-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Reading a CSV into a DataFrame</a></span></li><li><span><a href=\"#Specifying-the-index-column-when-reading-a-CSV-file\" data-toc-modified-id=\"Specifying-the-index-column-when-reading-a-CSV-file-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Specifying the index column when reading a CSV file</a></span></li><li><span><a href=\"#Data-type-inference-and-specification\" data-toc-modified-id=\"Data-type-inference-and-specification-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Data type inference and specification</a></span></li><li><span><a href=\"#Specifying-column-names\" data-toc-modified-id=\"Specifying-column-names-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Specifying column names</a></span></li><li><span><a href=\"#Specifying-specific-columns-to-load\" data-toc-modified-id=\"Specifying-specific-columns-to-load-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Specifying specific columns to load</a></span></li><li><span><a href=\"#Saving-a-DataFrame-to-a-CSV\" data-toc-modified-id=\"Saving-a-DataFrame-to-a-CSV-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Saving a DataFrame to a CSV</a></span></li><li><span><a href=\"#General-field-delimited-data\" data-toc-modified-id=\"General-field-delimited-data-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>General field-delimited data</a></span></li><li><span><a href=\"#Handling-variants-of-formats-in-field-delimited-data\" data-toc-modified-id=\"Handling-variants-of-formats-in-field-delimited-data-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Handling variants of formats in field-delimited data</a></span><ul class=\"toc-item\"><li><span><a href=\"#(skiprows-=-[])-:-헤더-지우기\" data-toc-modified-id=\"(skiprows-=-[])-:-헤더-지우기-3.8.1\"><span class=\"toc-item-num\">3.8.1&nbsp;&nbsp;</span><code>(skiprows = [])</code> : 헤더 지우기</a></span></li><li><span><a href=\"#(skipfooter-=-[])-:-푸터-지우기\" data-toc-modified-id=\"(skipfooter-=-[])-:-푸터-지우기-3.8.2\"><span class=\"toc-item-num\">3.8.2&nbsp;&nbsp;</span><code>(skipfooter = [])</code> : 푸터 지우기</a></span></li><li><span><a href=\"#(nrows-=-)-:-처음-몇-개의-로우만-불러오기\" data-toc-modified-id=\"(nrows-=-)-:-처음-몇-개의-로우만-불러오기-3.8.3\"><span class=\"toc-item-num\">3.8.3&nbsp;&nbsp;</span><code>(nrows = )</code> : 처음 몇 개의 로우만 불러오기</a></span></li></ul></li><li><span><a href=\"#Reading-and-writing-data-in-Excel-format\" data-toc-modified-id=\"Reading-and-writing-data-in-Excel-format-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Reading and writing data in Excel format</a></span><ul class=\"toc-item\"><li><span><a href=\"#pd.read_excel()\" data-toc-modified-id=\"pd.read_excel()-3.9.1\"><span class=\"toc-item-num\">3.9.1&nbsp;&nbsp;</span><code>pd.read_excel()</code></a></span></li><li><span><a href=\"#.to_excel(),-to-xls\" data-toc-modified-id=\".to_excel(),-to-xls-3.9.2\"><span class=\"toc-item-num\">3.9.2&nbsp;&nbsp;</span><code>.to_excel()</code>, to xls</a></span></li><li><span><a href=\"#.to_excel(),-to-xlsx\" data-toc-modified-id=\".to_excel(),-to-xlsx-3.9.3\"><span class=\"toc-item-num\">3.9.3&nbsp;&nbsp;</span><code>.to_excel()</code>, to xlsx</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "1.22.4\n",
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# used for dates\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set some pandas options controlling output format\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 60)\n",
    "\n",
    "# bring in matplotlib for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# version check\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 접근\n",
    "---\n",
    "현실에서의 데이터 분석에 있어서 거의 대부분은 외부로부터의 데이터 로딩이 필요하다. pandas는 파이썬을 기반으로 구현됐으므로, 데이터를 가져오기 위해 파이썬이 제공하는 모든 수단을 이용할 수 있다!!! 또한 엑셀 스프레드시트, 웹사이트, 웹서비스, 데이터베이스, 클라우드 서비스 등 거의 제약 없이 어떤 소스의 데이터라도 접근이 가능하다.  \n",
    "그러나 파이썬의 표준 데이터 로딩 함수를 사용하는 경우에는 파이썬 객체를 pandas의 `Series`나 `DataFrame` 객체로 변환하는 작업이 필요하며, 이는 소스코드의 복잡도를 증가시킨다. 그런 복잡함을 경감해주기위해 pandas는 데이터를 곧바로 pandas 객체로 로딩하는 다양한 기능을 제공한다.  \n",
    "\n",
    "로컬 파일  \n",
    "- CSV를 데이터 프레임으로 로딩\n",
    "- CSV 로딩 시 인덱스 칼럼 지정\n",
    "- 데이터 타입의 추론과 지정\n",
    "- 칼럼명 지정\n",
    "- 특정 칼럼의 로딩\n",
    "- 데이터를 CSV로 저장\n",
    "- 필드 구분 데이터로 작업\n",
    "- 필드 구분 데이터의 다양한 형식 다루기\n",
    "- 엑셀 데이터의 읽기와 쓰기  \n",
    "\n",
    "웹 파일\n",
    "- JSON 파일의 읽기와 쓰기\n",
    "- HTML 데이터 읽기\n",
    "- HDF5 파일의 읽기와 쓰기\n",
    "- 웹을 통한 CSV 데이터 접근\n",
    "- 데이터베이스의 읽기와 쓰기\n",
    "- 야후!와 구글로부터 주식 데이터 읽기\n",
    "- 구글파이낸스의 옵션 데이터 가져오기\n",
    "- 세인트루이스 연방준비은행의 FRED 데이터 가져오기\n",
    "- 케네스 프렌치 데이터에 접근\n",
    "- 세계은행의 데이터 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬 파일\n",
    "---\n",
    "CSV, 텍스트, 테이블 형식의 데이터\n",
    "\n",
    "CSV는 pandas로 작업할 때 가장 흔히 다루게 되는 포맷이다. 많은 웹 기반의 서비스가 데이터를 CSV 형식으로 제공하며, 이는 기업 내 정보 시스템의 경우도 마찬가지다.  \n",
    "CSV는 사용하기 쉬운 포맷이며, Excel 등과 같은 스프레드 시트에서 내보내기 형식으로도 자주 사용된다.  \n",
    "CSV는 여러 줄을 가질 수 있는 텍스트 기반의 데이터이다. 각 값은 쉼표로 구분된다.  \n",
    "마치 스프레드시트에서 하나의 시트처럼 CSV를 하나의 데이터 테이블로 생각할 수 있다. 즉, 각각의 줄이 데이터의 로우이며, 쉼표로 구분된 텍스트 값들이 해당 로우의 각 칼럼이 된다.  \n",
    "\n",
    "    CSV = comma separated values\n",
    "\n",
    "CSV를 통해 배운 내용은 이후의 다른 포맷을 다룰 때에도 적용될 뿐만 아니라 약간의 편의성도 더해준다.\n",
    "\n",
    "### CSV 데이터셋 예제: msft.csv \n",
    "MSTF 티커(ticker, 시황)의 주가 현황 데이터다.  \n",
    "\n",
    "`!head` 명령어로 원하는 수의 줄을 읽을 수 있다.  \n",
    "윈도우의 경우`type` 명령어를 사용해야 한다.  \n",
    "\n",
    "첫째 로우는 쉼표로 구분된 칼럼명으로 구성되어있다. 이후 각 로우는 특정 날짜에서의 주가 데이터로 이루어져있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume\r\n",
      "7/21/2014,83.46,83.53,81.81,81.93,2359300\r\n",
      "7/18/2014,83.3,83.4,82.52,83.35,4020800\r\n",
      "7/17/2014,84.35,84.63,83.33,83.63,1974000\r\n",
      "7/16/2014,83.77,84.91,83.66,84.91,1755600\r\n"
     ]
    }
   ],
   "source": [
    "# view the first five lines of data/msft.csv\n",
    "!head -n 5 /Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv # mac or Linux\n",
    "# type data/msft.csv # on windows, but shows the entire file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a CSV into a DataFrame\n",
    "CSV를 데이터 프레임으로 로딩\n",
    "\n",
    "'mstf.csv' 데이터는 모든 데이터가 완전하고, 첫 번째 로우가 칼럼명으로 되어있기 때문에 완벽하게 데이터 프레임으로 불러올 수 있다.  \n",
    "\n",
    "```\n",
    "pd.read_csv('location')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in msft.csv into a DataFrame\n",
    "msft = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\")\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the index column when reading a CSV file\n",
    "CSV 로딩 시 인덱스 칼럼 지정\n",
    "\n",
    "앞의 예제에서는 날짜가 아닌 0에서 시작하는 숫자가 인덱스였다. 이는 pandas가 파일의 특정 칼럼을 반드시 인덱스로 사용해야 한다고 제약하지 않기 때문인데,  \n",
    "`read_csv()` 사용시 `index_col = (제로베이스 포지션)` 파라미터를 사용하여 원하는 칼럼을 인덱스로 사용할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Open   High    Low  Close   Volume\n",
       "Date                                          \n",
       "7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use column 0 as the index\n",
    "msft = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", index_col= 0)\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data type inference and specification\n",
    "데이터 타입의 추론과 지정\n",
    "\n",
    "칼럼의 데이터 타입을 확인해보면 pandas가 해당 데이터를 통해 추론한 칼럼 타입을 알 수 있다.  \n",
    "강제로 지정하려면 **`pd.read_csv(dtype = )` 파라미터를 사용한다. 딕셔너리 형태로** 지정해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the types of the columns in this DataFrame\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify that the Volume column should be a float64\n",
    "msft = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", \n",
    "                    dtype= {'Volume': np.float64},\n",
    "                    index_col= 0)\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying column names\n",
    "칼럼명 지정\n",
    "\n",
    "`pd.read_csv(names = )` 파라미터를 사용하면 데이터를 읽어올 때 칼럼명도 직접 지정할 수 있다.  \n",
    "**이때 `header = 0` 파라미터를 사용하여 파일의 첫 번째 로우를 건너 뛰도록** 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close   volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a new set of names for the columns\n",
    "# all lower case, remove space in Adj Close\n",
    "# also, header=0 skips the header row\n",
    "df = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", \n",
    "                 header= 0,\n",
    "                 names= ['date', 'open', 'high', 'low', \n",
    "                        'close', 'volume'])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying specific columns to load\n",
    "특정 칼럼만 로드하기\n",
    "\n",
    "파일을 읽을 때 로딩하고자 하는 칼럼을 지정할 수도 있다. 이는 분석 대상이 아닌 칼럼이 파일에 많은 경우 로드와 세이브에 필요한 시간과 메모리를 절약할 수 있는 유용한 방법이다.  \n",
    "`pd.read_csv(usecols = )` 파라미터로 지정할 수 있으며, 이 파라미터에는 칼럼 이름(헤더에 포함된 칼럼명)이나 오프셋(제로베이스 포지션)의 리스트를 전달하면 된다.  \n",
    "\n",
    "날짜와 종가만 읽어들여 날짜를 인덱스로 사용한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Close\n",
       "Date            \n",
       "7/21/2014  81.93\n",
       "7/18/2014  83.35\n",
       "7/17/2014  83.63\n",
       "7/16/2014  84.91\n",
       "7/15/2014  83.58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data only in the Date and Close columns\n",
    "# and index by the Date column\n",
    "df2 = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", \n",
    "                  usecols= ['Date', 'Close'], \n",
    "                  index_col= ['Date'])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Close\n",
       "Date            \n",
       "7/21/2014  81.93\n",
       "7/18/2014  83.35\n",
       "7/17/2014  83.63\n",
       "7/16/2014  84.91\n",
       "7/15/2014  83.58"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", \n",
    "                  usecols= [0,4], \n",
    "                  index_col= [0])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a DataFrame to a CSV\n",
    "데이터 프레임을 CSV 파일로 저장 \n",
    "\n",
    "`to_csv()` 메서드를 사용하면 `DataFrame`을 cSV 파일로 저장할 수 있다.  \n",
    "\n",
    "이때 `index_label`같이 특정 칼럼을 인덱스 레이블로 지정하는 것이 좋다.  \n",
    "그렇지 않으면 파일의 첫 번째 로우에 인덱스 이름이 포함되지 않으므로, 나중에 이 파일을 읽을 때 어려움이 있을 수 있다.  \n",
    "\n",
    "(추가로, 정수 인덱스가 pandas에서 부여된 상황일 때 `index = False`로 하면 불필요한 인덱스 칼럼이 포함되는 것을 막을 수 있다.)\n",
    "\n",
    "파일이 제대로 저장됐는지 알기 위해 `!head` 명령어로 콘텐츠의 일부를 확인해 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df2 to a new csv file\n",
    "# also specify naming the index as date\n",
    "df2.to_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft_modified.csv\", index_label= 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,Close\r\n",
      "7/21/2014,81.93\r\n",
      "7/18/2014,83.35\r\n",
      "7/17/2014,83.63\r\n",
      "7/16/2014,84.91\r\n"
     ]
    }
   ],
   "source": [
    "# view the start of the file just saved\n",
    "!head -n 5 /Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft_modified.csv\n",
    "#type data/msft_modified.csv # windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General field-delimited data\n",
    "필드 구분ㄴ 데이터로 작업\n",
    "\n",
    "사실 CSV는 필드 구분(field-delimited) 데이터의 특정 형태 중 하나이다.  \n",
    "필드 구분 데이터에서 각 아이템은 기호(구분자)에 의해 구분되며, CSV의 경우 그 기호가 , 인 것이다.  \n",
    "쉽표 대신 파이프(|) 기호를 사용할 수 있으며, 그렇게 구분한 데이터를 파이프 구분(pipe-delimited) 데이터라고 부른다.\n",
    "\n",
    "필드 구분 데이터를 읽기 위해서 `pd.read_table(sep = )` 을 사용할 수 있다. \n",
    "구분자를 지정하여 파일을 읽어올 수 있다.  \n",
    "(CSV파일은 , 로 구분된 필드 구분 데이터이기 때문에 구분자를 쉼표로 지정하고 로드 할 수 있다. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use read_table with sep=',' to read a CSV\n",
    "df = pd.read_table(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", sep= ',')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_table()`이라는 메서드는 없고, `.to_csv(sep = )`으로 지정해 필드 구분 데이터를 저장할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Date|Open|High|Low|Close|Volume\r\n",
      "0|7/21/2014|83.46|83.53|81.81|81.93|2359300\r\n",
      "1|7/18/2014|83.3|83.4|82.52|83.35|4020800\r\n",
      "2|7/17/2014|84.35|84.63|83.33|83.63|1974000\r\n",
      "3|7/16/2014|83.77|84.91|83.66|84.91|1755600\r\n"
     ]
    }
   ],
   "source": [
    "# save as pipe delimited\n",
    "df.to_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft_piped.txt\", sep='|')\n",
    "# check that it worked\n",
    "!head -n 5 /Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft_piped.txt # osx or Linux\n",
    "# type data/psft_piped.txt # on windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling variants of formats in field-delimited data\n",
    "필드 구분 데이터의 다양한 형식 다루기\n",
    "\n",
    "필드 구분 데이터에는 헤더와 푸터가 추가로 포함될 수 있다.  \n",
    "예컨대 헤더에는 기업 정보가 있을 수 있고, 푸터에는 접수 번호, 주소, 요약 등의 있을 수 있다.  \n",
    "또는 줄 사이사이에 그런 데이터가 들어 있을 수도 있다.  \n",
    "`pd.read_csv()`, `pd.read_table()` 메서드에는 그런 상황에 대처할 수 있는 파라미터들이 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is fun because the data does not start on the first line,,,,,\r\n",
      "Date,Open,High,Low,Close,Volume\r\n",
      ",,,,,\r\n",
      "And there is space between the header row and data,,,,,\r\n",
      "7/21/2014,83.46,83.53,81.81,81.93,2359300\r\n",
      "7/18/2014,83.3,83.4,82.52,83.35,4020800\r\n"
     ]
    }
   ],
   "source": [
    "# messy file\n",
    "!head -n 6 /Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft2.csv # osx or Linux\n",
    "# type data/msft2.csv # windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `(skiprows = [])` : 헤더 지우기\n",
    "이런 상황에서 `pd.read_csv(skiprows = [])` 파라미터를 사용할 수 있으며, 0번부터 시작하는 로우 넘버를 사용하여 건너뛰도록 지정할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read, but skip rows 0, 2 and 3\n",
    "df = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft2.csv\", skiprows= [0, 2, 3])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뒤에 콘텐츠가 포함되어있는 경우를 본다면, `!head` 가 아니라 `!cat`으로 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume\r\n",
      "7/21/2014,83.46,83.53,81.81,81.93,2359300\r\n",
      "7/18/2014,83.3,83.4,82.52,83.35,4020800\r\n",
      "\r\n",
      "Uh oh, there is stuff at the end.\r\n"
     ]
    }
   ],
   "source": [
    "# another messy file, with the mess at the end\n",
    "!cat /Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft_with_footer.csv # osx or Linux\n",
    "# type data/msft_with_footer.csv # windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `(skipfooter = [])` : 푸터 지우기\n",
    "\n",
    "이런 경우 `pd.read_csv(skipfooter = )`파라미터에 파일의 마지막 몇 줄을 건너뛸 것인지 지어함으로써 해결할 수 있다. (skip_footer는 지원 중단됨.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip only two lines at the end\n",
    "df = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft_with_footer.csv\", \n",
    "                 skipfooter= 2,\n",
    "                 engine= 'python')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    `engine = 'python' :?\n",
    "    pandas에서 engine 옵션의 기본 값은 'c'인데, 아나콘다는 C엔진을 구현하지 않았다. 따라서 이 옵션을 지정하지 않으면 차선책인 파이썬 엔진이 사용되지만, 그와 동시에 경고 메시지도 나타나게 된다. \n",
    "    \n",
    "### `(nrows = )` : 처음 몇 개의 로우만 불러오기\n",
    "\n",
    "큰 파일에서 첫 몇개의 로우만 로딩하고 싶은 경우 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only process the first three rows\n",
    "pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", nrows= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skiprows` 파라미터를 사용하면 지정한 개수의 로우를 건너뛰고 그 다음 로우만 로딩할 수 있다.  \n",
    "예를 들어 100개의 로우를 건너뛰고, 그 다음 5개 로우만 불러온다면 이렇게 쓸 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close      vol\n",
       "0   3/3/2014  80.35  81.31  79.91  79.97  5004100\n",
       "1  2/28/2014  82.40  83.42  82.17  83.42  2853200\n",
       "2  2/27/2014  84.06  84.63  81.63  82.00  3676800\n",
       "3  2/26/2014  82.92  84.03  82.43  83.81  2623600\n",
       "4  2/25/2014  83.80  83.80  81.72  83.08  3579100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip 100 lines, then only process the next five\n",
    "pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft.csv\", \n",
    "            skiprows= 100, nrows= 5, \n",
    "            header= 0,\n",
    "            names= ['date', 'open', 'high', 'low', \n",
    "                   'close', 'vol']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing data in Excel format\n",
    "엑셀 데이터의 읽기와 쓰기\n",
    "\n",
    "### `pd.read_excel()`\n",
    "pandas는 `pd.read_excel()` 함수나 `ExcelFile` 클래스를 통해 엑셀 2003과 그 이후 버전의 엑셀 데이터 로딩을 지원한다. 내부적으로 두 기술 모두 XLPD나 OPENpyXL 패키지를 사용하므로 파이썬 환경에 둘 중 하나가 설치돼 있어야 한다.  \n",
    "\n",
    "엑셀 파일에는 시트가 나누어 존재하기 때문에 불러오면 첫 번째 워크시트의 콘텐츠만 로딩되게 된다.  \n",
    "만약 다른 워크시트를 로딩하려면 `sheet_name = 'worksheetname' `파라미터에 해당 워크 시트 이름을 전달한다.  \n",
    "(버전의 문제로 sheetname이 아니라 sheet_name 이라고 써야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read excel file\n",
    "# only reads first sheet (msft in this case)\n",
    "df = pd.read_excel(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/stocks.xlsx\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from the aapl worksheet\n",
    "aapl = pd.read_excel(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/stocks.xlsx\", \n",
    "                     sheet_name= 'aapl')\n",
    "aapl[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_csv()`처럼 여기도 pandas가 알아서 칼럼명, 데이터 타입, 인덱스 등을 추론해 적용했다. 그때 사용하던 옵션을 그대로 사용할 수 있다.  \n",
    "\n",
    "\n",
    "### `.to_excel()`, to xls\n",
    "엑셀 파일은 데이터 프레임의 `.to_excel()` 메서드를 사용해 작성할 수 있다. XLS 포맷 작성을 위해서는 XLWT 패키지가 파이썬 환경에 설치돼 있어야 한다.  \n",
    "이미 보유한 데이터 프레임을 저장하는 예시인데, sheet1 으로 자동적으로 저장되게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: XLWT in /Users/Angela/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install XLWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_25595/2780765029.py:2: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/stocks2.xls\")\n"
     ]
    }
   ],
   "source": [
    "# save to an .XLS file, in worksheet 'Sheet1'\n",
    "df.to_excel(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/stocks2.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_25595/294439127.py:2: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/stocks_msft.xls\", sheet_name= 'MSFT')\n"
     ]
    }
   ],
   "source": [
    "# write making the worksheet name MSFT\n",
    "df.to_excel(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/stocks_msft.xls\", sheet_name= 'MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미래의 판다스 패키지에서는 XLWT 가 사라질 것을 경고하고 있다. 그리고 온리 xls 포맷만 지원할 것으로 써있다. XLSX 하일을 쓰려면 openpyxl 을 사용하라는 경고이다. \n",
    "\n",
    "stocks_msft.xls 파일을 열어보면 MSFT 라는 시트 이름으로 데이터가 저장되어 있다! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "둘 이상의 `DataFrame`을 하나의 엑셀 파일에 개별 워크시트로 저장하려면 `with` 키워드롸 함께 `ExcelWriter`를 사용해야 한다.  \n",
    "`ExcelWriter`는 pandas의 일부이긴 하지만, 최상위 네임스페이스에는 속하지 않으므로 반드시 임포트를 해야한다.  \n",
    "\n",
    "다음은 두 개의 ₩DataFrame₩ 객체를 하나의 엑셀 파일에 각각의 워크시트로 저장하는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_25595/2945682119.py:4: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  with ExcelWriter(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/all_stocks.xls\") as writer:\n"
     ]
    }
   ],
   "source": [
    "# write multiple sheets\n",
    "# requires use of the ExcelWriter class\n",
    "from pandas import ExcelWriter\n",
    "with ExcelWriter(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/all_stocks.xls\") as writer:\n",
    "    aapl.to_excel(writer, sheet_name='AAPL')\n",
    "    df.to_excel(writer, sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.to_excel()`, to xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to xlsx\n",
    "df.to_excel(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/msft2.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
