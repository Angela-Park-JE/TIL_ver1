{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DataFrame-구조-다루기\" data-toc-modified-id=\"DataFrame-구조-다루기-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>DataFrame 구조 다루기</a></span></li><li><span><a href=\"#Configuring-pandas\" data-toc-modified-id=\"Configuring-pandas-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Configuring pandas</a></span></li><li><span><a href=\"#Renaming-columns\" data-toc-modified-id=\"Renaming-columns-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Renaming columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#.rename()-메서드\" data-toc-modified-id=\".rename()-메서드-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>.rename()</code> 메서드</a></span></li><li><span><a href=\"#Adding-new-columns-with-[]-and-.insert()\" data-toc-modified-id=\"Adding-new-columns-with-[]-and-.insert()-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Adding new columns with [] and .insert()</a></span><ul class=\"toc-item\"><li><span><a href=\"#[]-로-새-컬럼-추가\" data-toc-modified-id=\"[]-로-새-컬럼-추가-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span><code>[]</code> 로 새 컬럼 추가</a></span></li><li><span><a href=\"#.insert()-메서드로-새-컬럼-추가\" data-toc-modified-id=\".insert()-메서드로-새-컬럼-추가-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span><code>.insert()</code> 메서드로 새 컬럼 추가</a></span></li></ul></li></ul></li><li><span><a href=\"#Adding-columns\" data-toc-modified-id=\"Adding-columns-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Adding columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#.loc[]:-Adding-columns-through-enlargement\" data-toc-modified-id=\".loc[]:-Adding-columns-through-enlargement-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><code>.loc[]</code>: Adding columns through enlargement</a></span><ul class=\"toc-item\"><li><span><a href=\"#.loc[]속성과-슬라이싱을-사용한-칼럼-추가\" data-toc-modified-id=\".loc[]속성과-슬라이싱을-사용한-칼럼-추가-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span><code>.loc[]</code>속성과 슬라이싱을 사용한 칼럼 추가</a></span></li></ul></li><li><span><a href=\"#pd.concat():-Adding-columns-using-concatenation\" data-toc-modified-id=\"pd.concat():-Adding-columns-using-concatenation-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span><code>pd.concat()</code>: Adding columns using concatenation</a></span></li></ul></li><li><span><a href=\"#Reordering-columns\" data-toc-modified-id=\"Reordering-columns-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Reordering columns</a></span></li><li><span><a href=\"#Replacing-the-contents-of-a-column\" data-toc-modified-id=\"Replacing-the-contents-of-a-column-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Replacing the contents of a column</a></span></li><li><span><a href=\"#Deleting-columns\" data-toc-modified-id=\"Deleting-columns-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Deleting columns</a></span></li><li><span><a href=\"#Adding-rows\" data-toc-modified-id=\"Adding-rows-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Adding rows</a></span><ul class=\"toc-item\"><li><span><a href=\"#Appending-rows-from-other-DataFrame-objects-with-.append()\" data-toc-modified-id=\"Appending-rows-from-other-DataFrame-objects-with-.append()-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Appending rows from other DataFrame objects with .append()</a></span></li><li><span><a href=\"#Concatenating-rows\" data-toc-modified-id=\"Concatenating-rows-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Concatenating rows</a></span></li><li><span><a href=\"#Adding-and-replacing-rows-via-setting-with-enlargement\" data-toc-modified-id=\"Adding-and-replacing-rows-via-setting-with-enlargement-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Adding and replacing rows via setting with enlargement</a></span></li></ul></li><li><span><a href=\"#Removing-rows\" data-toc-modified-id=\"Removing-rows-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Removing rows</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removing-rows-using-.drop()\" data-toc-modified-id=\"Removing-rows-using-.drop()-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Removing rows using .drop()</a></span></li><li><span><a href=\"#Removing-rows-using-Boolean-selection\" data-toc-modified-id=\"Removing-rows-using-Boolean-selection-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Removing rows using Boolean selection</a></span></li><li><span><a href=\"#Removing-rows-using-a-slice\" data-toc-modified-id=\"Removing-rows-using-a-slice-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Removing rows using a slice</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame 구조 다루기\n",
    "\n",
    "pandas는 데이터 탐색을 위한 강력한 조작 엔진을 제공한다. 그런 탐색에는 종종 불필요한 데이터 제거, 데이터 포맥 변경, 다른 로우나 칼럼으로부터의 데이터 파생 등 DataFrame 객체의 구조를 조작하는 일이 수반되는데, 이런 것들을 알아보는 챕터.\n",
    "\n",
    "- 칼럼명 변경\n",
    "- `[]`와 `.insert()`를 사용한 칼럼 추가\n",
    "- 확장(enlargemant)를 통한 칼럼 추가\n",
    "- 접합(concatenation)을 통한 칼럼 추가\n",
    "- 칼럼 재배열\n",
    "- 칼럼 콘텐츠 교체 \n",
    "- 칼럼 삭제\n",
    "- 새 로우 추가\n",
    "- 로우 접합\n",
    "- 확장을 통한 로우 추가 및 교체\n",
    "- `.drop()`을 사용한 로우 삭제\n",
    "- 불리언 선택을 통한 로우 삭제\n",
    "- 슬라이싱을 통한 로우 삭제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring pandas\n",
    "\n",
    "셋팅 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "1.22.4\n",
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# used for dates\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set some pandas options controlling output format\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 80)\n",
    "\n",
    "# version check\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "# bring in matplotlib for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the data and print the first five rows\n",
    "# use the Symbol column as the index, and \n",
    "# only read in columns in positions 0, 2, 3, 7\n",
    "sp500 = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/sp500.csv\", \n",
    "                    index_col='Symbol', \n",
    "                    usecols=[0, 2, 3, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming columns\n",
    "칼럼명 변경\n",
    "\n",
    "## `.rename()` 메서드\n",
    "이 메서드는 변경할 칼럼 레이블(key)와 새 이름(value)로 이루어진 딕셔너리 객체를 받는다.  \n",
    "\n",
    "`.rename()`을 사용하면 새 이름의 칼럼과 복사된 데이터를 갖는 새 데이터 프레임이 반환된다. 즉, 원래의 데이터프레임은 변경되지 않는다.  \n",
    "만약 복사본을 만들지 않고 원래 데이터프레임을 수정하려 한다면 `inplace = True` 파라미터를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the Book Value column to not have a space\n",
    "# this returns a copy with the column renamed\n",
    "newSP500 = sp500.rename(columns=\n",
    "                        {'Book Value': 'BookValue'})\n",
    "# print first 2 rows\n",
    "newSP500[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본은 수정되지 않은 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sector', 'Price', 'Book Value'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the columns in the original did not change\n",
    "sp500.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sector', 'Price', 'BookValue'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this changes the column in-place\n",
    "sp500.rename(columns=                  \n",
    "             {'Book Value': 'BookValue'},                   \n",
    "             inplace=True)\n",
    "# we can see the column is changed\n",
    "sp500.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 attribute 방식으로 접근할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM     26.668\n",
       "ABT     15.573\n",
       "ABBV     2.954\n",
       "ACN      8.326\n",
       "ACE     86.897\n",
       "Name: BookValue, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now we can use .BookValue\n",
    "sp500.BookValue[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new columns with [] and .insert()\n",
    "\n",
    "### `[]` 로 새 컬럼 추가\n",
    "\n",
    "반올림을 적용한 가격을 새 칼럼으로 추가해본다. \n",
    "\n",
    "기존 값을 가지고 할 경우, pandas는 해당 칼럼의 데이터를 선택하고, 해당 Series의 모든 값에 적용한 후, 이 새 Series를 DataFrame의 복사본에 정렬시키고 새 칼럼을 추가한다.  \n",
    "새 칼럼은 기존 칼럼 인덱스의 마지막 다음에 추가된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue  RoundedPrice\n",
       "Symbol                                              \n",
       "MMM     Industrials  141.14     26.668         141.0\n",
       "ABT     Health Care   39.60     15.573          40.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy so that we keep the original data unchanged\n",
    "sp500_copy = sp500.copy()\n",
    "# add the new column\n",
    "sp500_copy['RoundedPrice'] = sp500.Price.round()\n",
    "sp500_copy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.insert()` 메서드로 새 컬럼 추가\n",
    "`insert(칼럼포지션, 칼럼이름, 데이터)` 식으로 추가한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector  RoundedPrice   Price  BookValue\n",
       "Symbol                                              \n",
       "MMM     Industrials         141.0  141.14     26.668\n",
       "ABT     Health Care          40.0   39.60     15.573"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy so that we keep the original data unchanged\n",
    "copy = sp500.copy()\n",
    "# insert sp500.Price * 2 as the \n",
    "# second column in the DataFrame\n",
    "copy.insert(1, 'RoundedPrice', sp500.Price.round())\n",
    "copy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding columns\n",
    "\n",
    "## `.loc[]`: Adding columns through enlargement\n",
    "확장을 통한 칼럼 추가\n",
    "\n",
    "### `.loc[]`속성과 슬라이싱을 사용한 칼럼 추가\n",
    "\n",
    "`.loc[:, 컬럼이름] = 데이터`  \n",
    "\n",
    "모든 값을 0으로 초기화한 PER라는 새 칼럼을 데이터프레임에 추가하는 예시이다.  \n",
    "이러한 방식으로 이미 데이터가 존재하는 Series를 추가할 수도 있는데, 이 경우 **정렬 작업이 발생하므로 대상 데이터 프레임과 동일한 인덱스를 사용해야** 한다.  \n",
    "따라서 index는 추가하려는 데이터프레임의 `.index`로 넣을 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue  PER\n",
       "Symbol                                     \n",
       "MMM     Industrials  141.14     26.668    0\n",
       "ABT     Health Care   39.60     15.573    0\n",
       "ABBV    Health Care   53.95      2.954    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of subset / slice\n",
    "ss = sp500[:3].copy()\n",
    "# add the new column initialized to 0\n",
    "ss.loc[:,'PER'] = 0\n",
    "# take a look at the results\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue       PER\n",
       "Symbol                                          \n",
       "MMM     Industrials  141.14     26.668  0.469112\n",
       "ABT     Health Care   39.60     15.573 -0.282863\n",
       "ABBV    Health Care   53.95      2.954 -1.509059"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of subset / slice\n",
    "ss = sp500[:3].copy()\n",
    "# add the new column initialized with random numbers\n",
    "np.random.seed(123456)\n",
    "ss.loc[:,'PER'] = pd.Series(np.random.normal(size=3), index=ss.index)\n",
    "# take a look at the results\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.concat()`: Adding columns using concatenation\n",
    "접합을 통한 칼럼 추가 \n",
    "\n",
    "`[]`연산자와 `.insert()` 메서드는 대상 데이터 프레임을 즉석에서 직접 수정했었다.  \n",
    "그러나 원래의 데이터 프레임은 건드리지 않고 새 데이터 프레임에 칼럼을 추가하고 싶을 때에는 `pd.concat()`함수를 사용하면 된다.  \n",
    "\n",
    "다음 예시 DataFrame은 반올림 주가를 갖는 단일 칼럼의 DataFrame을 만들고,  \n",
    "거기에 `pd.concat()`을 사용하여 sp500과 이 단일 칼럼 데이터 프레임 rounded_price를 칼럼 축을 기준으로 접합하는 방식이다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue  RoundedPrice\n",
       "Symbol                                                         \n",
       "MMM                Industrials  141.14     26.668         141.0\n",
       "ABT                Health Care   39.60     15.573          40.0\n",
       "ABBV               Health Care   53.95      2.954          54.0\n",
       "ACN     Information Technology   79.79      8.326          80.0\n",
       "ACE                 Financials  102.91     86.897         103.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with only the RoundedPrice column\n",
    "rounded_price = pd.DataFrame({'RoundedPrice' : sp500.Price.round()})\n",
    "# concatenate along the 'columns axis'\n",
    "concatenated = pd.concat([sp500, rounded_price], axis = 1)\n",
    "concatenated[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "접합을 한 결과에서는 칼럼명 중복이 가능하다. 시험삼아 rounded_price라는 DataFrame을 price라는 컬럼이름을 가지도록 새로 만들어서 접합해본다.  \n",
    "이때 **같은 이름을 가진 두 칼럼은 해당 이름을 attribute로 호출했을 때 둘 다 모두 가져오게 된다**.  \n",
    "\n",
    "따라서 두 칼럼 중 하나만 선택하고 싶다면 칼럼명 대신 포지션을 사용해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Price\n",
       "Symbol       \n",
       "MMM     141.0\n",
       "ABT      40.0\n",
       "ABBV     54.0\n",
       "ACN      80.0\n",
       "ACE     103.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with only the RoundedPrice column\n",
    "rounded_price = pd.DataFrame({'Price': sp500.Price.round()})\n",
    "rounded_price[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue  Price\n",
       "Symbol                                                  \n",
       "MMM                Industrials  141.14     26.668  141.0\n",
       "ABT                Health Care   39.60     15.573   40.0\n",
       "ABBV               Health Care   53.95      2.954   54.0\n",
       "ACN     Information Technology   79.79      8.326   80.0\n",
       "ACE                 Financials  102.91     86.897  103.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will result in duplicate Price columm\n",
    "dups = pd.concat([sp500, rounded_price], axis=1)\n",
    "dups[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Price  Price\n",
       "Symbol               \n",
       "MMM     141.14  141.0\n",
       "ABT      39.60   40.0\n",
       "ABBV     53.95   54.0\n",
       "ACN      79.79   80.0\n",
       "ACE     102.91  103.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieves both Price columns\n",
    "dups.Price[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM     141.14\n",
       "ABT      39.60\n",
       "ABBV     53.95\n",
       "ACN      79.79\n",
       "ACE     102.91\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose first'Price'\n",
    "dups.iloc[:5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM     141.0\n",
       "ABT      40.0\n",
       "ABBV     54.0\n",
       "ACN      80.0\n",
       "ACE     103.0\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose second 'Price'\n",
    "dups.iloc[:5, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reordering columns\n",
    "칼럼 재배열\n",
    "\n",
    "DataFrame의 사본에서는 원하는 순서로 칼럼을 재배열할 수 있다. 다음은 칼럼을 역순으로 재배열한 예시이다.  \n",
    "\n",
    "배열일 뿐, 사실상 원본 데이터 프레임에서 칼럼의 순서자체를 바꿀 방법은 없다고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        BookValue   Price                  Sector\n",
       "Symbol                                           \n",
       "MMM        26.668  141.14             Industrials\n",
       "ABT        15.573   39.60             Health Care\n",
       "ABBV        2.954   53.95             Health Care\n",
       "ACN         8.326   79.79  Information Technology\n",
       "ACE        86.897  102.91              Financials"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a new DataFrame with the columns reversed\n",
    "reversed_column_names = sp500.columns[::-1]\n",
    "sp500[reversed_column_names][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing the contents of a column\n",
    "칼럼의 콘텐츠 교체\n",
    "\n",
    "`[]` 연산자를 사용해 기존 칼럼에 새 Series를 할당하는 방식으로 교체할 수 있다.  \n",
    "\n",
    "1. attribute 방식을 통해 `copy.Price`에 `rounded_price.Price`를 입힌 결과이다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector  Price  BookValue\n",
       "Symbol                                          \n",
       "MMM                Industrials  141.0     26.668\n",
       "ABT                Health Care   40.0     15.573\n",
       "ABBV               Health Care   54.0      2.954\n",
       "ACN     Information Technology   80.0      8.326\n",
       "ACE                 Financials  103.0     86.897"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this occurs in-place so let's use a copy\n",
    "copy = sp500.copy()\n",
    "# replace the Price column data with the new values\n",
    "# instead of adding a new column\n",
    "copy.Price = rounded_price.Price\n",
    "copy[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 슬라이싱 방식을 통해 할당할 수 있다. 모든 `Price`의 모든 로우를 선택하여 할당하는 식이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector  Price  BookValue\n",
       "Symbol                                          \n",
       "MMM                Industrials  141.0     26.668\n",
       "ABT                Health Care   40.0     15.573\n",
       "ABBV               Health Care   54.0      2.954\n",
       "ACN     Information Technology   80.0      8.326\n",
       "ACE                 Financials  103.0     86.897"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this occurs in-place so let's use a copy\n",
    "copy = sp500.copy()\n",
    "# replace the Price column data wwith rounded values\n",
    "copy.loc[:,'Price'] = rounded_price.Price\n",
    "copy[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting columns\n",
    "칼럼 삭제\n",
    "\n",
    "DataFrame의 `del` 키워드, 또는 `.pop()`이나 `.drop()` 메서드를 사용하면 칼럼을 삭제할 수 있다.\n",
    "동작 방식은 약간씩 다르다. \n",
    "\n",
    "1. `del`은 DataFrame에서 Series를 즉석에서 삭제한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price\n",
       "Symbol                     \n",
       "MMM     Industrials  141.14\n",
       "ABT     Health Care   39.60"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of using del to delete a column\n",
    "# make a copy as this is done in-place\n",
    "copy = sp500.copy()\n",
    "del copy['BookValue']\n",
    "copy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `.pop()`은 즉석에서 Series를 삭제하고, 삭제한 Series를 반환한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Price  BookValue\n",
       "Symbol                   \n",
       "MMM     141.14     26.668\n",
       "ABT      39.60     15.573"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of using pop to remove a column from a DataFrame\n",
    "# first make a copy of a subset of the data frame as\n",
    "# pop works in place\n",
    "copy = sp500.copy()\n",
    "# this will remove Sector and return it as a series\n",
    "popped = copy.pop('Sector')\n",
    "# Sector column removed in-place\n",
    "copy[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM                Industrials\n",
       "ABT                Health Care\n",
       "ABBV               Health Care\n",
       "ACN     Information Technology\n",
       "ACE                 Financials\n",
       "Name: Sector, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we have the Sector column as the result of the pop ('Sector' column)\n",
    "popped[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `.drop(labels, axis = 1)`은 칼럼이 삭제된 새 데이터 프레임을 반환한다. 즉 기존의 DataFrame은 변경되지 않는다.  \n",
    "\n",
    "`drop()` 메서드는 로우 삭제와 칼럼 삭제 모두에 사용할 수 있다. 칼럼을 삭제하기 위해서 반드시 `axis = 1`을 지정해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Price  BookValue\n",
       "Symbol                   \n",
       "MMM     141.14     26.668\n",
       "ABT      39.60     15.573\n",
       "ABBV     53.95      2.954\n",
       "ACN      79.79      8.326\n",
       "ACE     102.91     86.897"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of using drop to remove a column \n",
    "# make a copy of a subset of the data frame\n",
    "copy = sp500.copy()\n",
    "# this will return a new DataFrame with 'Sector’ removed\n",
    "# the copy DataFrame is not modified\n",
    "afterdrop = copy.drop(['Sector'], axis = 1)\n",
    "afterdrop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue\n",
       "Symbol                                           \n",
       "MMM                Industrials  141.14     26.668\n",
       "ABT                Health Care   39.60     15.573\n",
       "ABBV               Health Care   53.95      2.954\n",
       "ACN     Information Technology   79.79      8.326\n",
       "ACE                 Financials  102.91     86.897\n",
       "...                        ...     ...        ...\n",
       "YHOO    Information Technology   35.02     12.768\n",
       "YUM     Consumer Discretionary   74.77      5.147\n",
       "ZMH                Health Care  101.84     37.181\n",
       "ZION                Financials   28.43     30.191\n",
       "ZTS                Health Care   30.53      2.150\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding rows\n",
    "\n",
    "## Appending rows from other DataFrame objects with .append()\n",
    "새 로우 추가\n",
    "\n",
    "로우 추가는 DataFrame의 `.append()` 메서드를 사용한다.  \n",
    "이 메서드는 원래 DataFrame의 마지막 로우 다음에 새 로우가 덧붙여진 새 DataFrame을 반환한다.  \n",
    "로우 추가에는 정렬 작업이 관여되지 않기 때문에 중복된 인덱스가 존재할 수 있다.  \n",
    "\n",
    "아래의 경우 sp500 에서 추출한 df1 과 df2를 붙인 것이데, 포지션 2였던 로우 ('ABBV')가 중복으로 존재하는 것을 볼 수 있다. \n",
    "\n",
    "또한 프레임.append() 메서드는 앞으로 사라질 것이기 때문에 concat을 쓰라는 경고가 함께 뜬다. (python 3.8.5 ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_7832/2175085768.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  appended = df1.append(df2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573\n",
       "ABBV    Health Care   53.95      2.954\n",
       "A       Health Care   56.18     16.928\n",
       "GAS       Utilities   52.98     32.462\n",
       "ABBV    Health Care   53.95      2.954"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the first three rows of sp500\n",
    "df1 = sp500.iloc[0:3].copy()\n",
    "# copy 10th and 11th rows\n",
    "df2 = sp500.iloc[[10, 11, 2]]\n",
    "# append df1 and df2\n",
    "appended = df1.append(df2)\n",
    "# the result is the rows of the first followed by \n",
    "# those of the second\n",
    "appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        PER\n",
       "Symbol     \n",
       "MMM     0.0\n",
       "ABT     0.0\n",
       "ABBV    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data frame using df1.index and just a PER column\n",
    "# also a good example of using a scalar value\n",
    "# to initialize multiple rows\n",
    "df3 = pd.DataFrame(0.0, \n",
    "                   index=df1.index,\n",
    "                   columns=['PER'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        BookValue  PER   Price       Sector\n",
       "Symbol                                     \n",
       "MMM        26.668  NaN  141.14  Industrials\n",
       "ABT        15.573  NaN   39.60  Health Care\n",
       "ABBV        2.954  NaN   53.95  Health Care\n",
       "MMM           NaN  0.0     NaN          NaN\n",
       "ABT           NaN  0.0     NaN          NaN\n",
       "ABBV          NaN  0.0     NaN          NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append df1 and df3\n",
    "# each has three rows, so 6 rows is the result\n",
    "# df1 had no PER column, so NaN from for those rows\n",
    "# df3 had no BookValue, Price or Sector, so NaN's\n",
    "df1.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   BookValue  PER   Price       Sector\n",
       "0     26.668  NaN  141.14  Industrials\n",
       "1     15.573  NaN   39.60  Health Care\n",
       "2      2.954  NaN   53.95  Health Care\n",
       "3        NaN  0.0     NaN          NaN\n",
       "4        NaN  0.0     NaN          NaN\n",
       "5        NaN  0.0     NaN          NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore index labels, create default index\n",
    "df1.append(df3, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
