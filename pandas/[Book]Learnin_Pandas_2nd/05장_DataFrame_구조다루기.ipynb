{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DataFrame-구조-다루기\" data-toc-modified-id=\"DataFrame-구조-다루기-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>DataFrame 구조 다루기</a></span></li><li><span><a href=\"#Configuring-pandas\" data-toc-modified-id=\"Configuring-pandas-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Configuring pandas</a></span></li><li><span><a href=\"#Renaming-columns\" data-toc-modified-id=\"Renaming-columns-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Renaming columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#.rename()-메서드\" data-toc-modified-id=\".rename()-메서드-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>.rename()</code> 메서드</a></span></li><li><span><a href=\"#Adding-new-columns-with-[]-and-.insert()\" data-toc-modified-id=\"Adding-new-columns-with-[]-and-.insert()-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Adding new columns with [] and .insert()</a></span><ul class=\"toc-item\"><li><span><a href=\"#[]-로-새-컬럼-추가\" data-toc-modified-id=\"[]-로-새-컬럼-추가-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span><code>[]</code> 로 새 컬럼 추가</a></span></li><li><span><a href=\"#.insert()-메서드로-새-컬럼-추가\" data-toc-modified-id=\".insert()-메서드로-새-컬럼-추가-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span><code>.insert()</code> 메서드로 새 컬럼 추가</a></span></li></ul></li></ul></li><li><span><a href=\"#Adding-columns\" data-toc-modified-id=\"Adding-columns-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Adding columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#.loc[]:-Adding-columns-through-enlargement\" data-toc-modified-id=\".loc[]:-Adding-columns-through-enlargement-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><code>.loc[]</code>: Adding columns through enlargement</a></span><ul class=\"toc-item\"><li><span><a href=\"#.loc[]속성과-슬라이싱을-사용한-칼럼-추가\" data-toc-modified-id=\".loc[]속성과-슬라이싱을-사용한-칼럼-추가-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span><code>.loc[]</code>속성과 슬라이싱을 사용한 칼럼 추가</a></span></li></ul></li><li><span><a href=\"#pd.concat():-Adding-columns-using-concatenation\" data-toc-modified-id=\"pd.concat():-Adding-columns-using-concatenation-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span><code>pd.concat()</code>: Adding columns using concatenation</a></span></li></ul></li><li><span><a href=\"#Reordering-columns\" data-toc-modified-id=\"Reordering-columns-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Reordering columns</a></span></li><li><span><a href=\"#Replacing-the-contents-of-a-column\" data-toc-modified-id=\"Replacing-the-contents-of-a-column-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Replacing the contents of a column</a></span></li><li><span><a href=\"#Deleting-columns\" data-toc-modified-id=\"Deleting-columns-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Deleting columns</a></span></li><li><span><a href=\"#Adding-rows\" data-toc-modified-id=\"Adding-rows-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Adding rows</a></span><ul class=\"toc-item\"><li><span><a href=\"#Appending-rows-from-other-DataFrame-objects-with-.append()\" data-toc-modified-id=\"Appending-rows-from-other-DataFrame-objects-with-.append()-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Appending rows from other DataFrame objects with .append()</a></span><ul class=\"toc-item\"><li><span><a href=\"#.append(ignore_index-=-True)\" data-toc-modified-id=\".append(ignore_index-=-True)-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>.append(ignore_index = True)</a></span></li></ul></li><li><span><a href=\"#.concat([DataFrame1,-DataFrame2,-...])-:-Concatenating-rows\" data-toc-modified-id=\".concat([DataFrame1,-DataFrame2,-...])-:-Concatenating-rows-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span><code>.concat([DataFrame1, DataFrame2, ...])</code> : Concatenating rows</a></span><ul class=\"toc-item\"><li><span><a href=\"#pd.concat(keys-=-[DataFrame1,-DataFrame2,...])\" data-toc-modified-id=\"pd.concat(keys-=-[DataFrame1,-DataFrame2,...])-8.2.1\"><span class=\"toc-item-num\">8.2.1&nbsp;&nbsp;</span><code>pd.concat(keys = [DataFrame1, DataFrame2,...])</code></a></span></li><li><span><a href=\"#DataFrame.loc[index_label]-=-[values...]:-Adding-and-replacing-rows-via-setting-with-enlargement\" data-toc-modified-id=\"DataFrame.loc[index_label]-=-[values...]:-Adding-and-replacing-rows-via-setting-with-enlargement-8.2.2\"><span class=\"toc-item-num\">8.2.2&nbsp;&nbsp;</span><code>DataFrame.loc[index_label] = [values...]</code>: Adding and replacing rows via setting with enlargement</a></span></li></ul></li></ul></li><li><span><a href=\"#Removing-rows\" data-toc-modified-id=\"Removing-rows-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Removing rows</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removing-rows-using-.drop()\" data-toc-modified-id=\"Removing-rows-using-.drop()-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Removing rows using .drop()</a></span></li><li><span><a href=\"#Removing-rows-using-Boolean-selection\" data-toc-modified-id=\"Removing-rows-using-Boolean-selection-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Removing rows using Boolean selection</a></span></li><li><span><a href=\"#Removing(select-and-copy)-rows-using-a-slice\" data-toc-modified-id=\"Removing(select-and-copy)-rows-using-a-slice-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Removing(select and copy) rows using a slice</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame 구조 다루기\n",
    "\n",
    "pandas는 데이터 탐색을 위한 강력한 조작 엔진을 제공한다. 그런 탐색에는 종종 불필요한 데이터 제거, 데이터 포맥 변경, 다른 로우나 칼럼으로부터의 데이터 파생 등 DataFrame 객체의 구조를 조작하는 일이 수반되는데, 이런 것들을 알아보는 챕터.\n",
    "\n",
    "- 칼럼명 변경\n",
    "- `[]`와 `.insert()`를 사용한 칼럼 추가\n",
    "- 확장(enlargemant)를 통한 칼럼 추가\n",
    "- 접합(concatenation)을 통한 칼럼 추가\n",
    "- 칼럼 재배열\n",
    "- 칼럼 콘텐츠 교체 \n",
    "- 칼럼 삭제\n",
    "- 새 로우 추가\n",
    "- 로우 접합\n",
    "- 확장을 통한 로우 추가 및 교체\n",
    "- `.drop()`을 사용한 로우 삭제\n",
    "- 불리언 선택을 통한 로우 삭제\n",
    "- 슬라이싱을 통한 로우 삭제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring pandas\n",
    "\n",
    "셋팅 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "1.22.4\n",
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# used for dates\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Set some pandas options controlling output format\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 80)\n",
    "\n",
    "# version check\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "# bring in matplotlib for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the data and print the first five rows\n",
    "# use the Symbol column as the index, and \n",
    "# only read in columns in positions 0, 2, 3, 7\n",
    "sp500 = pd.read_csv(\"/Users/Angela/Desktop/Personal/Learning-Pandas-Second-Edition-master/data/sp500.csv\", \n",
    "                    index_col='Symbol', \n",
    "                    usecols=[0, 2, 3, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming columns\n",
    "칼럼명 변경\n",
    "\n",
    "## `.rename()` 메서드\n",
    "이 메서드는 변경할 칼럼 레이블(key)와 새 이름(value)로 이루어진 딕셔너리 객체를 받는다.  \n",
    "\n",
    "`.rename()`을 사용하면 새 이름의 칼럼과 복사된 데이터를 갖는 새 데이터 프레임이 반환된다. 즉, 원래의 데이터프레임은 변경되지 않는다.  \n",
    "만약 복사본을 만들지 않고 원래 데이터프레임을 수정하려 한다면 `inplace = True` 파라미터를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the Book Value column to not have a space\n",
    "# this returns a copy with the column renamed\n",
    "newSP500 = sp500.rename(columns=\n",
    "                        {'Book Value': 'BookValue'})\n",
    "# print first 2 rows\n",
    "newSP500[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본은 수정되지 않은 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sector', 'Price', 'Book Value'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the columns in the original did not change\n",
    "sp500.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sector', 'Price', 'BookValue'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this changes the column in-place\n",
    "sp500.rename(columns=                  \n",
    "             {'Book Value': 'BookValue'},                   \n",
    "             inplace=True)\n",
    "# we can see the column is changed\n",
    "sp500.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 attribute 방식으로 접근할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM     26.668\n",
       "ABT     15.573\n",
       "ABBV     2.954\n",
       "ACN      8.326\n",
       "ACE     86.897\n",
       "Name: BookValue, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now we can use .BookValue\n",
    "sp500.BookValue[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new columns with [] and .insert()\n",
    "\n",
    "### `[]` 로 새 컬럼 추가\n",
    "\n",
    "반올림을 적용한 가격을 새 칼럼으로 추가해본다. \n",
    "\n",
    "기존 값을 가지고 할 경우, pandas는 해당 칼럼의 데이터를 선택하고, 해당 Series의 모든 값에 적용한 후, 이 새 Series를 DataFrame의 복사본에 정렬시키고 새 칼럼을 추가한다.  \n",
    "새 칼럼은 기존 칼럼 인덱스의 마지막 다음에 추가된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue  RoundedPrice\n",
       "Symbol                                              \n",
       "MMM     Industrials  141.14     26.668         141.0\n",
       "ABT     Health Care   39.60     15.573          40.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy so that we keep the original data unchanged\n",
    "sp500_copy = sp500.copy()\n",
    "# add the new column\n",
    "sp500_copy['RoundedPrice'] = sp500.Price.round()\n",
    "sp500_copy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.insert()` 메서드로 새 컬럼 추가\n",
    "`insert(칼럼포지션, 칼럼이름, 데이터)` 식으로 추가한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector  RoundedPrice   Price  BookValue\n",
       "Symbol                                              \n",
       "MMM     Industrials         141.0  141.14     26.668\n",
       "ABT     Health Care          40.0   39.60     15.573"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy so that we keep the original data unchanged\n",
    "copy = sp500.copy()\n",
    "# insert sp500.Price * 2 as the \n",
    "# second column in the DataFrame\n",
    "copy.insert(1, 'RoundedPrice', sp500.Price.round())\n",
    "copy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding columns\n",
    "\n",
    "## `.loc[]`: Adding columns through enlargement\n",
    "확장을 통한 칼럼 추가\n",
    "\n",
    "### `.loc[]`속성과 슬라이싱을 사용한 칼럼 추가\n",
    "\n",
    "`.loc[:, 컬럼이름] = 데이터`  \n",
    "\n",
    "모든 값을 0으로 초기화한 PER라는 새 칼럼을 데이터프레임에 추가하는 예시이다.  \n",
    "이러한 방식으로 이미 데이터가 존재하는 Series를 추가할 수도 있는데, 이 경우 **정렬 작업이 발생하므로 대상 데이터 프레임과 동일한 인덱스를 사용해야** 한다.  \n",
    "따라서 index는 추가하려는 데이터프레임의 `.index`로 넣을 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue  PER\n",
       "Symbol                                     \n",
       "MMM     Industrials  141.14     26.668    0\n",
       "ABT     Health Care   39.60     15.573    0\n",
       "ABBV    Health Care   53.95      2.954    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of subset / slice\n",
    "ss = sp500[:3].copy()\n",
    "# add the new column initialized to 0\n",
    "ss.loc[:,'PER'] = 0\n",
    "# take a look at the results\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue       PER\n",
       "Symbol                                          \n",
       "MMM     Industrials  141.14     26.668  0.469112\n",
       "ABT     Health Care   39.60     15.573 -0.282863\n",
       "ABBV    Health Care   53.95      2.954 -1.509059"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of subset / slice\n",
    "ss = sp500[:3].copy()\n",
    "# add the new column initialized with random numbers\n",
    "np.random.seed(123456)\n",
    "ss.loc[:,'PER'] = pd.Series(np.random.normal(size=3), index=ss.index)\n",
    "# take a look at the results\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.concat()`: Adding columns using concatenation\n",
    "접합을 통한 칼럼 추가 \n",
    "\n",
    "`[]`연산자와 `.insert()` 메서드는 대상 데이터 프레임을 즉석에서 직접 수정했었다.  \n",
    "그러나 원래의 데이터 프레임은 건드리지 않고 새 데이터 프레임에 칼럼을 추가하고 싶을 때에는 `pd.concat()`함수를 사용하면 된다.  \n",
    "\n",
    "다음 예시 DataFrame은 반올림 주가를 갖는 단일 칼럼의 DataFrame을 만들고,  \n",
    "거기에 `pd.concat()`을 사용하여 sp500과 이 단일 칼럼 데이터 프레임 rounded_price를 칼럼 축을 기준으로 접합하는 방식이다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue  RoundedPrice\n",
       "Symbol                                                         \n",
       "MMM                Industrials  141.14     26.668         141.0\n",
       "ABT                Health Care   39.60     15.573          40.0\n",
       "ABBV               Health Care   53.95      2.954          54.0\n",
       "ACN     Information Technology   79.79      8.326          80.0\n",
       "ACE                 Financials  102.91     86.897         103.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with only the RoundedPrice column\n",
    "rounded_price = pd.DataFrame({'RoundedPrice' : sp500.Price.round()})\n",
    "# concatenate along the 'columns axis'\n",
    "concatenated = pd.concat([sp500, rounded_price], axis = 1)\n",
    "concatenated[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "접합을 한 결과에서는 칼럼명 중복이 가능하다. 시험삼아 rounded_price라는 DataFrame을 price라는 컬럼이름을 가지도록 새로 만들어서 접합해본다.  \n",
    "이때 **같은 이름을 가진 두 칼럼은 해당 이름을 attribute로 호출했을 때 둘 다 모두 가져오게 된다**.  \n",
    "\n",
    "따라서 두 칼럼 중 하나만 선택하고 싶다면 칼럼명 대신 포지션을 사용해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Price\n",
       "Symbol       \n",
       "MMM     141.0\n",
       "ABT      40.0\n",
       "ABBV     54.0\n",
       "ACN      80.0\n",
       "ACE     103.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with only the RoundedPrice column\n",
    "rounded_price = pd.DataFrame({'Price': sp500.Price.round()})\n",
    "rounded_price[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue  Price\n",
       "Symbol                                                  \n",
       "MMM                Industrials  141.14     26.668  141.0\n",
       "ABT                Health Care   39.60     15.573   40.0\n",
       "ABBV               Health Care   53.95      2.954   54.0\n",
       "ACN     Information Technology   79.79      8.326   80.0\n",
       "ACE                 Financials  102.91     86.897  103.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will result in duplicate Price columm\n",
    "dups = pd.concat([sp500, rounded_price], axis=1)\n",
    "dups[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Price  Price\n",
       "Symbol               \n",
       "MMM     141.14  141.0\n",
       "ABT      39.60   40.0\n",
       "ABBV     53.95   54.0\n",
       "ACN      79.79   80.0\n",
       "ACE     102.91  103.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieves both Price columns\n",
    "dups.Price[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM     141.14\n",
       "ABT      39.60\n",
       "ABBV     53.95\n",
       "ACN      79.79\n",
       "ACE     102.91\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose first'Price'\n",
    "dups.iloc[:5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM     141.0\n",
       "ABT      40.0\n",
       "ABBV     54.0\n",
       "ACN      80.0\n",
       "ACE     103.0\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose second 'Price'\n",
    "dups.iloc[:5, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reordering columns\n",
    "칼럼 재배열\n",
    "\n",
    "DataFrame의 사본에서는 원하는 순서로 칼럼을 재배열할 수 있다. 다음은 칼럼을 역순으로 재배열한 예시이다.  \n",
    "\n",
    "배열일 뿐, 사실상 원본 데이터 프레임에서 칼럼의 순서자체를 바꿀 방법은 없다고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        BookValue   Price                  Sector\n",
       "Symbol                                           \n",
       "MMM        26.668  141.14             Industrials\n",
       "ABT        15.573   39.60             Health Care\n",
       "ABBV        2.954   53.95             Health Care\n",
       "ACN         8.326   79.79  Information Technology\n",
       "ACE        86.897  102.91              Financials"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a new DataFrame with the columns reversed\n",
    "reversed_column_names = sp500.columns[::-1]\n",
    "sp500[reversed_column_names][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing the contents of a column\n",
    "칼럼의 콘텐츠 교체\n",
    "\n",
    "`[]` 연산자를 사용해 기존 칼럼에 새 Series를 할당하는 방식으로 교체할 수 있다.  \n",
    "\n",
    "1. attribute 방식을 통해 `copy.Price`에 `rounded_price.Price`를 입힌 결과이다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector  Price  BookValue\n",
       "Symbol                                          \n",
       "MMM                Industrials  141.0     26.668\n",
       "ABT                Health Care   40.0     15.573\n",
       "ABBV               Health Care   54.0      2.954\n",
       "ACN     Information Technology   80.0      8.326\n",
       "ACE                 Financials  103.0     86.897"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this occurs in-place so let's use a copy\n",
    "copy = sp500.copy()\n",
    "# replace the Price column data with the new values\n",
    "# instead of adding a new column\n",
    "copy.Price = rounded_price.Price\n",
    "copy[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 슬라이싱 방식을 통해 할당할 수 있다. 모든 `Price`의 모든 로우를 선택하여 할당하는 식이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector  Price  BookValue\n",
       "Symbol                                          \n",
       "MMM                Industrials  141.0     26.668\n",
       "ABT                Health Care   40.0     15.573\n",
       "ABBV               Health Care   54.0      2.954\n",
       "ACN     Information Technology   80.0      8.326\n",
       "ACE                 Financials  103.0     86.897"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this occurs in-place so let's use a copy\n",
    "copy = sp500.copy()\n",
    "# replace the Price column data wwith rounded values\n",
    "copy.loc[:,'Price'] = rounded_price.Price\n",
    "copy[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting columns\n",
    "칼럼 삭제\n",
    "\n",
    "DataFrame의 `del` 키워드, 또는 `.pop()`이나 `.drop()` 메서드를 사용하면 칼럼을 삭제할 수 있다.\n",
    "동작 방식은 약간씩 다르다. \n",
    "\n",
    "1. `del`은 DataFrame에서 Series를 즉석에서 삭제한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price\n",
       "Symbol                     \n",
       "MMM     Industrials  141.14\n",
       "ABT     Health Care   39.60"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of using del to delete a column\n",
    "# make a copy as this is done in-place\n",
    "copy = sp500.copy()\n",
    "del copy['BookValue']\n",
    "copy[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `.pop()`은 즉석에서 Series를 삭제하고, 삭제한 Series를 반환한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Price  BookValue\n",
       "Symbol                   \n",
       "MMM     141.14     26.668\n",
       "ABT      39.60     15.573"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of using pop to remove a column from a DataFrame\n",
    "# first make a copy of a subset of the data frame as\n",
    "# pop works in place\n",
    "copy = sp500.copy()\n",
    "# this will remove Sector and return it as a series\n",
    "popped = copy.pop('Sector')\n",
    "# Sector column removed in-place\n",
    "copy[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "MMM                Industrials\n",
       "ABT                Health Care\n",
       "ABBV               Health Care\n",
       "ACN     Information Technology\n",
       "ACE                 Financials\n",
       "Name: Sector, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we have the Sector column as the result of the pop ('Sector' column)\n",
    "popped[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `.drop(labels, axis = 1)`은 칼럼이 삭제된 새 데이터 프레임을 반환한다. 즉 기존의 DataFrame은 변경되지 않는다.  \n",
    "\n",
    "`drop()` 메서드는 로우 삭제와 칼럼 삭제 모두에 사용할 수 있다. 칼럼을 삭제하기 위해서 반드시 `axis = 1`을 지정해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Price  BookValue\n",
       "Symbol                   \n",
       "MMM     141.14     26.668\n",
       "ABT      39.60     15.573\n",
       "ABBV     53.95      2.954\n",
       "ACN      79.79      8.326\n",
       "ACE     102.91     86.897"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of using drop to remove a column \n",
    "# make a copy of a subset of the data frame\n",
    "copy = sp500.copy()\n",
    "# this will return a new DataFrame with 'Sector’ removed\n",
    "# the copy DataFrame is not modified\n",
    "afterdrop = copy.drop(['Sector'], axis = 1)\n",
    "afterdrop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue\n",
       "Symbol                                           \n",
       "MMM                Industrials  141.14     26.668\n",
       "ABT                Health Care   39.60     15.573\n",
       "ABBV               Health Care   53.95      2.954\n",
       "ACN     Information Technology   79.79      8.326\n",
       "ACE                 Financials  102.91     86.897\n",
       "...                        ...     ...        ...\n",
       "YHOO    Information Technology   35.02     12.768\n",
       "YUM     Consumer Discretionary   74.77      5.147\n",
       "ZMH                Health Care  101.84     37.181\n",
       "ZION                Financials   28.43     30.191\n",
       "ZTS                Health Care   30.53      2.150\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding rows\n",
    "\n",
    "## Appending rows from other DataFrame objects with .append()\n",
    "새 로우 추가\n",
    "\n",
    "로우 추가는 DataFrame의 `.append()` 메서드를 사용한다.  \n",
    "이 메서드는 원래 DataFrame의 마지막 로우 다음에 새 로우가 덧붙여진 새 DataFrame을 반환한다.  \n",
    "**로우 추가에는 정렬 작업이 관여되지 않기 때문에 중복된 인덱스가 존재할 수 있다.**  \n",
    "\n",
    "아래의 경우 sp500 에서 추출한 df1 과 df2를 붙인 것이데, 포지션 2였던 로우 ('ABBV')가 중복으로 존재하는 것을 볼 수 있다. \n",
    "\n",
    "    또한 프레임.append() 메서드는 앞으로 사라질 것이기 때문에 concat을 쓰라는 경고가 함께 뜬다. (python 3.8.5 ver)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_67373/3555563576.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  appended = df1.append(df2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573\n",
       "ABBV    Health Care   53.95      2.954\n",
       "A       Health Care   56.18     16.928\n",
       "GAS       Utilities   52.98     32.462\n",
       "ABBV    Health Care   53.95      2.954"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the first three rows of sp500\n",
    "df1 = sp500.iloc[0:3].copy()\n",
    "# copy 10th and 11th rows\n",
    "df2 = sp500.iloc[[10, 11, 2]]\n",
    "\n",
    "# index 2 is duplicated\n",
    "# append df1 and df2\n",
    "appended = df1.append(df2)\n",
    "# the result is the rows of the first followed by \n",
    "# those of the second\n",
    "appended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row 방향으로 붙이려는 두 DataFrame 객체의 칼럼 셋이 동일할 필요는 없다.  \n",
    "붙이고 난 후의 데이터 프레임은 두 객체에 있는 칼럼 셋을 모두 포함하며, 누락된 칼럼은 `NaN` 으로 채워진다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        PER\n",
       "Symbol     \n",
       "MMM     0.0\n",
       "ABT     0.0\n",
       "ABBV    0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data frame using df1.index and just a PER column\n",
    "# also a good example of using a scalar value\n",
    "# to initialize multiple rows\n",
    "df3 = pd.DataFrame(0.0, \n",
    "                   index=df1.index,\n",
    "                   columns=['PER'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_67373/3943592431.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1.append(df3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue  PER\n",
       "Symbol                                     \n",
       "MMM     Industrials  141.14     26.668  NaN\n",
       "ABT     Health Care   39.60     15.573  NaN\n",
       "ABBV    Health Care   53.95      2.954  NaN\n",
       "MMM             NaN     NaN        NaN  0.0\n",
       "ABT             NaN     NaN        NaN  0.0\n",
       "ABBV            NaN     NaN        NaN  0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append df1 and df3\n",
    "# each has three rows, so 6 rows is the result\n",
    "# df1 had no PER column, so NaN from for those rows\n",
    "# df3 had no BookValue, Price or Sector, so NaN's\n",
    "df1.append(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .append(ignore_index = True)\n",
    "\n",
    "`ignore_index = True` 파라미터를 사용하면 DataFrame의 인덱스를 보존하지 않고 붙인다.  \n",
    "이는 인덱스 레이블의 의미가 그다지 중요하지 않을 때 유용하며, 대신 순차적으로 증가하는 정수가 인덱스로 사용된다.  \n",
    "이 케이스의 경우 인덱스가 종목코드이기 때문에 중요하지만 그렇지 않을 때, 새로 이용할 데이터프레임을 만드는 과정이면 유용할 수 있다고 생각한다. \n",
    "\n",
    "아래 결과를 보면 데이터 프레임이 기본적으로 RangeIndex를 사용하며, 원래의 Symbol 인덱스는 사라졌다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/j72d9nwn5dq0vxtqtw2bbtnh0000gp/T/ipykernel_67373/345374009.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1.append(df3, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        Sector   Price  BookValue  PER\n",
       "0  Industrials  141.14     26.668  NaN\n",
       "1  Health Care   39.60     15.573  NaN\n",
       "2  Health Care   53.95      2.954  NaN\n",
       "3          NaN     NaN        NaN  0.0\n",
       "4          NaN     NaN        NaN  0.0\n",
       "5          NaN     NaN        NaN  0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore index labels, create default index\n",
    "df1.append(df3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.concat([DataFrame1, DataFrame2, ...])` : Concatenating rows\n",
    "로우 접합\n",
    "\n",
    "여러 DataFrame 객체의 로우는 `axis = 0` 파라미터와 함께 `pd.concat()`함수를 사용하여 접합시킬 수 있다. \n",
    "\n",
    "`pd.concat()` 옵션을 기본값으로 사용하면 두 DataFrame 객체를 로우 기준으로 접합시킨다. 즉 `.append()`메소드와 동일한 역할을 한다. \n",
    "\n",
    "방금 위의 케이스들을 `pd.concat()`으로 구성해본다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573\n",
       "ABBV    Health Care   53.95      2.954\n",
       "A       Health Care   56.18     16.928\n",
       "GAS       Utilities   52.98     32.462\n",
       "ABBV    Health Care   53.95      2.954"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the first three rows of sp500\n",
    "df1 = sp500.iloc[0:3].copy()\n",
    "# copy 10th and 11th rows\n",
    "df2 = sp500.iloc[[10, 11, 2]]\n",
    "# pass them as a list\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로, 접합시키는 DataFrame 각각에 서로 없는 칼럼 셋은 모든 칼럼을 포함시키며 없는 값을 `NaN` 으로 처리한다. \n",
    "\n",
    "아래는 df2에 'Foo' 라는 새 칼럼을 추가하고 이를 이 칼럼이 없는 df1와 합쳐본다.  \n",
    "원래 객체의 로우가 있는 그대로 복사되기 때문에, 그 결과 인덱스 레이블은 중복될 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector  Price  BookValue  Foo\n",
       "Symbol                                    \n",
       "A       Health Care  56.18     16.928    0\n",
       "GAS       Utilities  52.98     32.462    0\n",
       "ABBV    Health Care  53.95      2.954    0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy df2\n",
    "df2_2 = df2.copy()\n",
    "# add a column to df2_2 that is not in df1\n",
    "df2_2.insert(3, 'Foo', pd.Series(0, index=df2.index))\n",
    "# see what it looks like\n",
    "df2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue  Foo\n",
       "Symbol                                     \n",
       "MMM     Industrials  141.14     26.668  NaN\n",
       "ABT     Health Care   39.60     15.573  NaN\n",
       "ABBV    Health Care   53.95      2.954  NaN\n",
       "A       Health Care   56.18     16.928  0.0\n",
       "GAS       Utilities   52.98     32.462  0.0\n",
       "ABBV    Health Care   53.95      2.954  0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now concatenate\n",
    "pd.concat([df1, df2_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pd.concat(keys = [DataFrame1, DataFrame2,...])`\n",
    "`keys` 파라미터를 사용하면 로우의 셋이 어느 데이터 프레임으로부터 왔는지 구별할 수 있도록 표기한다.  \n",
    "원래의 객체 이름을 인덱스에 추가로 표시하게 된다.  \n",
    "\n",
    "    이렇게 표시되는 것을 계층형 인덱스(hierarchical index)라고 하는데, 이에 대한 것은 6장에서 더 자세히 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 Sector   Price  BookValue  Foo\n",
       "    Symbol                                     \n",
       "df1 MMM     Industrials  141.14     26.668  NaN\n",
       "    ABT     Health Care   39.60     15.573  NaN\n",
       "    ABBV    Health Care   53.95      2.954  NaN\n",
       "df2 A       Health Care   56.18     16.928  0.0\n",
       "    GAS       Utilities   52.98     32.462  0.0\n",
       "    ABBV    Health Care   53.95      2.954  0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify keys\n",
    "r = pd.concat([df1, df2_2], keys=['df1', 'df2'])\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame.loc[index_label] = [values...]`: Adding and replacing rows via setting with enlargement\n",
    "확장을 통한 로우 추가 및 교체\n",
    "\n",
    "`.loc` 속성을 사용하여 데이터 프레임에 로우를 추가할 수도 있다.  \n",
    "`.loc[]`에는 로우가 위치해야할 인덱스 레이블을 파라미터로 전달한다.  \n",
    "지정한 레이블이 존재하지 않을 경우에는 그 레이블을 사용해 마지막 로우 다음에 붙여진다.  \n",
    "지정한 레이블이 존재할 경우에는 기존 로우의 값이 교체된다.  \n",
    "\n",
    "`DataFrame.loc[인덱스 레이블] = [각 칼럼의 값]`으로 추가하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573\n",
       "ABBV    Health Care   53.95      2.954\n",
       "FOO      the sector  100.00    110.000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a small subset of the sp500 \n",
    "# make sure to copy the slice to make a copy\n",
    "ss = sp500[:3].copy()\n",
    "# create a new row with index label FOO\n",
    "# and assign some values to the columns via a list\n",
    "ss.loc['FOO'] = ['the sector', 100, 110]\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 `.iloc[]` 로도 추가할 수 있을까? : NO.  \n",
    "`iloc cannot enlarge its target object` 라는 traceback을 반환한다.  \n",
    "\n",
    "그렇다면 교체는 가능할까? : YES.\n",
    "있는 위치의 RangeIndex를 선택하여 바꿀 수 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "iloc cannot enlarge its target object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ss2 \u001b[38;5;241m=\u001b[39m sp500[:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 2\u001b[0m ss2\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe sector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m110\u001b[39m]\n\u001b[1;32m      3\u001b[0m ss2\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages/pandas/core/indexing.py:713\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    711\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m    712\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_setitem_indexer(key)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_valid_setitem_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m    716\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages/pandas/core/indexing.py:1413\u001b[0m, in \u001b[0;36m_iLocIndexer._has_valid_setitem_indexer\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(i):\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ax):\n\u001b[0;32m-> 1413\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: iloc cannot enlarge its target object"
     ]
    }
   ],
   "source": [
    "ss2 = sp500[:3].copy()\n",
    "ss2.iloc[3] = ['the sector', 100, 110]\n",
    "ss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573\n",
       "ABBV     the sector  100.00    110.000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss3 = sp500[:3].copy()\n",
    "ss3.iloc[2] = ['the sector', 100, 110]\n",
    "ss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing rows \n",
    "## Removing rows using .drop()\n",
    "`.drop()`을 사용한 로우 삭제\n",
    "\n",
    "`.drop()` 메소드는 DataFrame의 로우를 삭제할 때 사용한다. (물론 칼럼을 사용할 때도 사용가능)  \n",
    "삭제할 로우의 인덱스 레이블 목록을 받으며, 그 로우가 삭제된 DataFrame의 사본을 반환한다.  \n",
    "(이말은, `inplace = True` 파라미터를 사용하지 않으면 원래의 데이터프레임은 그대로 남아있다. 이 파라미터를 사용하면 원본에서도 삭제된 것으롭 변경된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue\n",
       "Symbol                                           \n",
       "MMM                Industrials  141.14     26.668\n",
       "ABT                Health Care   39.60     15.573\n",
       "ABBV               Health Care   53.95      2.954\n",
       "ACN     Information Technology   79.79      8.326\n",
       "ACE                 Financials  102.91     86.897"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a copy of the first 5 rows of sp500\n",
    "ss = sp500[:5]\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABBV    Health Care   53.95      2.954\n",
       "ACE      Financials  102.91     86.897"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with labels ABT and ACN\n",
    "afterdrop = ss.drop(['ABT', 'ACN'])\n",
    "afterdrop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue\n",
       "Symbol                                           \n",
       "MMM                Industrials  141.14     26.668\n",
       "ABT                Health Care   39.60     15.573\n",
       "ABBV               Health Care   53.95      2.954\n",
       "ACN     Information Technology   79.79      8.326\n",
       "ACE                 Financials  102.91     86.897"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing rows using Boolean selection\n",
    "불리언 선택을 통한 로우 삭제 \n",
    "\n",
    "불리언 선택을 활용하여 DataFrame의 로우를 삭제할 수 있다.  \n",
    "불리언 선택은 논리식의 결과가 True인 로우의 사본을 반환하는데, 로우를 삭제하려면 삭제하고자 하는 로우가 False가 되도록 논리식을 작성하여 데이터 프레임이 적용하면 된다.  \n",
    "\n",
    "Price가 300 보다 큰 것을 선택하여 삭제하려면, 우선 큰 것들을 선택하는 조건식을 만든다. `sum()`을 활용하면 총 10개의 로우인 것을 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the rows where Price > 300\n",
    "selection = sp500.Price > 300\n",
    "# report number of rows and number that will be dropped\n",
    "(len(selection), selection.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 조건의 반대가 되는 서브셋을 가져오도록 `~`을 활용하여 가져온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Sector   Price  BookValue\n",
       "Symbol                                           \n",
       "MMM                Industrials  141.14     26.668\n",
       "ABT                Health Care   39.60     15.573\n",
       "ABBV               Health Care   53.95      2.954\n",
       "ACN     Information Technology   79.79      8.326\n",
       "ACE                 Financials  102.91     86.897\n",
       "...                        ...     ...        ...\n",
       "YHOO    Information Technology   35.02     12.768\n",
       "YUM     Consumer Discretionary   74.77      5.147\n",
       "ZMH                Health Care  101.84     37.181\n",
       "ZION                Financials   28.43     30.191\n",
       "ZTS                Health Care   30.53      2.150\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the complement of the expression\n",
    "# note the use of the complement of the selection\n",
    "price_less_than_300 = sp500[~selection]\n",
    "price_less_than_300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing(select and copy) rows using a slice\n",
    "슬라이싱을 통한 로우 삭제\n",
    "\n",
    "(말이 삭제지, 원하는 로우만 따로 새 데이터 프레임으로 가져온다고 생각하면 된다. `슬라이싱.copy()`를 사용해 원하는 부분만 복사하여 새 객체에 저장한다.)\n",
    "\n",
    "슬라이싱 역시 데이터 프레임의 레코드 삭제에 사용할 수 있다. 삭제하고자 하는 로우를 제외한 나머지 모두를 선택한다는 점에서 그 과정이 불리언 선택과 동일하다. \n",
    "\n",
    "처음 3개의 레코드를 제외한 나머지를 삭제해보도록한다. 우선 `[:3]`으로 슬라이싱하면 처음 3개의 로우가 반환된다.  \n",
    "이때 이것은 슬라이싱이기 때문에 이 결과는 원래 데이터 프레임의 '뷰'일 뿐이라는 점을 기억해야 한다. 원래 데이터 프레임에서 삭제된 것은 없다.  \n",
    "그러나 이 3개의 로우에 변경을 가하면 원래 데이터 프레임의 데이터도 변경된다. **이를 방지하기 위해, 슬라이싱의 결과를 복사한 새 데이터 프레임을 만들어 작업하는 것이다**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573\n",
       "ABBV    Health Care   53.95      2.954"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only the first three rows : this can alter the origin\n",
    "only_first_three = sp500[:3]\n",
    "only_first_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Sector   Price  BookValue\n",
       "Symbol                                \n",
       "MMM     Industrials  141.14     26.668\n",
       "ABT     Health Care   39.60     15.573\n",
       "ABBV    Health Care   53.95      2.954"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first three, but a copy of them : this is seperated by the origin so, this cannot alter the origin\n",
    "only_first_three = sp500[:3].copy()\n",
    "only_first_three"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
