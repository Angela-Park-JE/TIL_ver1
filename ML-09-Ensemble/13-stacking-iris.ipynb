{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# 머신러닝 with Python \n",
    "## 09 앙상블 학습 스태킹 연습 - iris 데이터\n",
    "\n",
    "##### 스태킹 알고리즘을 활용하여 iris를 분류하는 모형을 만드는 연습을 해본다.\n",
    "\n",
    "(책 p.295~ 원래 실습은 유방암 양성음성 관련 데이터였으나 모형들과 관련한 의문이 남아서 다른 데이터로도 실행을 해보고자 한다.) \n",
    "\n",
    "---\n",
    "\n",
    "하단부 실험에서는 이전 스태킹 실험들과 마찬가지로, 학습기 종류 자체나 학습의 순서 등을 변경하는 실험을 진행하였다.\n",
    "\n",
    "> 배운점: 데이터마다 해당 데이터에 강력한 모형이 따로 있음을 확실히 알게 되었다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022679e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e3ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "raw_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fee972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 내 피처 살펴보기\n",
    "raw_iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "### 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_iris.data\n",
    "y = raw_iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc70ec",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할 및 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b99b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split              # 데이터 분할을 위한 함수\n",
    "from sklearn.preprocessing import StandardScaler                  # 데이터 표준화를 위한 함수\n",
    "\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0) # 데이터 분할\n",
    "\n",
    "std_scale = StandardScaler()                                      # 표준화 스케일러 선언\n",
    "std_scale.fit(X_tn)                                               # 트레이닝 피처(데이터)를 기준으로 표준화 스케일러 적합\n",
    "\n",
    "X_tn_std = std_scale.transform(X_tn)                              # 트레인, 테스트 데이터를 표준화 스케일러 처리\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9de511",
   "metadata": {},
   "source": [
    "### 데이터 학습 (베이스러너: SVM, Gnb | 메타러너: LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be35818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('svm', SVC(kernel='linear', random_state=0)),\n",
       "                               ('gnb', GaussianNB())],\n",
       "                   final_estimator=LogisticRegression(random_state=0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('svm', base_clf1),('gnb', base_clf2)],   # 개별 학습기 넣은 최종 모형 설정\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) # 분류 문제를 해결해야 할 경우 StackingRegressor 사용\n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd9156",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3205bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "print(pred_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639cdb8",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901af3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ea91",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a91b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa8933",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "313190f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46761be3",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "한개만 틀린 결과가 나왔다. 나쁘지 않은 성능을 보여주었는데, 과연 붓꽃 데이터에서는 나이브 베이즈는 어떤 성능을 보여줄 것인가!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385a861",
   "metadata": {},
   "source": [
    "# 실험- 학습기 개수 변경\n",
    "## 실험1 : 베이스 학습기를 SVC만 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d562a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기- SVM만 사용했을 경우 정확도:  0.9736842105263158\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "# base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('svm', base_clf1)],\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기- SVM만 사용했을 경우 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93a9cd",
   "metadata": {},
   "source": [
    "## 실험2: 베이스 학습기를 GaussianNB만 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bfaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기- 가우시안 나이브 베이즈만 사용했을 경우 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "# base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', base_clf2)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기- 가우시안 나이브 베이즈만 사용했을 경우 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff8e2b",
   "metadata": {},
   "source": [
    "### 위의 실험 결과\n",
    "\n",
    "재밌는 결과가 나왔다. SVC-LR의 조합보다 GNB-LR의 조합이 더 좋은 성능을 보여주었다! 드디어 가우시안 나이브 베이즈도 잘하는 게 있다고 증명을 한 것이다! (?)\n",
    "\n",
    "물론 각각 만 개도 안되는 데이터들로 결론을 내리기에는 조악하긴 하지만, 앞전과는 다른, 의외의 결과인 것이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749aeca7",
   "metadata": {},
   "source": [
    "# 실험3: 학습기 순서 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efc3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기 순서 변경 후 정확도:  0.9736842105263158\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', base_clf2), ('svc', base_clf1)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기 순서 변경 후 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83806cc6",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "순서가 상관이 없다는 것이 증명이 되었음에도 그저 돌려보았는데 뭐 그런가보다 싶을 때까지 코드가 익숙해졌으면 좋겠어서."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd9432",
   "metadata": {},
   "source": [
    "# 실험- 기본 학습기와 메타 학습기 조합 변경\n",
    "\n",
    "베이스 학습기들의 결과가 나온 것을 메타 학습기가 받는다고 했을 때, \n",
    "\n",
    "같은 종류의 학습기가 순차적으로 데이터를 받아 분류한다면 결과가 어떨지에 대한 궁금증과,\n",
    "\n",
    "세 가지 분류 알고리즘들의 조합에 따라 이 데이터 셋에서는 어떤 성능차이가 있을지 궁금해졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e10aea",
   "metadata": {},
   "source": [
    "## 실험4: 셋 중 메타 학습기를 변경했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0255780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 학습기:  SVM\n",
      "베이스 학습기:  Gaussian Naive Bayes, Logistic Regression\n",
      "모델 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "========================================================\n",
      "메타 학습기:  Gaussian Naive Bayes\n",
      "베이스 학습기:  SVM, Logistic Regression\n",
      "모델 정확도:  0.9736842105263158\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "clf_svc = svm.SVC(kernel = 'linear', random_state = 0)\n",
    "clf_gnb = GaussianNB()\n",
    "clf_lr = LogisticRegression(random_state = 0)\n",
    "\n",
    "\n",
    "# 메타 학습기가 SVC 일 때\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', clf_gnb), ('lr', clf_lr)], \n",
    "                                  final_estimator = svm.SVC(kernel = 'linear', random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기: \", \"SVM\")\n",
    "print(\"베이스 학습기: \", \"Gaussian Naive Bayes, Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# 메타 학습기가 Naive Bayes 일 때\n",
    "clf_stacking = StackingClassifier(estimators = [('svc', clf_svc), ('lr', clf_lr)], final_estimator = GaussianNB()) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기: \", \"Gaussian Naive Bayes\")\n",
    "print(\"베이스 학습기: \", \"SVM, Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d733b",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "이번에는 베이스 학습기가 가우시안 나이브 베이즈가 포함된 상태가 성능이 더 좋게 나왔다. 그렇다면 학습기 모형이 같은 모형일때 성능은 어떨까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89595e9",
   "metadata": {},
   "source": [
    "## 실험5: 베이스 학습기와 메타 학습기가 같은 모형일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2ec200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 학습기 = 베이스 학습기:  Logistic Regression\n",
      "모델 정확도:  0.9736842105263158\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "========================================================\n",
      "메타 학습기 = 베이스 학습기:  SVM\n",
      "모델 정확도:  0.9736842105263158\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "========================================================\n",
      "메타 학습기 = 베이스 학습기:  Gaussian Naive Bayes\n",
      "모델 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "clf_svc = svm.SVC(kernel = 'linear', random_state = 0) \n",
    "clf_gnb = GaussianNB()\n",
    "clf_lr = LogisticRegression(random_state = 0)\n",
    "\n",
    "\n",
    "# LogisticRegression\n",
    "clf_stacking = StackingClassifier(estimators = [('lr', clf_lr)], \n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# SVM\n",
    "clf_stacking = StackingClassifier(estimators = [('svc', clf_svc)],\n",
    "                                  final_estimator = svm.SVC(kernel = 'linear', random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"SVM\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', clf_gnb)], \n",
    "                                  final_estimator = GaussianNB()) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"Gaussian Naive Bayes\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042b4c7",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "붓꽃 데이터에서는 Gaussian Naive Bayes가 LogisticRegression과 SupportVectorMachine보다 더 나은 성능을 보여주었다. \n",
    "\n",
    "적은 데이터이고 다른 여러 옵션들(조건을 같게 할 수 있는 상세한 튜닝)을 만질 수 있는 수준이 되지 못함에 아쉽지만 이전의 와인이나 유방암 데이터와는 다른 결과간 나온 것이 재미있다.\n",
    "\n",
    "다른 데이터로도 스태킹을 실험해보고 싶다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
