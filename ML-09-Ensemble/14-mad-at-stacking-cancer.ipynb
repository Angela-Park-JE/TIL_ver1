{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# Stacking 연습 - breast_cancer 데이터\n",
    "\n",
    "##### CV 세트 기반 스태킹 알고리즘까지 스태킹을 이해하기 위해 하는 스태킹 실습.  해당 스태킹 모델을 활용하여 유방암 여부를 예측하는 모형을 만들어본다.\n",
    "\n",
    "##### 해당 링크를 참조하여 만들어본다. https://kimdingko-world.tistory.com/186 \n",
    "\n",
    "---\n",
    "\n",
    "CV Set 기반 스태킹 전 일반 스태킹을 진행한 다음 비교해보고자 한다.\n",
    "\n",
    "첫 번째로는 블로그 내용에서는 따로 표준화를 진행하지 않았으므로 그대로 따라서 결과 데이터를 행렬 상태로 이용하여 진행하였고,\n",
    "\n",
    "두 번째로는 표준화 진행하지 않은 채로 StackingClassifier를 이용하기로 한다.\n",
    "\n",
    "세 번째로는 표준화를 진행하고 행렬 상태를 이용하도록 하고, \n",
    "\n",
    "네 번쨰로는 표준화를 진행하고 StackingClassifier를 이용하도록 하겠다.\n",
    "\n",
    "그다음 CV set 기반 스태킹을 실습하려 한다. \n",
    "\n",
    "\n",
    "> 배운점: 사이킷런의 스태킹모델로 스태킹을 할 때와, 결과들을 수제로 데이터 넣는 것과는 차이가 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9f1a8",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022679e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e3ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "raw_breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fee972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 내 피처 살펴보기\n",
    "raw_breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "### 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = raw_breast_cancer.data\n",
    "y_label = raw_breast_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28805ed6",
   "metadata": {},
   "source": [
    "# Mode1: No Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc70ec",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539d34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                # 데이터 분할을 위한 함수\n",
    "# from sklearn.preprocessing import StandardScaler                  # 데이터 표준화를 위한 함수\n",
    "\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X_data, y_label, random_state = 0) # 데이터 분할\n",
    "\n",
    "# std_scale = StandardScaler()                                      # 표준화 스케일러 선언\n",
    "# std_scale.fit(X_tn)                                               # 트레이닝 피처(데이터)를 기준으로 표준화 스케일러 적합\n",
    "\n",
    "# X_tn_std = std_scale.transform(X_tn)                              # 트레인, 테스트 데이터를 표준화 스케일러 처리\n",
    "# X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb5e73",
   "metadata": {},
   "source": [
    "## Model1: 베이스러너 아웃풋을 전치시켜 메타러너에 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9de511",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0be35818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 모델에 사용할 알고리즘 호출\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 베이스 러너: 개별 ML 모델 객체 생성 \n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier(random_state = 0)\n",
    "ada_clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "# 메타 모델: 스태킹으로 만들어진 데이터 학습 및 예측 - 로지스틱 리그레션 모형\n",
    "lr_final = LogisticRegression(C = 10, random_state = 0)\n",
    "\n",
    "# 개별 모델 학습\n",
    "knn_clf.fit(X_tn, y_tn)\n",
    "rf_clf.fit(X_tn, y_tn)\n",
    "dt_clf.fit(X_tn, y_tn)\n",
    "ada_clf.fit(X_tn, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2f29e",
   "metadata": {},
   "source": [
    "### 베이스 러너 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98858ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도 : 0.9230769230769231\n",
      "RF 정확도 : 0.972027972027972\n",
      "DT 정확도 : 0.8811188811188811\n",
      "ADA부스트 정확도 : 0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "# 기반 모델 예측 세트와 정확도 확인\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_pred = knn_clf.predict(X_te)\n",
    "rf_pred = rf_clf.predict(X_te)\n",
    "dt_pred = dt_clf.predict(X_te)\n",
    "ada_pred = ada_clf.predict(X_te)\n",
    "\n",
    "print('KNN 정확도 :',accuracy_score(y_te, knn_pred))\n",
    "print('RF 정확도 :',accuracy_score(y_te, rf_pred))\n",
    "print('DT 정확도 :',accuracy_score(y_te, dt_pred))\n",
    "print('ADA부스트 정확도 :',accuracy_score(y_te, ada_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e540fe",
   "metadata": {},
   "source": [
    "### 메타 모델 빌드: 베이스 러너 결과를 전치하여 각 모델을 컬럼으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4170418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 143)\n",
      "(143, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 기반 모델의 예측 결과를 스태킹\n",
    "stacked_pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(stacked_pred.shape)\n",
    "\n",
    "# transpose를 이용, 행과 열의 위치를 교환, 칼럼 레벨로 각 모델의 예측 결과를 피처로 사용\n",
    "stacked_pred = np.transpose(stacked_pred)\n",
    "print(stacked_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd9156",
   "metadata": {},
   "source": [
    "### 메타 모델로 데이터 예측: 결과 (0.9930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eaa932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델 정확도:  0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "# 메타 모델은 기반모델의 예측결과를 기반으로 학습\n",
    "\n",
    "lr_final.fit(stacked_pred, y_te)\n",
    "final_pred = lr_final.predict(stacked_pred)\n",
    "\n",
    "print('최종 메타 모델 정확도: ',accuracy_score(y_te, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c59ea",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인\n",
    "\n",
    "안해볼 수가 없지. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b4da683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90        53\n",
      "           1       0.95      0.92      0.94        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.91      0.92      0.92       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        53\n",
      "           1       0.99      0.97      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85        53\n",
      "           1       0.96      0.84      0.90        90\n",
      "\n",
      "    accuracy                           0.88       143\n",
      "   macro avg       0.87      0.89      0.88       143\n",
      "weighted avg       0.90      0.88      0.88       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        53\n",
      "           1       0.98      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.98      0.98       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "prediction_list = [knn_pred, rf_pred, dt_pred, ada_pred]\n",
    "\n",
    "for i in prediction_list:\n",
    "    class_report = classification_report(y_te, i)\n",
    "    print(class_report)\n",
    "    print(\"=======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6abfa9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 분류 리포트\n",
    "\n",
    "class_report = classification_report(y_te, final_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c56f8",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "스태킹 분류기를 따로 사용하지 않고 바로 이들을 사용하는 방식으로 진행되었다.\n",
    "\n",
    "knn_pred, rf_pred, dt_pred, ada_pred 로서의 분류 결과도 나쁘지 않았으나, 실제 스태킹 모델의 분류가 수치적으로는 조금 더 정확해 보이기는 한다.\n",
    "\n",
    "특이한 점은 에이다부스트를 개별 모델로 사용했다는 점인데, 정확도가 디시전 트리보다 좋게 나왔다. 재미있는 부분.\n",
    "\n",
    "또한 knn과 DT가 똥을 쌌음(?)에도 버스기사가 존재한건지 버스 성능이 좋은건지 메타학습기 정확도가 상당히 높게 나왔다.\n",
    "\n",
    "---\n",
    "\n",
    "기존에 익혔던 스태킹 분류기에 각 분류기를 같은 옵션으로 넣었을 때에도 같은 결과가 나오는지 아래에서 해본다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293f4fc",
   "metadata": {},
   "source": [
    "## Model2: 표준화 진행 없이 StackingClassifier 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e6204",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccccb94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=4)),\n",
       "                               ('rf', RandomForestClassifier(random_state=0)),\n",
       "                               ('dt', DecisionTreeClassifier(random_state=0)),\n",
       "                               ('ada',\n",
       "                                AdaBoostClassifier(n_estimators=100,\n",
       "                                                   random_state=0))],\n",
       "                   final_estimator=LogisticRegression(C=10, random_state=0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 모델에 사용할 알고리즘\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 스태킹을 위한 앙상블 알고리즘\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 베이스 러너: 개별 ML 모델 객체 생성 \n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier(random_state = 0)\n",
    "ada_clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "# 메타 모델: 스태킹으로 만들어진 데이터 학습 및 예측 - 로지스틱 리그레션 모형\n",
    "# 위와 구분짓기 위해 주로 쓰던 네이밍을 사용했다\n",
    "clf_stacking = StackingClassifier(estimators = [('knn', knn_clf),('rf', rf_clf),('dt', dt_clf),('ada', ada_clf)],\n",
    "                                  final_estimator = LogisticRegression(C = 10, random_state = 0))\n",
    "\n",
    "# 데이터 적합\n",
    "clf_stacking.fit(X_tn, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e2961",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3205bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "pred_stacking = clf_stacking.predict(X_te)\n",
    "print(pred_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639cdb8",
   "metadata": {},
   "source": [
    "### 정확도 평가: 결과 (0.9720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "901af3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ea91",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a91b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  1]\n",
      " [ 3 87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa8933",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313190f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        53\n",
      "           1       0.99      0.97      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8f9c4",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "정확도가 눈에 띄게(?) 줄었는데 이유를 알고싶다. \n",
    "\n",
    "이럴 때에는 코드를 보아야 하는데 본다고 알 수준은 안되니 옵션을 살펴보기로 한다.\n",
    "\n",
    "```\n",
    "StackingClassifier(\n",
    "    estimators,\n",
    "    final_estimator=None,\n",
    "    *,\n",
    "    cv=None,\n",
    "    stack_method='auto',\n",
    "    n_jobs=None,\n",
    "    passthrough=False,\n",
    "    verbose=0,\n",
    ")\n",
    "```\n",
    "\n",
    "estimators는 그대로 들어갔고, final_estimator도 그대로 들어갔다. \n",
    "\n",
    "현재 내가 확인할 수 없는 부분은 cv, stack_method, n_jobs, passthrough, verbose 다섯가지 부분이다.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db248f",
   "metadata": {},
   "source": [
    "# Mode2: After Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccfb9a3",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할 및 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0119a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split              # 데이터 분할을 위한 함수\n",
    "from sklearn.preprocessing import StandardScaler                  # 데이터 표준화를 위한 함수\n",
    "\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X_data, y_label, random_state = 0) # 데이터 분할\n",
    "\n",
    "std_scale = StandardScaler()                                      # 표준화 스케일러 선언\n",
    "std_scale.fit(X_tn)                                               # 트레이닝 피처(데이터)를 기준으로 표준화 스케일러 적합\n",
    "\n",
    "X_tn_std = std_scale.transform(X_tn)                              # 트레인, 테스트 데이터를 표준화 스케일러 처리\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad92ee",
   "metadata": {},
   "source": [
    "## Model3: 베이스 러너 아웃풋을 전치시켜 메타러너에 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437fa100",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22f8fe28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 모델에 사용할 알고리즘 호출\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 베이스 러너: 개별 ML 모델 객체 생성 \n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier(random_state = 0)\n",
    "ada_clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "# 메타 모델: 스태킹으로 만들어진 데이터 학습 및 예측 - 로지스틱 리그레션 모형\n",
    "lr_final = LogisticRegression(C = 10, random_state = 0)\n",
    "\n",
    "# 개별 모델 학습\n",
    "knn_clf.fit(X_tn_std, y_tn)\n",
    "rf_clf.fit(X_tn_std, y_tn)\n",
    "dt_clf.fit(X_tn_std, y_tn)\n",
    "ada_clf.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ed994",
   "metadata": {},
   "source": [
    "### 베이스 러너 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f12741ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도 : 0.958041958041958\n",
      "RF 정확도 : 0.972027972027972\n",
      "DT 정확도 : 0.8811188811188811\n",
      "ADA부스트 정확도 : 0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "# 기반 모델 예측 세트와 정확도 확인\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_pred = knn_clf.predict(X_te_std)\n",
    "rf_pred = rf_clf.predict(X_te_std)\n",
    "dt_pred = dt_clf.predict(X_te_std)\n",
    "ada_pred = ada_clf.predict(X_te_std)\n",
    "\n",
    "print('KNN 정확도 :',accuracy_score(y_te, knn_pred))\n",
    "print('RF 정확도 :',accuracy_score(y_te, rf_pred))\n",
    "print('DT 정확도 :',accuracy_score(y_te, dt_pred))\n",
    "print('ADA부스트 정확도 :',accuracy_score(y_te, ada_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e4dc0",
   "metadata": {},
   "source": [
    "KNN의 정확도가 3%포인트 상승했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec04d90",
   "metadata": {},
   "source": [
    "### 메타 모델 빌드: 베이스 러너 결과를 전치하여 각 모델을 컬럼으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44af1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 143)\n",
      "(143, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 기반 모델의 예측 결과를 스태킹\n",
    "stacked_pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(stacked_pred.shape)\n",
    "\n",
    "# transpose를 이용, 행과 열의 위치를 교환, 칼럼 레벨로 각 모델의 예측 결과를 피처로 사용\n",
    "stacked_pred = np.transpose(stacked_pred)\n",
    "print(stacked_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c855ba",
   "metadata": {},
   "source": [
    "### 메타 모델로 데이터 예측: 결과 (0.9930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18915e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델 정확도:  0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "# 메타 모델은 기반모델의 예측결과를 기반으로 학습\n",
    "\n",
    "lr_final.fit(stacked_pred, y_te)\n",
    "final_pred = lr_final.predict(stacked_pred)\n",
    "\n",
    "print('최종 메타 모델 정확도: ',accuracy_score(y_te, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d365f",
   "metadata": {},
   "source": [
    "어라, 메타모델의 정확도는 그대로 일치한다.\n",
    "\n",
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce03af9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        53\n",
      "           1       0.97      0.97      0.97        90\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        53\n",
      "           1       0.99      0.97      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85        53\n",
      "           1       0.96      0.84      0.90        90\n",
      "\n",
      "    accuracy                           0.88       143\n",
      "   macro avg       0.87      0.89      0.88       143\n",
      "weighted avg       0.90      0.88      0.88       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        53\n",
      "           1       0.98      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.98      0.98       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "prediction_list = [knn_pred, rf_pred, dt_pred, ada_pred]\n",
    "\n",
    "for i in prediction_list:\n",
    "    class_report = classification_report(y_te, i)\n",
    "    print(class_report)\n",
    "    print(\"=======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09ee1bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 분류 리포트\n",
    "\n",
    "class_report = classification_report(y_te, final_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a364b",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "표준화를 진행하자 KNN의 정확도가 상당수준 상승했다. 하지만 데이터의 절대적 양이 적어서인지는 몰라도 메타 학습기에서의 성능 상승은 볼 수 없었다. \n",
    "\n",
    "그렇다면 결과를 전치시켜 그대로 사용한 것 말고, 사이킷런에서 제공하는 Stacking 앙상블 모델을 사용했을 때는 어떨까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef06ab",
   "metadata": {},
   "source": [
    "## Model4: 표준화 후 StackingClassifier 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde1bc",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5812b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=4)),\n",
       "                               ('rf', RandomForestClassifier(random_state=0)),\n",
       "                               ('dt', DecisionTreeClassifier(random_state=0)),\n",
       "                               ('ada',\n",
       "                                AdaBoostClassifier(n_estimators=100,\n",
       "                                                   random_state=0))],\n",
       "                   final_estimator=LogisticRegression(C=10, random_state=0))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 모델에 사용할 알고리즘\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 스태킹을 위한 앙상블 알고리즘\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 베이스 러너: 개별 ML 모델 객체 생성 \n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier(random_state = 0)\n",
    "ada_clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "# 메타 모델: 스태킹으로 만들어진 데이터 학습 및 예측 - 로지스틱 리그레션 모형\n",
    "# 위와 구분짓기 위해 주로 쓰던 네이밍을 사용했다\n",
    "clf_stacking = StackingClassifier(estimators = [('knn', knn_clf),('rf', rf_clf),('dt', dt_clf),('ada', ada_clf)],\n",
    "                                  final_estimator = LogisticRegression(C = 10, random_state = 0))\n",
    "\n",
    "# 데이터 적합\n",
    "clf_stacking.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7358fb",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d85c2f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "print(pred_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a530f8",
   "metadata": {},
   "source": [
    "### 정확도 평가: 결과 (0.9720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33aa3b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49670d",
   "metadata": {},
   "source": [
    "표준화를 시키기 전과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7e501",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80244b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  2]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c879f7",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9342f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        53\n",
      "           1       0.98      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c483a",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "정확도는 같지만 예측에 있어 차이가 있음을 볼 수 있는 부분이 바로 이 대목이다.\n",
    "\n",
    "컨퓨전 매트릭스가 \n",
    "\n",
    "```\n",
    "[[52  1],  [ 3 87]]\n",
    "```\n",
    "\n",
    "였지만\n",
    "\n",
    "```\n",
    "[[51  2],  [ 2 88]] \n",
    "```\n",
    "이렇게 결과가 변했다. 분명한 차이가 있었음을 알수 있다. \n",
    "\n",
    "만약 해당 데이터 포인트를 불러와서 각 모델들이 맞추지 못한 것들이 어떤 데이터인지 뽑아서 볼 수 있으면 더 좋을 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
