{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# Stacking 연습 - breast_cancer 데이터\n",
    "\n",
    "##### CV 세트 기반 스태킹 알고리즘까지 스태킹을 이해하기 위해 하는 스태킹 실습.  해당 스태킹 모델을 활용하여 유방암 여부를 예측하는 모형을 만들어본다.\n",
    "\n",
    "##### 해당 링크를 참조하여 만들어본다. https://kimdingko-world.tistory.com/186 \n",
    "\n",
    "---\n",
    "\n",
    "CV Set 기반 스태킹 전 일반 스태킹을 진행한 다음 비교해보고자 한다.\n",
    "\n",
    "첫 번째로는 블로그 내용에서는 따로 정규화를 진행하지 않았으므로 그대로 따라서 진행하였고,\n",
    "\n",
    "두 번째로는 정규화 진행하지 않은 채로 StackingClassifier를 이용하기로 한다.\n",
    "\n",
    "세 번째로는 정규화도 진행하고 StackingClassifier를 사용할 것이고,\n",
    "\n",
    "네 번째로 CV set 기반 스태킹을 실습하려 한다.\n",
    "\n",
    "\n",
    "> 배운점:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3218a73",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022679e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e3ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "raw_breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fee972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 내 피처 살펴보기\n",
    "raw_breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "### 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = raw_breast_cancer.data\n",
    "y_label = raw_breast_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42c19d",
   "metadata": {},
   "source": [
    "# Mode1: No Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc70ec",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775e940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                # 데이터 분할을 위한 함수\n",
    "# from sklearn.preprocessing import StandardScaler                  # 데이터 표준화를 위한 함수\n",
    "\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X_data, y_label, random_state = 0) # 데이터 분할\n",
    "\n",
    "# std_scale = StandardScaler()                                      # 표준화 스케일러 선언\n",
    "# std_scale.fit(X_tn)                                               # 트레이닝 피처(데이터)를 기준으로 표준화 스케일러 적합\n",
    "\n",
    "# X_tn_std = std_scale.transform(X_tn)                              # 트레인, 테스트 데이터를 표준화 스케일러 처리\n",
    "# X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640af2ad",
   "metadata": {},
   "source": [
    "## Model1: 베이스러너 아웃풋을 전치시켜 메타러너에 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9de511",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0be35818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 모델에 사용할 알고리즘 호출\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 베이스 러너: 개별 ML 모델 객체 생성 \n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier(random_state = 0)\n",
    "ada_clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "# 메타 모델: 스태킹으로 만들어진 데이터 학습 및 예측 - 로지스틱 리그레션 모형\n",
    "lr_final = LogisticRegression(C = 10, random_state = 0)\n",
    "\n",
    "# 개별 모델 학습\n",
    "knn_clf.fit(X_tn, y_tn)\n",
    "rf_clf.fit(X_tn, y_tn)\n",
    "dt_clf.fit(X_tn, y_tn)\n",
    "ada_clf.fit(X_tn, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54237ea",
   "metadata": {},
   "source": [
    "### 베이스 러너 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6847f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도 : 0.9230769230769231\n",
      "RF 정확도 : 0.972027972027972\n",
      "DT 정확도 : 0.8811188811188811\n",
      "ADA부스트 정확도 : 0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "# 기반 모델 예측 세트와 정확도 확인\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_pred = knn_clf.predict(X_te)\n",
    "rf_pred = rf_clf.predict(X_te)\n",
    "dt_pred = dt_clf.predict(X_te)\n",
    "ada_pred = ada_clf.predict(X_te)\n",
    "\n",
    "print('KNN 정확도 :',accuracy_score(y_te, knn_pred))\n",
    "print('RF 정확도 :',accuracy_score(y_te, rf_pred))\n",
    "print('DT 정확도 :',accuracy_score(y_te, dt_pred))\n",
    "print('ADA부스트 정확도 :',accuracy_score(y_te, ada_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74747c15",
   "metadata": {},
   "source": [
    "### 메타 모델 빌드: 베이스 러너 결과를 전치하여 각 모델을 컬럼으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa08992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 143)\n",
      "(143, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 기반 모델의 예측 결과를 스태킹\n",
    "stacked_pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(stacked_pred.shape)\n",
    "\n",
    "# transpose를 이용, 행과 열의 위치를 교환, 칼럼 레벨로 각 모델의 예측 결과를 피처로 사용\n",
    "stacked_pred = np.transpose(stacked_pred)\n",
    "print(stacked_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd9156",
   "metadata": {},
   "source": [
    "### 메타 모델로 데이터 예측: 결과 (0.9930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "803eaad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델 정확도:  0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "# 메타 모델은 기반모델의 예측결과를 기반으로 학습\n",
    "\n",
    "lr_final.fit(stacked_pred, y_te)\n",
    "final_pred = lr_final.predict(stacked_pred)\n",
    "\n",
    "print('최종 메타 모델 정확도: ',accuracy_score(y_te, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921ccf5",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인\n",
    "\n",
    "안해볼 수가 없지. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b40da39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90        53\n",
      "           1       0.95      0.92      0.94        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.91      0.92      0.92       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        53\n",
      "           1       0.99      0.97      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85        53\n",
      "           1       0.96      0.84      0.90        90\n",
      "\n",
      "    accuracy                           0.88       143\n",
      "   macro avg       0.87      0.89      0.88       143\n",
      "weighted avg       0.90      0.88      0.88       143\n",
      "\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        53\n",
      "           1       0.98      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.98      0.98       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "prediction_list = [knn_pred, rf_pred, dt_pred, ada_pred]\n",
    "\n",
    "for i in prediction_list:\n",
    "    class_report = classification_report(y_te, i)\n",
    "    print(class_report)\n",
    "    print(\"=======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9564e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 분류 리포트\n",
    "\n",
    "class_report = classification_report(y_te, final_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f850dd9",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "스태킹 분류기를 따로 사용하지 않고 바로 이들을 사용하는 방식으로 진행되었다.\n",
    "\n",
    "knn_pred, rf_pred, dt_pred, ada_pred 로서의 분류 결과도 나쁘지 않았으나, 실제 스태킹 모델의 분류가 수치적으로는 조금 더 정확해 보이기는 한다.\n",
    "\n",
    "특이한 점은 에이다부스트를 개별 모델로 사용했다는 점인데, 정확도가 디시전 트리보다 좋게 나왔다. 재미있는 부분.\n",
    "\n",
    "또한 knn과 DT가 똥을 쌌음(?)에도 버스기사가 존재한건지 버스 성능이 좋은건지 메타학습기 정확도가 상당히 높게 나왔다.\n",
    "\n",
    "---\n",
    "\n",
    "기존에 익혔던 스태킹 분류기에 각 분류기를 같은 옵션으로 넣었을 때에도 같은 결과가 나오는지 아래에서 해본다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5111fa",
   "metadata": {},
   "source": [
    "## Model2: 정규화 진행 없이 StackingClassifier 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe1100",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "067195c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=4)),\n",
       "                               ('rf', RandomForestClassifier(random_state=0)),\n",
       "                               ('dt', DecisionTreeClassifier(random_state=0)),\n",
       "                               ('ada',\n",
       "                                AdaBoostClassifier(n_estimators=100,\n",
       "                                                   random_state=0))],\n",
       "                   final_estimator=LogisticRegression(C=10, random_state=0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 모델에 사용할 알고리즘\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 스태킹을 위한 앙상블 알고리즘\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 베이스 러너: 개별 ML 모델 객체 생성 \n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier(random_state = 0)\n",
    "ada_clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "# 메타 모델: 스태킹으로 만들어진 데이터 학습 및 예측 - 로지스틱 리그레션 모형\n",
    "# 위와 구분짓기 위해 주로 쓰던 네이밍을 사용했다\n",
    "clf_stacking = StackingClassifier(estimators = [('knn', knn_clf),('rf', rf_clf),('dt', dt_clf),('ada', ada_clf)],\n",
    "                                  final_estimator = LogisticRegression(C = 10, random_state = 0))\n",
    "\n",
    "# 데이터 적합\n",
    "clf_stacking.fit(X_tn, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aaadbf",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3205bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "pred_stacking = clf_stacking.predict(X_te)\n",
    "print(pred_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639cdb8",
   "metadata": {},
   "source": [
    "### 정확도 평가: 결과 (0.9720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "901af3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ea91",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a91b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  1]\n",
      " [ 3 87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa8933",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313190f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        53\n",
      "           1       0.99      0.97      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8f9c4",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "정확도가 눈에 띄게(?) 줄었는데 이유를 알고싶다. \n",
    "\n",
    "이럴 때에는 코드를 보아야 하는데 본다고 알 수준은 안되니 옵션을 살펴보기로 한다.\n",
    "\n",
    "```\n",
    "StackingClassifier(\n",
    "    estimators,\n",
    "    final_estimator=None,\n",
    "    *,\n",
    "    cv=None,\n",
    "    stack_method='auto',\n",
    "    n_jobs=None,\n",
    "    passthrough=False,\n",
    "    verbose=0,\n",
    ")\n",
    "```\n",
    "\n",
    "estimators는 그대로 들어갔고, final_estimator도 그대로 들어갔다. \n",
    "\n",
    "현재 내가 확인할 수 없는 부분은 cv, stack_method, n_jobs, passthrough, verbose 다섯가지 부분이다.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703ea60",
   "metadata": {},
   "source": [
    "# Mode2: After Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9260756",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split              # 데이터 분할을 위한 함수\n",
    "from sklearn.preprocessing import StandardScaler                  # 데이터 표준화를 위한 함수\n",
    "\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X_data, y_label, random_state = 0) # 데이터 분할\n",
    "\n",
    "std_scale = StandardScaler()                                      # 표준화 스케일러 선언\n",
    "std_scale.fit(X_tn)                                               # 트레이닝 피처(데이터)를 기준으로 표준화 스케일러 적합\n",
    "\n",
    "X_tn_std = std_scale.transform(X_tn)                              # 트레인, 테스트 데이터를 표준화 스케일러 처리\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad92ee",
   "metadata": {},
   "source": [
    "## Model3: 베이스 러너 아웃풋을 전치시켜 메타러너에 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fef0c0",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
