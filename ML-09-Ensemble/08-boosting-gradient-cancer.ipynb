{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# 머신러닝 with Python \n",
    "## 09 앙상블 학습 그래디언트 부스팅(Boosting) 실습- breast_cancer 데이터\n",
    "\n",
    "##### 그래디언트 부스팅 알고리즘을 활용해 유방암 여부를 예측하는 모형을 만들어본다.\n",
    "\n",
    "책 p.286~ \n",
    "\n",
    "---\n",
    "\n",
    "기본 실습은 사이킷런으로 진행하지만 하단부에서는 XGBoost와 LightGBM을 데려와서 실습 해보기도 해보고싶다. 아마 다른 파일에서 진행할 것 같다.\n",
    "\n",
    "> 배운점1: \n",
    "\n",
    "> 배운점2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022679e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e3ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf788f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유방암 데이터 가져오기\n",
    "\n",
    "raw_breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4be6bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 살펴보기\n",
    "\n",
    "raw_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fee972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 내 피처 이름들\n",
    "\n",
    "raw_breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "### 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_breast_cancer.data\n",
    "y = raw_breast_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ae465",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acca5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                 # 분할을 위해 필요한 함수\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)    # 분리. randomstate는 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc70ec",
   "metadata": {},
   "source": [
    "### 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a771eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler         # 데이터 표준화를 위한 함수\n",
    "std_scale = StandardScaler()                             # 표준화 스케일러 지정\n",
    "std_scale.fit(X_tn)                                      # 트레이닝 피처를 기준으로 표준화를 적합\n",
    "\n",
    "X_tn_std = std_scale.transform(X_tn) \n",
    "X_te_std = std_scale.transform(X_te)                     # 트레인, 테스트 데이터 각각 적합시킨 표준화에 맞게 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9de511",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6910d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.01, max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier     # 그래디언트 부스팅 함수. 회귀문제를 풀때는 regressor로 호출.\n",
    "clf_gbt = GradientBoostingClassifier(max_depth = 2,         # 개별 학습기의 최대 깊이\n",
    "                                     learning_rate = 0.01,  # 학습율. 너무 크면 튀고 너무 작으면 느리다.\n",
    "                                     random_state = 0)\n",
    "clf_gbt.fit(X_tn_std, y_tn)                                 # 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba9c2f",
   "metadata": {},
   "source": [
    "```\n",
    "max_depth : The maximum depth of the individual regression estimators. The maximum\n",
    "    depth limits the number of nodes in the tree. Tune this parameter\n",
    "    for best performance; the best value depends on the interaction\n",
    "    of the input variables.\n",
    "```\n",
    "\n",
    "맥스 뎁스는 default = 3이지만 2ㅗㄹ 바꾼다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd9156",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3205bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = clf_gbt.predict(X_te_std)                     # std된 테스트 피처 데이터를 넣고 실행하여 결과 확인 \n",
    "print(pred_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639cdb8",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901af3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_gbt)                # 실제값과 예측값을 넣음\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ea91",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a91b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  4]\n",
      " [ 1 89]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_gbt)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa8933",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "313190f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        53\n",
      "           1       0.96      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_gbt)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d758781",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "0.9650이 나쁜 성능은 아니지만 좋은 성능은 아닌 것 같으니 여기서 멈출수 없지, 일부를 바꾸는 연습을 해본다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b3cb9",
   "metadata": {},
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde13c7",
   "metadata": {},
   "source": [
    "## 실험1: max_depth(default = 3) 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3afd18ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류기 개별 max_depth:  1\n",
      "모델 정확도:  0.958041958041958\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        53\n",
      "           1       0.94      1.00      0.97        90\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.97      0.94      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "모델 정확도:  0.965034965034965\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        53\n",
      "           1       0.96      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  3\n",
      "모델 정확도:  0.965034965034965\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        53\n",
      "           1       0.98      0.97      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  4\n",
      "모델 정확도:  0.9230769230769231\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        53\n",
      "           1       0.98      0.90      0.94        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.91      0.93      0.92       143\n",
      "weighted avg       0.93      0.92      0.92       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  5\n",
      "모델 정확도:  0.9230769230769231\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        53\n",
      "           1       0.98      0.90      0.94        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.91      0.93      0.92       143\n",
      "weighted avg       0.93      0.92      0.92       143\n",
      "\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  # 그래디언트 부스팅 모델 함수. 회귀문제를 풀때는 regressor 호출\n",
    "from sklearn.metrics import accuracy_score               # 정확도 테스트 함수\n",
    "from sklearn.metrics import classification_report        # 분류 리포트 확인을 위한 함수\n",
    "\n",
    "for i in range(1, 6):\n",
    "    clf_gbt = GradientBoostingClassifier(max_depth = i,         # 개별 학습기의 최대 깊이\n",
    "                                         learning_rate = 0.01,  # 학습율. 너무 크면 튀고 너무 작으면 느리다.\n",
    "                                         random_state = 0)\n",
    "    # 데이터 학습\n",
    "    clf_gbt.fit(X_tn_std, y_tn)\n",
    "    \n",
    "    # 데이터 예측\n",
    "    pred_gbt = clf_gbt.predict(X_te_std) \n",
    "    \n",
    "    # 데이터 정확도 평가\n",
    "    accuracy = accuracy_score(y_te, pred_gbt)\n",
    "    \n",
    "    # 분류 리포트 확인\n",
    "    class_report = classification_report(y_te, pred_gbt)\n",
    "    \n",
    "    # 모델 상황 확인\n",
    "    \n",
    "    print(\"분류기 개별 max_depth: \", i )\n",
    "    print(\"모델 정확도: \", accuracy)\n",
    "    print(\"모델 분류 리포트\")\n",
    "    print(class_report)\n",
    "    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50968b5a",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "특정 개수 이상 늘어나면 오히려 성능이 떨어졌다. 예견된 일이기도 했는데, 튜닝과 관련해서는 놓칠 수 없는 부분이기 때문에 실험해 보았다.\n",
    "\n",
    "학습기의 개수는 어느 선 이상에서 더이상 성능이 상승하지 않을 것으로 예상되는데, 궁금하니 여러개를 해보기로 해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244de6c",
   "metadata": {},
   "source": [
    "## 실험2: n_estimators(default=100) 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff4c30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Angela/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Angela/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Angela/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  10\n",
      "모델 정확도:  0.6293706293706294\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        53\n",
      "           1       0.63      1.00      0.77        90\n",
      "\n",
      "    accuracy                           0.63       143\n",
      "   macro avg       0.31      0.50      0.39       143\n",
      "weighted avg       0.40      0.63      0.49       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  25\n",
      "모델 정확도:  0.9370629370629371\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        53\n",
      "           1       0.91      1.00      0.95        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.95      0.92      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  50\n",
      "모델 정확도:  0.951048951048951\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93        53\n",
      "           1       0.94      0.99      0.96        90\n",
      "\n",
      "    accuracy                           0.95       143\n",
      "   macro avg       0.96      0.94      0.95       143\n",
      "weighted avg       0.95      0.95      0.95       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  75\n",
      "모델 정확도:  0.958041958041958\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94        53\n",
      "           1       0.95      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.95      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  90\n",
      "모델 정확도:  0.958041958041958\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94        53\n",
      "           1       0.95      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.95      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  100\n",
      "모델 정확도:  0.965034965034965\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        53\n",
      "           1       0.96      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  120\n",
      "모델 정확도:  0.965034965034965\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        53\n",
      "           1       0.96      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n",
      "========================================================\n",
      "분류기 개별 max_depth:  2\n",
      "분류기 개수:  150\n",
      "모델 정확도:  0.951048951048951\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        53\n",
      "           1       0.96      0.97      0.96        90\n",
      "\n",
      "    accuracy                           0.95       143\n",
      "   macro avg       0.95      0.95      0.95       143\n",
      "weighted avg       0.95      0.95      0.95       143\n",
      "\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  # 그래디언트 부스팅 모델 함수. 회귀문제를 풀때는 regressor 호출\n",
    "from sklearn.metrics import accuracy_score               # 정확도 테스트 함수\n",
    "from sklearn.metrics import classification_report        # 분류 리포트 확인을 위한 함수\n",
    "\n",
    "n_esti = [10, 25, 50, 75, 90, 100, 120, 150]\n",
    "\n",
    "for i in n_esti:\n",
    "    clf_gbt = GradientBoostingClassifier(max_depth = 2,         # 개별 학습기의 최대 깊이\n",
    "                                         n_estimators = i,\n",
    "                                         learning_rate = 0.01,  # 학습율. 너무 크면 튀고 너무 작으면 느리다.\n",
    "                                         random_state = 0)\n",
    "    # 데이터 학습\n",
    "    clf_gbt.fit(X_tn_std, y_tn)\n",
    "    \n",
    "    # 데이터 예측\n",
    "    pred_gbt = clf_gbt.predict(X_te_std) \n",
    "    \n",
    "    # 데이터 정확도 평가\n",
    "    accuracy = accuracy_score(y_te, pred_gbt)\n",
    "    \n",
    "    # 분류 리포트 확인\n",
    "    class_report = classification_report(y_te, pred_gbt)\n",
    "    \n",
    "    # 모델 상황 확인\n",
    "    \n",
    "    print(\"분류기 개별 max_depth: \", 2 )\n",
    "    print(\"분류기 개수: \", i)\n",
    "    print(\"모델 정확도: \", accuracy)\n",
    "    print(\"모델 분류 리포트\")\n",
    "    print(class_report)\n",
    "    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902901e8",
   "metadata": {},
   "source": [
    "### 결과\n",
    "```\n",
    "분류기 개수:  50 / \n",
    "모델 정확도:  0.951048951048951\n",
    "\n",
    "분류기 개수:  75 / \n",
    "모델 정확도:  0.958041958041958\n",
    "\n",
    "분류기 개수:  100 /\n",
    "모델 정확도:  0.965034965034965\n",
    "\n",
    "분류기 개수:  150 / \n",
    "모델 정확도:  0.951048951048951\n",
    "```\n",
    "넣었던 개수 리스트 중 주요 변곡점을 짚어보면 이러하다. 100개일 때 가장 높은 성능을 보여주었고, 120개를 넘어 150개로 늘어났을 때의 정확도는 50개의 수준으로 다시 떨어졌다.\n",
    "\n",
    "분류기 개수가 늘어날수록 성능이 올라가는 것은 아님을 이전 앙상블 모델들을 공부하면서도 보아왔다. \n",
    "\n",
    "그러나 그래디언트 부스팅의 개념을 생각해 보았을 때, 이전 학습기의 에러를 두고 공부를 하기 때문에 일정 수준의 성능까지 꾸준히 올라가 일정수준에서 고정될 것이라고 생각했으나, 그 것과는 다른 결과가 나온 것이다.\n",
    "\n",
    "흥미로운 결과이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa53431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
