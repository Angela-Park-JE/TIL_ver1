{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# 머신러닝 with Python \n",
    "## 09 앙상블 학습 스태킹 연습 - wine 데이터\n",
    "\n",
    "##### 스태킹 알고리즘을 활용하여 wine을 분류하는 모형을 만들어보고자 한다.\n",
    "\n",
    "(책 p.295~ 원래 실습은 유방암 양성음성 관련 데이터였으나 모형들과 관련한 의문이 남아서 다른 데이터로도 실행을 해보고자 한다.) \n",
    "\n",
    "---\n",
    "\n",
    "하단부 실험에서는 이전 스태킹 실험들과 마찬가지로, 학습기 종류 자체나 학습의 순서 등을 변경하는 실험을 진행하였다.\n",
    "\n",
    "> 배운점: garbage in, garbage out과 마찬가지로 베이스 학습기가 분류를 잘 했다면 좋은 output을 받은 메타 학습기가 학습을 잘 할 것이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022679e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e3ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "raw_wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fee972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 내 피처 살펴보기\n",
    "raw_wine.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "### 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_wine.data\n",
    "y = raw_wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ae465",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc70ec",
   "metadata": {},
   "source": [
    "### 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b99b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split              # 데이터 분할을 위한 함수\n",
    "from sklearn.preprocessing import StandardScaler                  # 데이터 표준화를 위한 함수\n",
    "\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0) # 데이터 분할\n",
    "\n",
    "std_scale = StandardScaler()                                      # 표준화 스케일러 선언\n",
    "std_scale.fit(X_tn)                                               # 트레이닝 피처(데이터)를 기준으로 표준화 스케일러 적합\n",
    "\n",
    "X_tn_std = std_scale.transform(X_tn)                              # 트레인, 테스트 데이터를 표준화 스케일러 처리\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9de511",
   "metadata": {},
   "source": [
    "### 데이터 학습 (베이스러너: SVM, Gnb | 메타러너: LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be35818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('svm', SVC(kernel='linear', random_state=0)),\n",
       "                               ('gnb', GaussianNB())],\n",
       "                   final_estimator=LogisticRegression(random_state=0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('svm', base_clf1),('gnb', base_clf2)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) # 분류 문제를 해결해야 할 경우 StackingRegressor 사용\n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd9156",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3205bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 0 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0 2\n",
      " 1 1 2 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "print(pred_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639cdb8",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901af3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ea91",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a91b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 1 19  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa8933",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "313190f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46761be3",
   "metadata": {},
   "source": [
    "### 결과: 0.9555\n",
    "\n",
    "오 역시 그렇고 그런 성능이 나왔습니다. (90%대의 성능에 너무 익숙해진건 아닐까...?)\n",
    "\n",
    "비슷한 데이터 분포로 여러 데이터들을 만들어서 실험해 볼 수 있으면 좋을텐데.\n",
    "\n",
    "이어서 다른 모형들의 조합으로도 해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385a861",
   "metadata": {},
   "source": [
    "# 실험- 학습기 개수 변경\n",
    "## 실험1 : 베이스 학습기를 SVC만 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d562a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기- SVM만 사용했을 경우 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "# base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('svm', base_clf1)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기- SVM만 사용했을 경우 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea52c6",
   "metadata": {},
   "source": [
    "*?????????? 머선일이고?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93a9cd",
   "metadata": {},
   "source": [
    "## 실험2: 베이스 학습기를 GaussianNB만 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bfaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기- 가우시안 나이브 베이즈만 사용했을 경우 정확도:  0.9333333333333333\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.95      0.94        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "# base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', base_clf2)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기- 가우시안 나이브 베이즈만 사용했을 경우 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff8e2b",
   "metadata": {},
   "source": [
    "### 위의 실험 결과\n",
    "\n",
    "유방암 분류하는 것과 비슷하게, 서포트 벡터 머신을 사용했을 때 보다 나이브 베이즈 모형을 베이스 학습기로 사용했을 때 성능이 더 좋지 않게 나왔다.\n",
    "\n",
    "문제는 SVM을 베이스 학습기로 사용했을 때의 성능이 1.0이 나와버렸다는 것인데, 이 분류를 위해서 가장 잘 맞는 모형인 것일까?\n",
    "\n",
    "좋은 데이터가 메타 학습기에 들어갔기 때문에 정확도가 높게 나왔겠지?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749aeca7",
   "metadata": {},
   "source": [
    "# 실험3: 학습기 순서 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efc3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기 순서 변경 후 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', base_clf2), ('svc', base_clf1)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기 순서 변경 후 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83806cc6",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "마찬가지로 순서가 상관이 없음이 밝혀진 것 같다. 베이스 러너- 메타 러너의 순서로 가긴 하지만, 베이스 러너들 간에는 순서 없이 말그대로 결과를 종합하는 것이기 때문인 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd9432",
   "metadata": {},
   "source": [
    "# 실험- 기본 학습기와 메타 학습기 조합 변경\n",
    "\n",
    "베이스 학습기들의 결과가 나온 것을 메타 학습기가 받는다고 했을 때, \n",
    "\n",
    "같은 종류의 학습기가 순차적으로 데이터를 받아 분류한다면 결과가 어떨지에 대한 궁금증과,\n",
    "\n",
    "세 가지 분류 알고리즘들의 조합에 따라 이 데이터 셋에서는 어떤 성능차이가 있을지 궁금해졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e10aea",
   "metadata": {},
   "source": [
    "## 실험4: 셋 중 메타 학습기를 변경했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0255780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 학습기:  SVM\n",
      "베이스 학습기:  Gaussian Naive Bayes, Logistic Regression\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "메타 학습기:  Gaussian Naive Bayes\n",
      "베이스 학습기:  SVM, Logistic Regression\n",
      "모델 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "clf_svc = svm.SVC(kernel = 'linear', random_state = 0)\n",
    "clf_gnb = GaussianNB()\n",
    "clf_lr = LogisticRegression(random_state = 0)\n",
    "\n",
    "\n",
    "# 메타 학습기가 SVC 일 때\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', clf_gnb), ('lr', clf_lr)], \n",
    "                                  final_estimator = svm.SVC(kernel = 'linear', random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기: \", \"SVM\")\n",
    "print(\"베이스 학습기: \", \"Gaussian Naive Bayes, Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# 메타 학습기가 Naive Bayes 일 때\n",
    "clf_stacking = StackingClassifier(estimators = [('svc', clf_svc), ('lr', clf_lr)], final_estimator = GaussianNB()) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기: \", \"Gaussian Naive Bayes\")\n",
    "print(\"베이스 학습기: \", \"SVM, Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d733b",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "신기한 결과가 나왔다. 메타 러너가 서포트 벡터 머신이라 하더라도 가우시안 나이브 베이즈가 베이스 학습기로 들어있을 때의 성능은 그저 그랬다. \n",
    "\n",
    "처음의 기본 설계 모델과 같은 성능과 같은 성능이다. 처음 모델의 성능을 보자면,\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      1.00      0.97        16\n",
    "           1       1.00      0.90      0.95        21\n",
    "           2       0.89      1.00      0.94         8\n",
    "\n",
    "    accuracy                           0.96        45\n",
    "   macro avg       0.94      0.97      0.95        45\n",
    "weighted avg       0.96      0.96      0.96        45\n",
    "```\n",
    "\n",
    "실제로 정확도나 재현율도 클래스 별로 같게 나왔다. 베이스 러너간의 우위가 있지 않음에도, 성능의 차이에 영향을 이만큼 줄 만큼의 차이가 있음을 볼 수 있었다.\n",
    "\n",
    "그렇다면 정말 같은 아이들끼리 붙여봤을떄, 어떨까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89595e9",
   "metadata": {},
   "source": [
    "## 실험5: 베이스 학습기와 메타 학습기가 같은 모형일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2ec200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 학습기 = 베이스 학습기:  Logistic Regression\n",
      "모델 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "========================================================\n",
      "메타 학습기 = 베이스 학습기:  SVM\n",
      "모델 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "========================================================\n",
      "메타 학습기 = 베이스 학습기:  Gaussian Naive Bayes\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.97      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "clf_svc = svm.SVC(kernel = 'linear', random_state = 0) \n",
    "clf_gnb = GaussianNB()\n",
    "clf_lr = LogisticRegression(random_state = 0)\n",
    "\n",
    "\n",
    "# LogisticRegression\n",
    "clf_stacking = StackingClassifier(estimators = [('lr', clf_lr)], \n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# SVM\n",
    "clf_stacking = StackingClassifier(estimators = [('svc', clf_svc)],\n",
    "                                  final_estimator = svm.SVC(kernel = 'linear', random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"SVM\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', clf_gnb)], \n",
    "                                  final_estimator = GaussianNB()) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"Gaussian Naive Bayes\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042b4c7",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "다양한 피처들을 데리고 분류 문제를 품에 있어서 Gaussian Naive Bayes보다는 LogisticRegression과 SupportVectorMachine이 더 나은지도 모른다는 생각을 들게하는 실험 결과였다.\n",
    "\n",
    "처음 내가 접했던, iris 데이터를 가지고도 해보아야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
