{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# 머신러닝 with Python \n",
    "## 09 앙상블 학습 스태킹 실습 - breast_cancer 데이터\n",
    "\n",
    "##### 스태킹 알고리즘을 활용하여 유방암 여부를 예측하는 모형을 만들어본다.\n",
    "\n",
    "책 p.295~ \n",
    "\n",
    "---\n",
    "\n",
    "하단부 실험에서는 학습기 종류 자체나 학습의 순서 등을 변경하는 실험을 진행하였다.\n",
    "\n",
    "> 배운점1: 같은 데이터이고 같은 모형들을 이용한다 하더라도 어떤 조합이냐에 따라 성능이 현저히 다르다.\n",
    "\n",
    "> 배운점2: 데이터 특성상 특정 모델이 특정 데이터에 성능이 안좋게 나올 가능성이 있다.\n",
    "\n",
    "> 배운점3: 서포트 벡터 머신으로만 이루어진 모델의 결과가 가장 좋게 나왔고, 가우시안 나이브 베이즈 모형으로만 이루어진 모델의 결과가 가장 안좋게 나왔는데, 이 이유를 알기 위해선 데이터의 특성과 모형의 특성들을 대조하면서 비교해보아야 알 수 있을 것 같다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022679e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e3ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "raw_breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fee972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 내 피처 살펴보기\n",
    "raw_breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "### 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_breast_cancer.data\n",
    "y = raw_breast_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ae465",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc70ec",
   "metadata": {},
   "source": [
    "### 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b21920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split              # 데이터 분할을 위한 함수\n",
    "from sklearn.preprocessing import StandardScaler                  # 데이터 표준화를 위한 함수\n",
    "\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0) # 데이터 분할\n",
    "\n",
    "std_scale = StandardScaler()                                      # 표준화 스케일러 선언\n",
    "std_scale.fit(X_tn)                                               # 트레이닝 피처(데이터)를 기준으로 표준화 스케일러 적합\n",
    "\n",
    "X_tn_std = std_scale.transform(X_tn)                              # 트레인, 테스트 데이터를 표준화 스케일러 처리\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9de511",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be35818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('svm', SVC(kernel='linear', random_state=0)),\n",
       "                               ('gnb', GaussianNB())],\n",
       "                   final_estimator=LogisticRegression(random_state=0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('svm', base_clf1),('gnb', base_clf2)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) # 분류 문제를 해결해야 할 경우 StackingRegressor 사용\n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd9156",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3205bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "print(pred_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639cdb8",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901af3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ea91",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a91b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  3]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa8933",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "313190f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        53\n",
      "           1       0.97      0.98      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.97      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8f9c4",
   "metadata": {},
   "source": [
    "### 결과: 0.965034965034965\n",
    "\n",
    "\n",
    "생각보다 좋은 성능은 나오지 않았음을 느꼈는데... 개인적으로 기대를 했으나 왜 이런 결과가 나올 수 밖에 없었던 걸까?\n",
    "\n",
    "몇가지를 만져보며 실험을 진행해보았다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad92ee",
   "metadata": {},
   "source": [
    "# 실험- 학습기 개수 변경\n",
    "## 실험1 : 베이스 학습기를 SVC만 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35a291a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기- SVM만 사용했을 경우 정확도:  0.972027972027972\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        53\n",
      "           1       0.98      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "# base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('svm', base_clf1)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기- SVM만 사용했을 경우 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ec524",
   "metadata": {},
   "source": [
    "## 실험2: 베이스 학습기를 GaussianNB만 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d79efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기- 가우시안 나이브 베이즈만 사용했을 경우 정확도:  0.916083916083916\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        53\n",
      "           1       0.93      0.93      0.93        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.91      0.91      0.91       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "# base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', base_clf2)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기- 가우시안 나이브 베이즈만 사용했을 경우 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e498db",
   "metadata": {},
   "source": [
    "### 위의 실험 결과\n",
    "\n",
    "베이스 학습기로 서포트 벡터 머신을 사용했을 떄보다 나이브 베이즈 모형을 사용했을때의 성능이 훨씬 좋지 않은 것으로 나왔다. \n",
    "\n",
    "많이 차이나지 않을 것이라는 생각과 달랐다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a3253",
   "metadata": {},
   "source": [
    "# 실험- 학습기 순서 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913bab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베이스 학습기 순서 변경 후 정확도:  0.965034965034965\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        53\n",
      "           1       0.97      0.98      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.97      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm                                   # 베이스 학습기로 서포트 벡터 머신, 가우시안 나이브 베이즈\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression       # 메타 학습기로 로지스틱 회귀 분석 모형 사용\n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "\n",
    "base_clf1 = svm.SVC(kernel = 'linear', random_state = 0)  # 베이스 학습기 모형 설정\n",
    "base_clf2 = GaussianNB()\n",
    "\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', base_clf2), ('svc', base_clf1)],   # 개별 학습기 넣은 최종 모형\n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)                          # 데이터 적합\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"베이스 학습기 순서 변경 후 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fcd63",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "베이스 학습기 자체의 순서는 상관이 없음을 확인할 수 있었다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed21d606",
   "metadata": {},
   "source": [
    "# 실험- 기본 학습기와 메타 학습기 조합 변경\n",
    "\n",
    "베이스 학습기들의 결과가 나온 것을 메타 학습기가 받는다고 했을 때, \n",
    "\n",
    "같은 종류의 학습기가 순차적으로 데이터를 받아 분류한다면 결과가 어떨지에 대한 궁금증과,\n",
    "\n",
    "세 가지 분류 알고리즘들의 조합에 따라 이 데이터 셋에서는 어떤 성능차이가 있을지 궁금해졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805f5b6",
   "metadata": {},
   "source": [
    "## 실험3: 셋 중 메타 학습기를 변경했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7964f250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 학습기:  SVM\n",
      "베이스 학습기:  Gaussian Naive Bayes, Logistic Regression\n",
      "모델 정확도:  0.965034965034965\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        53\n",
      "           1       0.97      0.98      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.97      0.96       143\n",
      "\n",
      "========================================================\n",
      "메타 학습기:  Gaussian Naive Bayes\n",
      "베이스 학습기:  SVM, Logistic Regression\n",
      "모델 정확도:  0.9370629370629371\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92        53\n",
      "           1       0.97      0.93      0.95        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.94      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "clf_svc = svm.SVC(kernel = 'linear', random_state = 0)\n",
    "clf_gnb = GaussianNB()\n",
    "clf_lr = LogisticRegression(random_state = 0)\n",
    "\n",
    "\n",
    "# 메타 학습기가 SVC 일 때\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', clf_gnb), ('lr', clf_lr)], \n",
    "                                  final_estimator = svm.SVC(kernel = 'linear', random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기: \", \"SVM\")\n",
    "print(\"베이스 학습기: \", \"Gaussian Naive Bayes, Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# 메타 학습기가 Naive Bayes 일 때\n",
    "clf_stacking = StackingClassifier(estimators = [('svc', clf_svc), ('lr', clf_lr)], final_estimator = GaussianNB()) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기: \", \"Gaussian Naive Bayes\")\n",
    "print(\"베이스 학습기: \", \"SVM, Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe69a6",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "0.9370! 최종 학습기가 가우시안 나이브 베이즈일 경우 성능이 많이 낮게 나온 것을 볼 수 있다.\n",
    "\n",
    "가우시안 나이브 베이즈와 로지스틱 회귀 분류 학습기를 스태킹 했을때(0.9160)처럼 낮은 성능이다.\n",
    "\n",
    "하지만 처음의 실습에서나, 방금 위에서 실시했던 것 처럼 서포트 벡터 머신이나 로지스틱 회귀 분류 학습기를 메타 학습기로 얹었을 경우는 나이브 베이즈가 함께 있어도 일정 수준의 성능이 나왔다.\n",
    "\n",
    "그럼에도, 서포트 벡터 머신과 로지스틱 회귀 분류 학습기를 스태킹한 상태(0.9720)가 스태킹으로 현재 데이터를 분류한 것들 중에서는 가장 성능이 높게 나온 것을 보면,\n",
    "\n",
    "가우시안 나이브 베이즈는 현재 데이터를 올바르게 분류하는데 적합하지 않은 분류 모형인지 모르겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089125e",
   "metadata": {},
   "source": [
    "## 실험4: 베이스 학습기와 메타 학습기가 같은 모형일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bf6da79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 학습기 = 베이스 학습기:  Logistic Regression\n",
      "모델 정확도:  0.965034965034965\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        53\n",
      "           1       0.97      0.98      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.97      0.96       143\n",
      "\n",
      "========================================================\n",
      "메타 학습기 = 베이스 학습기:  SVM\n",
      "모델 정확도:  0.972027972027972\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        53\n",
      "           1       0.98      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "========================================================\n",
      "메타 학습기 = 베이스 학습기:  Gaussian Naive Bayes\n",
      "모델 정확도:  0.9090909090909091\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88        53\n",
      "           1       0.93      0.92      0.93        90\n",
      "\n",
      "    accuracy                           0.91       143\n",
      "   macro avg       0.90      0.90      0.90       143\n",
      "weighted avg       0.91      0.91      0.91       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import StackingClassifier           # 스태킹 분류 모형\n",
    "\n",
    "clf_svc = svm.SVC(kernel = 'linear', random_state = 0) \n",
    "clf_gnb = GaussianNB()\n",
    "clf_lr = LogisticRegression(random_state = 0)\n",
    "\n",
    "\n",
    "# LogisticRegression\n",
    "clf_stacking = StackingClassifier(estimators = [('lr', clf_lr)], \n",
    "                                  final_estimator = LogisticRegression(random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"Logistic Regression\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# SVM\n",
    "clf_stacking = StackingClassifier(estimators = [('svc', clf_svc)],\n",
    "                                  final_estimator = svm.SVC(kernel = 'linear', random_state = 0)) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"SVM\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)\n",
    "print(\"========================================================\")\n",
    "\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "clf_stacking = StackingClassifier(estimators = [('gnb', clf_gnb)], \n",
    "                                  final_estimator = GaussianNB()) \n",
    "\n",
    "clf_stacking.fit(X_tn_std, y_tn)\n",
    "\n",
    "pred_stacking = clf_stacking.predict(X_te_std)\n",
    "accuracy = accuracy_score(y_te, pred_stacking)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_te, pred_stacking)\n",
    "class_report = classification_report(y_te, pred_stacking)\n",
    "\n",
    "print(\"메타 학습기 = 베이스 학습기: \", \"Gaussian Naive Bayes\")\n",
    "print(\"모델 정확도: \", accuracy)\n",
    "print(\"모델 분류 리포트\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17970e4c",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "같은 모형을 베이스 학습기와 메타 학습기로 붙이는 일을 해보았는데, \n",
    "\n",
    "실제로 서포트 벡터 머신으로만 이루어진 모델의 결과가 가장 좋게 나왔고, 가우시안 나이브 베이즈 모형으로만 이루어진 모델의 결과가 가장 안좋게 나왔다. \n",
    "\n",
    "다른 실험 결과들 중에 0.9090의 수준인데 이를 높이기 위해서는 어떤 옵션들을 만져야 할지, 만져서 성능이 올라가기는 할지 궁금하다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
