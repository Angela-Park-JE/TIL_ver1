{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# 머신러닝 with Python \n",
    "## 09 앙상블 학습 배깅(Bootstrap aggregating) 실습- wine data set\n",
    "\n",
    "##### 배깅 알고리즘을 이용하여 나이브 베이즈 모델을 활용, 와인 데이터를 분류하는 모형을 만들어본다.\n",
    "\n",
    "책 p.267~ \n",
    "\n",
    "---\n",
    "\n",
    "하단부에서는 분류기의 개수에 따른 성능의 변화를 실험해 보았다.\n",
    "\n",
    "> 배운점1: 분류기 개수가 성능에 영향을 미친다. 분류기 개수가 늘어날수록 일정 수준까지 성능이 떨어지고 멈췄다.\n",
    "\n",
    "> 배운점2: 개수가 적고 성능이 좋다고 하더라도 해당 모델이 실제로 unseen 데이터 대응이 좋은지는 미지수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022679e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e3ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf788f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_wine = datasets.load_wine() # 와인 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4be6bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 살펴보기\n",
    "raw_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fee972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_wine.feature_names      # 데이터 셋 내 피처 이름들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542eee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "### 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_wine.data\n",
    "y = raw_wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ae465",
   "metadata": {},
   "source": [
    "### 트레이닝/테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acca5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                 # 분할을 위해 필요한 함수\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)    # 분리. randomstate는 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc70ec",
   "metadata": {},
   "source": [
    "### 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a771eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler         # 데이터 표준화를 위한 함수\n",
    "std_scale = StandardScaler()                             # 표준화 스케일러 지정\n",
    "std_scale.fit(X_tn)                                      # 트레이닝 피처를 기준으로 표준화를 적합 시도\n",
    "\n",
    "X_tn_std = std_scale.transform(X_tn) \n",
    "X_te_std = std_scale.transform(X_te)                     # 트레인, 테스트 데이터 각각 적합시킨 표준화에 맞게 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9de511",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2599e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=GaussianNB(), random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB               # 가우시안 나이브 베이즈 개별 분류기\n",
    "from sklearn.ensemble import BaggingClassifier           # 배깅 앙상블을 사용하여 분류\n",
    "\n",
    "# 배깅을 활용한 분류기 생성\n",
    "clf_bagging_gnb = BaggingClassifier(base_estimator = GaussianNB(),  # base_estimator : 개별 학습기 입력\n",
    "                                    n_estimators = 10,              # n_estimator : 개별 학습기의 개수\n",
    "                                    random_state = 0)               # 고정\n",
    "\n",
    "clf_bagging_gnb.fit(X_tn_std, y_tn)                                 # 적합시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd9156",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3205bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 0 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0 2\n",
      " 1 1 2 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred_bagging_gnb = clf_bagging_gnb.predict(X_te_std)                # std된 테스트 피처 데이터를 넣고 실행하여 결과 확인 \n",
    "print(pred_bagging_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639cdb8",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901af3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_bagging_gnb)                   # 실제값과 예측값을 넣음\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ea91",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a91b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 1 19  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_bagging_gnb)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa8933",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "313190f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_bagging_gnb)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d758781",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "적당한 정확도군요. 그럼 여기서 의문이 드는 것이 분류기의 개수와 분류기의 종류인데 종류는 노트북을 따로 만들기로 하고 분류기의 개수를 변경시켜봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee820a",
   "metadata": {},
   "source": [
    "# 실험: 분류기의 개수와 성능\n",
    "\n",
    "## 실험1: 분류기가 10개에서 5개로 반토막이 났을 때 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f9625e",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cb6569d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=GaussianNB(), n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB               # 가우시안 나이브 베이즈 개별 분류기\n",
    "from sklearn.ensemble import BaggingClassifier           # 배깅 앙상블을 사용하여 분류\n",
    "\n",
    "# 배깅을 활용한 분류기 생성\n",
    "clf_bagging_gnb = BaggingClassifier(base_estimator = GaussianNB(),  # base_estimator : 개별 학습기 입력\n",
    "                                    n_estimators = 5,               # n_estimator : 개별 학습기의 개수\n",
    "                                    random_state = 0)               # 고정\n",
    "\n",
    "clf_bagging_gnb.fit(X_tn_std, y_tn)                                 # 적합시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45f4f3",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce81e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 0 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0 2\n",
      " 1 1 2 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred_bagging_gnb = clf_bagging_gnb.predict(X_te_std)                # std된 테스트 피처 데이터를 넣고 실행하여 결과 확인 \n",
    "print(pred_bagging_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbaca80",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee7d3687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_bagging_gnb)                   # 실제값과 예측값을 넣음\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b78f86",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e06c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 1 20  0]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_bagging_gnb)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5956a",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "375069e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_bagging_gnb)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ad3ff",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "분류기의 개수가 반으로 줄어들었는데 성능이 오히려 올라갔다. 클래스 1의 분류가 더 정확해졌다.\n",
    "\n",
    "분류기의 개수가 많을 수록 정확도가 떨어질 수 있다.\n",
    "\n",
    "여기서 생각해 볼 수 있는 가설은\n",
    "\n",
    "1. 분류기의 개수에 따라 과적합의 문제가 일어날 수 있다. 오버피팅이 된건지 아닌지는 알 수 없다.\n",
    "\n",
    "2. 분류기의 개수가 많을 수록 꼭 수치적인 성능이 좋아지는 것은 아니다.\n",
    "\n",
    "---\n",
    "\n",
    "이어서 실험을 분류기의 개수를 더 줄여본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc6c90",
   "metadata": {},
   "source": [
    "## 실험2: 분류기가 5개에서 2개로 극단적으로 줄었을 때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab7eff",
   "metadata": {},
   "source": [
    "### 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f57213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=GaussianNB(), n_estimators=2, random_state=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB               # 가우시안 나이브 베이즈 개별 분류기\n",
    "from sklearn.ensemble import BaggingClassifier           # 배깅 앙상블을 사용하여 분류\n",
    "\n",
    "# 배깅을 활용한 분류기 생성\n",
    "clf_bagging_gnb = BaggingClassifier(base_estimator = GaussianNB(),  # base_estimator : 개별 학습기 입력\n",
    "                                    n_estimators = 2,               # n_estimator : 개별 학습기의 개수\n",
    "                                    random_state = 0)               # 고정\n",
    "\n",
    "clf_bagging_gnb.fit(X_tn_std, y_tn)                                 # 적합시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ed1d1",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00a1c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0 2\n",
      " 1 1 2 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred_bagging_gnb = clf_bagging_gnb.predict(X_te_std)                # std된 테스트 피처 데이터를 넣고 실행하여 결과 확인 \n",
    "print(pred_bagging_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2b64f",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173b07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, pred_bagging_gnb)                   # 실제값과 예측값을 넣음\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c66fce",
   "metadata": {},
   "source": [
    "### confusion matrix 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a43319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, pred_bagging_gnb)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81cf2a",
   "metadata": {},
   "source": [
    "### 분류 리포트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc8bc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, pred_bagging_gnb)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ef075",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "분류기의 개수가 더 줄었더니 정확도가 1.0이 되어버렸다.\n",
    "\n",
    "실제로 개수가 줄어듦에 따라 성능이 높아진건 좋지만, 성능이 높다는 것은 그만큼 unseen 데이터에 대한 정확도가 낮을 가능성이 높다는 생각이 든다.\n",
    "\n",
    "---\n",
    "\n",
    "실험 분류기의 개수를 2~10개로 돌려본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde13c7",
   "metadata": {},
   "source": [
    "## 실험3: 분류기 개수 2~10개 각각 성능 체크해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3afd18ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 분류기 개수:  2\n",
      "모델 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  3\n",
      "모델 정확도:  1.0\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  4\n",
      "모델 정확도:  0.9777777777777777\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  5\n",
      "모델 정확도:  0.9777777777777777\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  6\n",
      "모델 정확도:  0.9777777777777777\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  7\n",
      "모델 정확도:  0.9777777777777777\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  8\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  9\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  10\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB               # 가우시안 나이브 베이즈 개별 분류기\n",
    "from sklearn.ensemble import BaggingClassifier           # 배깅 앙상블을 사용하여 분류\n",
    "from sklearn.metrics import accuracy_score               # 정확도 테스트 함수\n",
    "from sklearn.metrics import classification_report        # 분류 리포트 확인을 위한 함수\n",
    "\n",
    "\n",
    "for i in range(2, 11):\n",
    "    # 배깅을 활용한 분류기 생성\n",
    "    clf_bagging_gnb = BaggingClassifier(base_estimator = GaussianNB(), \n",
    "                                        n_estimators = i,               # n_estimator : 개별 학습기의 개수\n",
    "                                        random_state = 0)               # 고정\n",
    "    \n",
    "    # 데이터 학습\n",
    "    clf_bagging_gnb.fit(X_tn_std, y_tn)\n",
    "\n",
    "    # 데이터 예측\n",
    "    pred_bagging_gnb = clf_bagging_gnb.predict(X_te_std) \n",
    "    \n",
    "    # 데이터 정확도 평가\n",
    "    accuracy = accuracy_score(y_te, pred_bagging_gnb)\n",
    "    \n",
    "    # 분류 리포트 확인\n",
    "    class_report = classification_report(y_te, pred_bagging_gnb)\n",
    "    \n",
    "    # 모델 상황 확인\n",
    "    \n",
    "    print(\"모델 분류기 개수: \", i )\n",
    "    print(\"모델 정확도: \", accuracy)\n",
    "    print(\"모델 분류 리포트\")\n",
    "    print(class_report)\n",
    "    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779e9f7",
   "metadata": {},
   "source": [
    " ### 결과\n",
    " \n",
    " 실험 결과를 보면 \n",
    " \n",
    " 모델 분류기 개수가 [2,3], [4,5,6,7],[8,9,10] 이렇게 정확도가 같게 나왔다. 실제로 클래스별 f1-score도 같게 나왔다.\n",
    " \n",
    " 분류기의 개수가 늘어날수록 정확도가 떨어지는 이유에 대해서 제대로 할 수는 없을까?\n",
    " \n",
    " 그럼 10보다 클 때는 어떻게 될까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d17b47",
   "metadata": {},
   "source": [
    "## 실험3: 분류기가 11개 이상일 떄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96c8ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 분류기 개수:  11\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  12\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  13\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  14\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  15\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  16\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  17\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  18\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  19\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n",
      "모델 분류기 개수:  20\n",
      "모델 정확도:  0.9555555555555556\n",
      "모델 분류 리포트\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB               # 가우시안 나이브 베이즈 개별 분류기\n",
    "from sklearn.ensemble import BaggingClassifier           # 배깅 앙상블을 사용하여 분류\n",
    "from sklearn.metrics import accuracy_score               # 정확도 테스트 함수\n",
    "from sklearn.metrics import classification_report        # 분류 리포트 확인을 위한 함수\n",
    "\n",
    "\n",
    "for i in range(11, 21):\n",
    "    # 배깅을 활용한 분류기 생성\n",
    "    clf_bagging_gnb = BaggingClassifier(base_estimator = GaussianNB(), \n",
    "                                        n_estimators = i,               # n_estimator : 개별 학습기의 개수\n",
    "                                        random_state = 0)               # 고정\n",
    "    \n",
    "    # 데이터 학습\n",
    "    clf_bagging_gnb.fit(X_tn_std, y_tn)\n",
    "\n",
    "    # 데이터 예측\n",
    "    pred_bagging_gnb = clf_bagging_gnb.predict(X_te_std) \n",
    "    \n",
    "    # 데이터 정확도 평가\n",
    "    accuracy = accuracy_score(y_te, pred_bagging_gnb)\n",
    "    \n",
    "    # 분류 리포트 확인\n",
    "    class_report = classification_report(y_te, pred_bagging_gnb)\n",
    "    \n",
    "    # 모델 상황 확인\n",
    "    \n",
    "    print(\"모델 분류기 개수: \", i )\n",
    "    print(\"모델 정확도: \", accuracy)\n",
    "    print(\"모델 분류 리포트\")\n",
    "    print(class_report)\n",
    "    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9dd562",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "아주 재밌는 결과가 나왔다. 11이상이 되어도 더 이상 정확도가 떨어지지 않았다.\n",
    "\n",
    "그럼 이 앙상블 모델에서는 가장 최적의 결과를 무엇으로 생각할까?\n",
    "\n",
    "정확도가 가장 높으면서, 분류기의 개수가 적으면 컴퓨팅 파워를 적게 소모할 것이니 가장 적은 분류기의 개수여야 할 것이다.\n",
    "\n",
    "그렇다면 분류기의 개수가 2개인게 좋은 것일까? \n",
    "\n",
    "다른 분류기 종류에서도 이런 결과가 나올까?\n",
    "\n",
    "--- \n",
    "\n",
    "이어서 다른 분류기로 wine데이터를 분류해보아야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
