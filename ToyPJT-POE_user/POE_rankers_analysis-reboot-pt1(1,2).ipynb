{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f618f4ba",
   "metadata": {},
   "source": [
    "# POE user analyzing project\n",
    "###### **Data reference and questions are here: https://www.kaggle.com/datasets/gagazet/path-of-exile-league-statistic**\n",
    "\n",
    "---\n",
    "Hi, I'm Angela. ðŸ˜Š I'm a novice in data analysis.  I'm a novice in data analysis. I'm interested in the video games, mobility, culture, and content industry. I hope to become a data scientist with anomaly detection and anti-cheating. I hope that my analysis will have a positive impact on the world at least a little bit.  \n",
    "\n",
    "This is my first Kaggle-data analyzing project on my own. I played(?) with this data for almost a month or more freely, and I finish it to start to answer these questions partially. Finally, I can close the analysis joyfully.\n",
    "I analyzed this data set with my thoughts and what I learned (as if I were a game analyst ðŸ˜†).  \n",
    "_ps. English may seem a little awkward because it is not my first language. I'm sorry. And I used the word 'average' more than the word 'mean' because I wanted to communicate more clearly in my hectic writing. 'mean' is so mean to 'average', 'mean' means 'mean' and... just joking._ ðŸ¤ª\n",
    "\n",
    "---\n",
    "##### **Questions for participants**\n",
    "\n",
    "1. A total number of players in each division, usage of each class in descending order.\n",
    "2. Some of the players streaming their game (twitch column). Do they play better than people, who does not?\n",
    "3. Predict chance to be at top 30 in each division, if we are Necromancer. With and without stream.\n",
    "4. Average number of finished challanges for each division, show division with highest and lowest average challanges.\n",
    "5. Show dependency between level and class of died characters. Only for HC divisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7d959",
   "metadata": {},
   "source": [
    "##### **Contents list**\n",
    "---\n",
    "1. data remaking (dummy etc)\n",
    "2. data distribution (all round veiwing)\n",
    "3. questions : result, processing, add commentary(ê·¸ì™¸ ì¶”ê°€ ì´ì•¼ê¸° ë° ë¶€ì¡±í•œ ê²ƒ í•„ìš”í•œ ê²ƒ ê°œì„  ë°©í–¥)\n",
    "4. what I analized with this dataset(my files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e85c0",
   "metadata": {},
   "source": [
    "## Importing Data and Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# import time as time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joypy import joyplot\n",
    "\n",
    "# visualization setting\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "\n",
    "np.random.seed(0)\n",
    "# tf.random.set_seed(0)\n",
    "\n",
    "# version check\n",
    "print(sns.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "# print(tf.__version__)\n",
    "# print(keras.__version__)\n",
    "\n",
    "data = pd.read_csv(\"poe_stats.csv\")\n",
    "\n",
    "# if you need\n",
    "# !pip install joypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7434e74",
   "metadata": {},
   "source": [
    "## Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a2c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# options about float\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef79755",
   "metadata": {},
   "source": [
    "# 1. rankers by ladder\n",
    "---\n",
    "##### Q1. A total number of players in each division, usage of each class in descending order.\n",
    "\n",
    "First I understood that question and wanted to know about each class ratio in each ladder. And it is true maybe.  \n",
    "(But... I think this question has to be more clear about 'players'. Because there're quite many users who have multiple characters which are on ranked.)  \n",
    "\n",
    "So I categorized the meaning of 'players' as characters and users. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad23c6",
   "metadata": {},
   "source": [
    "## 1-1. ids(characters) and users in each ladder\n",
    "If we set the meaning of â€˜playersâ€™ to â€˜charactersâ€™, the number of unique ids would be the answer. Also, if we set the meaning of it to 'users', the number of unique accounts would be the answer.  \n",
    "Each division has different numbers of ids(characters) and accounts, and there are some empty values among the 15000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id, rank, account unique numbers\n",
    "\n",
    "modes = ['Harbinger', 'Hardcore Harbinger', 'SSF Harbinger', 'SSF Harbinger HC']\n",
    "\n",
    "for i in modes:\n",
    "    print(\"* ladder:\", i)\n",
    "    print(\"  number of unique id:\", df[df['ladder'] == i]['id'].nunique())\n",
    "    print(\"  number of unique rank:\", df[df['ladder'] == i]['rank'].nunique())\n",
    "    print(\"  number of unique account:\", df[df['ladder'] == i]['account'].nunique())\n",
    "    print(\"  id per account:\", round(df[df['ladder'] == i]['id'].nunique()/df[df['ladder'] == i]['account'].nunique(), 2))\n",
    "    print(\"  max value of the rank:\", df[df['ladder'] == i]['rank'].max())\n",
    "    if i != 'SSF Harbinger HC':\n",
    "        print('---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41894d7d",
   "metadata": {},
   "source": [
    "## 1-2. account numbers and ratios of each class in each ladder\n",
    "We can all class and ladder mode put together in one data frame for analysis, and also make them separately to see more comfortably by descending order.  \n",
    "First, we can compare the number of specific classes's `account` with other ladders easily.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804bfa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. \n",
    "# pivot by class and ladder to one Data frame\n",
    "\n",
    "df_acc_bylad = df.pivot_table(values = 'account', index = 'ladder', columns = 'class', aggfunc = lambda x: len(x.unique()), margins=True, margins_name=\"total\", fill_value = 0)\n",
    "\n",
    "# transpose to make class as row\n",
    "df_acc_bylad = df_acc_bylad.sort_values(ascending = False, by = 'ladder').transpose()\n",
    "df_acc_bylad.reset_index(drop = False, inplace = True)\n",
    "\n",
    "# drop 'index = 26 'total' row '\n",
    "df_acc_bylad.drop(index = 26, inplace = True)\n",
    "df_acc_bylad.sort_values('total', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e597e",
   "metadata": {},
   "source": [
    "## 1-3. [Answer] : characters numbers/ratio of each class in each ladder (descending order)\n",
    "In the second method, we can compare the number of specific classes's `id` by ladder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5a1c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì•ˆëœê²ƒ\n",
    "\n",
    "# ladders = ['Harbinger', 'Hardcore Harbinger', 'SSF Harbinger', 'SSF Harbinger HC']\n",
    "# cnt = 0\n",
    "\n",
    "# for i in ladders:\n",
    "#     s1 = df[df['ladder'] == i].groupby(by = 'class').count()['id'].sort_values(ascending = False)\n",
    "#     s2 = df[df['ladder'] == i].groupby(by = 'class').count()['id'].sort_values(ascending = False)  / df[df['ladder'] == i].shape[0] * 100\n",
    "#     tmpdf = pd.DataFrame(columns = ['numbers', 'ratio'])\n",
    "#     tmpdf['numbers'], tmpdf['ratio'] = s1, s2\n",
    "\n",
    "#     if cnt == 0:\n",
    "#         df_cl_ratio_bylad = tmpdf\n",
    "#     else:\n",
    "#         cnt += 1\n",
    "#         pd.concat([df_cl_ratio_bylad, tmpdf])\n",
    "\n",
    "# df_cl_ratio_bylad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7806a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. \n",
    "# pivot by class and ladder, and concat them to one Data frame\n",
    "\n",
    "ladders = ['Harbinger', 'Hardcore Harbinger', 'SSF Harbinger', 'SSF Harbinger HC']\n",
    "tmps = []\n",
    "\n",
    "for i in ladders:\n",
    "    s1 = df[df['ladder'] == i].groupby(by = 'class').count()['id'].sort_values(ascending = False)\n",
    "    s2 = df[df['ladder'] == i].groupby(by = 'class').count()['id'].sort_values(ascending = False) / df[df['ladder'] == i].shape[0] * 100\n",
    "    tmpdf = pd.DataFrame(columns = ['numbers', 'ratio'])\n",
    "    tmpdf['numbers'], tmpdf['ratio'] = s1, s2\n",
    "    tmps.append(tmpdf)\n",
    "\n",
    "df_cl_ratio_bylad = pd.concat(tmps, axis = 1)\n",
    "df_cl_ratio_bylad.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672944a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. \n",
    "# if you want to see ratio seperated by ladder\n",
    "\n",
    "# Harbinger\n",
    "s1 = df[df['ladder'] == 'Harbinger'].groupby(by = 'class').count()['id'].sort_values(ascending = False)\n",
    "s2 = df[df['ladder'] == 'Harbinger'].groupby(by = 'class').count()['id'].sort_values(ascending = False)  / df[df['ladder'] == 'Harbinger'].shape[0] * 100\n",
    "tmpdf = pd.DataFrame(columns = ['numbers', 'ratio'])\n",
    "tmpdf['numbers'], tmpdf['ratio'] = s1, s2\n",
    "tmpdf.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0c0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Harbinger HC\n",
    "\n",
    "s1 = df[df['ladder'] == 'Hardcore Harbinger'].groupby(by = 'class').count()['id'].sort_values(ascending = False)\n",
    "s2 = df[df['ladder'] == 'Hardcore Harbinger'].groupby(by = 'class').count()['id'].sort_values(ascending = False)  / df[df['ladder'] == 'Hardcore Harbinger'].shape[0] * 100\n",
    "tmpdf = pd.DataFrame(columns = ['numbers', 'ratio'])\n",
    "tmpdf['numbers'], tmpdf['ratio'] = s1, s2\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03079614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SSF Harbinger \n",
    "\n",
    "s1 = df[df['ladder'] == 'SSF Harbinger'].groupby(by = 'class').count()['id'].sort_values(ascending = False)\n",
    "s2 = df[df['ladder'] == 'SSF Harbinger'].groupby(by = 'class').count()['id'].sort_values(ascending = False)  / df[df['ladder'] == 'SSF Harbinger'].shape[0] * 100\n",
    "tmpdf = pd.DataFrame(columns = ['numbers', 'ratio'])\n",
    "tmpdf['numbers'], tmpdf['ratio'] = s1, s2\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763cdf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SSF Harbinger HC\n",
    "\n",
    "s1 = df[df['ladder'] == 'SSF Harbinger HC'].groupby(by = 'class').count()['id'].sort_values(ascending = False)\n",
    "s2 = df[df['ladder'] == 'SSF Harbinger HC'].groupby(by = 'class').count()['id'].sort_values(ascending = False)  / df[df['ladder'] == 'SSF Harbinger HC'].shape[0] * 100\n",
    "tmpdf = pd.DataFrame(columns = ['numbers', 'ratio'])\n",
    "tmpdf['numbers'], tmpdf['ratio'] = s1, s2\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588be4b",
   "metadata": {},
   "source": [
    "## 1-4. Visualization\n",
    "\n",
    "### 1-4-1. Characters number of each class in each division separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cha_bylad = df.pivot_table(values = 'id', index = 'ladder', columns = 'class', aggfunc = 'count', margins=True, margins_name=\"total\", fill_value = 0)\n",
    "\n",
    "# transpose to make class as row\n",
    "df_cha_bylad = df_cha_bylad.sort_values(ascending = False, by = 'ladder').transpose()\n",
    "df_cha_bylad.reset_index(drop = False, inplace = True)\n",
    "\n",
    "# drop 'index = 26 'total' row '\n",
    "df_cha_bylad.drop(index = 26, inplace = True)\n",
    "df_cha_bylad.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fd736",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if you want to see 'characters' number as seperated by ladder (case when 'Harbinger')\n",
    "\n",
    "plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.xlabel('Class name')\n",
    "plt.ylabel('Number of id')\n",
    "plt.ylim(bottom=0, top=4000)\n",
    "plt.xticks(rotation=45, fontsize=9)\n",
    "\n",
    "ax = sns.barplot(x = 'class', y = 'Harbinger', data = df_cha_bylad, palette = \"rocket\")\n",
    "for p in ax.patches: \n",
    "    ax.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width()/2., p.get_height() - 30), \n",
    "       ha='center', va='center', fontsize=10, color='black', xytext=(0, 10), \n",
    "       textcoords='offset points') \n",
    "plt.tight_layout()\n",
    "plt.title('Characters in Harbinger division')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83851e2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # if you want to see 'characters' number as seperated by ladder, others \n",
    "\n",
    "\n",
    "# # Hardcore Harbinger \n",
    "# plt.subplots(figsize = (10, 6))\n",
    "\n",
    "# plt.xlabel('Class name')\n",
    "# plt.ylabel('Number of id')\n",
    "# plt.ylim(bottom=0, top=4000)\n",
    "# plt.xticks(rotation=45, fontsize=9)\n",
    "\n",
    "# ax = sns.barplot(x = 'class', y = 'Hardcore Harbinger', data = df_cha_bylad, palette = \"rocket\")\n",
    "# for p in ax.patches: \n",
    "#     ax.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width()/2., p.get_height() - 30), \n",
    "#        ha='center', va='center', fontsize=10, color='black', xytext=(0, 10), \n",
    "#        textcoords='offset points') \n",
    "# plt.tight_layout()\n",
    "# plt.title('Characters in Hardcore Harbinger division')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # SSF Harbinger \n",
    "# plt.subplots(figsize = (10, 6))\n",
    "\n",
    "# plt.xlabel('Class name')\n",
    "# plt.ylabel('Number of id')\n",
    "# plt.ylim(bottom=0, top=4000)\n",
    "# plt.xticks(rotation=45, fontsize=9)\n",
    "\n",
    "# ax = sns.barplot(x = 'class', y = 'SSF Harbinger', data = df_cha_bylad, palette = \"rocket\")\n",
    "# for p in ax.patches: \n",
    "#     ax.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width()/2., p.get_height() - 30), \n",
    "#        ha='center', va='center', fontsize=10, color='black', xytext=(0, 10), \n",
    "#        textcoords='offset points') \n",
    "# plt.tight_layout()\n",
    "# plt.title('Characters in SSF Harbinger division')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # SSF Hardcore Harbinger \n",
    "# plt.subplots(figsize = (10, 6))\n",
    "\n",
    "# plt.xlabel('Class name')\n",
    "# plt.ylabel('Number of id')\n",
    "# plt.ylim(bottom=0, top=4000)\n",
    "# plt.xticks(rotation=45, fontsize=9)\n",
    "\n",
    "# ax = sns.barplot(x = 'class', y = 'SSF Harbinger HC', data = df_cha_bylad, palette = \"rocket\")\n",
    "# for p in ax.patches: \n",
    "#     ax.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width()/2., p.get_height() - 30), \n",
    "#        ha='center', va='center', fontsize=10, color='black', xytext=(0, 10), \n",
    "#        textcoords='offset points') \n",
    "# plt.tight_layout()\n",
    "# plt.title('Characters in SSF Hardcore Harbinger division')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff0b0e",
   "metadata": {},
   "source": [
    "### 1-4-2. Characters number by division and class \n",
    "without number texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see all of them\n",
    "\n",
    "orderlist = list(df_cha_bylad['class'])\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 16)\n",
    "plt.xlabel('Class name')\n",
    "plt.ylabel('Number of id')\n",
    "plt.ylim(bottom = 0, top = 4000)\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "sns.set_style('whitegrid')\n",
    "ax = sns.countplot(data = df, y = 'class',\n",
    "              palette=\"rocket\", edgecolor = sns.color_palette(\"dark\", 1), hue = 'ladder', order = orderlist) \n",
    "plt.tight_layout()\n",
    "plt.title('Characters in each class by divisions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea7993",
   "metadata": {},
   "source": [
    "## 1-5. Result and conclusion:\n",
    "We checked the specific number needed. And there are some preferred classes in each ladder.  \n",
    "\n",
    "In Harbinger, the most common mode, Pathfinder is the most one.  \n",
    "And Necromancer is the most preferred in Harbinger hardcore mode. (Berserk was on the same level.)  \n",
    "In SSF Harbinger, the solo mode, the most picked one is Berserker and Necromancer is also preferred too.  \n",
    "In SSF Harbinger hardcore, the most one is Necromancer and Berserker is also preferred.  \n",
    "\n",
    "- Necromancer or Berserker are preferred in some modes, but Pathfinder is the most preferred class, only in Harbinger mode.  \n",
    "- And we may have to consider that all of them(Necromancer and Berserker and Pathfinder) are one-stat classes later. (Each class is among the Intelligence, Strength, and Dexterity stat.)  \n",
    "\n",
    "â—Ž As a result, you can find the preferred class in each mode and find out 'the imbalance in performance between classes' or 'the advantageous skills in certain modes' to see if there is a problem with game balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336701c4",
   "metadata": {},
   "source": [
    "# 2. Are streamers better or not?\n",
    "---\n",
    "##### Q2. Some of the players streaming their games (twitch column). Do they play better than people who do not stream?\n",
    "\n",
    "**Before analyzing, I gave shape to the question. This was important to solve this question especially because the â€˜better playâ€™ meaning is a little ambiguous.**\n",
    "\n",
    "1. We have to set the standard of 'play better' means, so I treat the rank of characters to the 'better play'. Maybe there are more criteria like ranking of 'exp' or 'level', 'challenge' contrasts.  \n",
    "    But I just used the **rank** because they are ranked players, they are already skilled enough to not need to base their rankings on the number of challenges or levels. In addition, there are many variables that affect classes, parties, items, and skill trees to compare the players. And each mode has a different environment. On other criteria other than game modes, we cannot know and use everything in detail.  \n",
    "\n",
    "2. And there are some cases where one twitch streamer has multiple accounts or characters. And also, one user has multiple characters on a rank chart. (I discovered it when I analyze the dataset before this project.) So I assumed that one account or one twitch id means one user(the one twitch â€˜playerâ€™ has multiple accounts or characters or the one â€˜playerâ€™ has multiple characters).  \n",
    "\n",
    "3. And there're some missing rank values in each ladder. (When I analyzed the data personally, I substituted the missing data by updating it to rank only the data we have. But,) anyway, I used the original rank in this analysis.  \n",
    "\n",
    "4. Plus, And I decided to use rank, but how should we decide the ability(rank) to represent one user? My words mean, which one is more accurate, the rank average or median of several characters a user has. I thought it would be ideal if the number of data in a user's ranking was more than 30. But the reality wasn't, so we used both for this analysis.  \n",
    "\n",
    "5. And I set their highest rank as their representative values. Because it's a question of how well they do, so we can treat the best score(rank) as a kind of their performance.\n",
    "\n",
    "6. sequence\n",
    "    1. normally get the average from all dataframe\n",
    "    2. get the average from each player(user)'s average rank and compare\n",
    "    3. get the average from each player(user)'s median rank and compare\n",
    "    4. get the average from each player(user)'s highest rank and compare\n",
    "    5. statistical significance test (Mann Whitney U test)\n",
    "\n",
    "(You can skip to 2-5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitch'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06cf92f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Not streaming users\n",
    "df[df['twitch'].isna() == True].describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924fadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitch streaming users\n",
    "df[df['twitch'].isna() == False].describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf36c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see how much missing values in rank are there by ladder\n",
    "\n",
    "print(df[df['ladder'] == 'Harbinger']['rank'].nunique())\n",
    "print(df[df['ladder'] == 'Hardcore Harbinger']['rank'].nunique())\n",
    "print(df[df['ladder'] == 'SSF Harbinger']['rank'].nunique())\n",
    "print(df[df['ladder'] == 'SSF Harbinger HC']['rank'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582fdf6",
   "metadata": {},
   "source": [
    "### dividing data\n",
    "\n",
    "Let's divide the dataset as whether 'twitch' user or not.  \n",
    "And divide them by person(twitch unique value is first in the twitch column)'s average.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's divide the dataset as whether 'twitch' column is null or not\n",
    "\n",
    "# each id's rank\n",
    "df_twt = df[df['twitch'].isna() == False]\n",
    "df_twt_non = df[df['twitch'].isna() == True]\n",
    "\n",
    "# each user's mean rank\n",
    "# grouping by player and get the 'average' rank of each player streaming on twitch or not\n",
    "df_twt_mean = df_twt.pivot_table(index = 'twitch', values = 'rank', aggfunc = 'mean')\n",
    "df_twt_non_mean = df_twt_non.pivot_table(index = 'account', values = 'rank', aggfunc = 'mean')\n",
    "\n",
    "# each user's median rank\n",
    "# grouping by player and get the 'median' rank of each player streaming on twitch or not\n",
    "df_twt_med = df_twt.pivot_table(index = 'twitch', values = 'rank', aggfunc = 'median')\n",
    "df_twt_non_med = df_twt_non.pivot_table(index = 'account', values = 'rank', aggfunc = 'median')\n",
    "\n",
    "# each user's min(highest) rank\n",
    "# grouping by player and get the 'median' rank of each player streaming on twitch or not\n",
    "df_twt_min = df_twt.pivot_table(index = 'twitch', values = 'rank', aggfunc = 'min')\n",
    "df_twt_non_min = df_twt_non.pivot_table(index = 'account', values = 'rank', aggfunc = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61f0db",
   "metadata": {},
   "source": [
    "## 2-1. normal average and median of rank simply\n",
    "\n",
    "normally get the average and median from all dataframe, and checking standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54acf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twtich streamers and not streaming users's rank 'average' of each 'id'\n",
    "print(df_twt['rank'].mean())\n",
    "print(df_twt_non['rank'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twtich streamers and not streaming users's rank 'median' of each 'id'\n",
    "print(df_twt['rank'].median())\n",
    "print(df_twt_non['rank'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fecdf",
   "metadata": {},
   "source": [
    "It seems that the rank of users who stream is about 500 higher.  \n",
    "Considering the total ranking is 15,000, the difference of 500 is about one-thirty, so it's not a small difference, but it doesn't seem to be a very big difference.  \n",
    "And the median showed a bigger difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55150fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the standard deviation\n",
    "\n",
    "print(\"All users rank : \\n\", df['rank'].std())\n",
    "print(\"Streaming users rank : \\n\", df_twt['rank'].std())\n",
    "print(\"Not-streaming users rank : \\n\", df_twt_non['rank'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec1686",
   "metadata": {},
   "source": [
    "## 2-2. average by account (when we set the average to a representative value)\n",
    "\n",
    "Get the average values from each player(user)'s average rank. And check the average and median of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d042722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of users' rank average.\n",
    "# grouping by twitch and get average 'rank' of each player streaming on twitch\n",
    "df_twt_mean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833998ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by twitch and get average 'rank' of each non_streaming players\n",
    "df_twt_mean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e737f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average of each player's average rank\n",
    "print(df_twt_mean['rank'].mean())\n",
    "print(df_twt_non_mean['rank'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median of each player's average rank\n",
    "print(df_twt_mean['rank'].median())\n",
    "print(df_twt_non_mean['rank'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c983471",
   "metadata": {},
   "source": [
    "## 2-3. median rank of each player and get average(when we set the median to a representative value)\n",
    "\n",
    "Get the average from each player(user)'s median rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cac04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of users' rank median.\n",
    "# grouping by twitch and get median 'rank' of each player streaming on twitch\n",
    "df_twt_med.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by twitch and get median 'rank' of each non_streaming players\n",
    "df_twt_non_med.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average of each player's median rank\n",
    "print(df_twt_med['rank'].mean())\n",
    "print(df_twt_non_med['rank'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median of each player's median rank\n",
    "print(df_twt_med['rank'].median())\n",
    "print(df_twt_non_med['rank'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1a4a3",
   "metadata": {},
   "source": [
    "## 2-4. highest rank of each player and get average(when we set the min rank to a representative value)\n",
    "\n",
    "Get the average from each player(user)'s minimum rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4513f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of users' rank min.\n",
    "# grouping by twitch and get min 'rank' of each player streaming on twitch\n",
    "df_twt_min.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1fc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by twitch and get min 'rank' of each non_streaming players\n",
    "df_twt_non_min.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0c630",
   "metadata": {},
   "source": [
    "This could be a little smaller than other results. But I think it still has the meaning of comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b64e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average of each player's highest(min) rank\n",
    "print(df_twt_min['rank'].mean())\n",
    "print(df_twt_non_min['rank'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1590e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median of each player's highest(min) rank\n",
    "print(df_twt_min['rank'].median())\n",
    "print(df_twt_non_min['rank'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd04d4",
   "metadata": {},
   "source": [
    "If you compare them by the median, it's almost 1000 points difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ad9ab",
   "metadata": {},
   "source": [
    "## 2-5. Visualizing each value\n",
    "For convenience, I will call a user who does not stream as a 'normal' user.  \n",
    "\n",
    "And I'll show the means at the Mann-Whitney Test, with a confidence interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = [df_twt['rank'], df_twt_non['rank'], \n",
    "       df_twt_mean['rank'], df_twt_non_mean['rank'], \n",
    "       df_twt_med['rank'], df_twt_non_med['rank'],\n",
    "       df_twt_min['rank'], df_twt_non_min['rank']]\n",
    "\n",
    "x = ['Arithmetic mean - All Twitch_user', 'Arithmetic mean - All normal_user', \n",
    "     'Mean of rank average - Twitch_user', 'Mean of rank average - normal_user', \n",
    "     'Mean of rank median - Twitch_user', 'Mean of rank median - normal_user', \n",
    "     'Mean of rank minimum - Twitch_user', 'Mean of rank minimum - normal_user']\n",
    "\n",
    "y1 = [x.mean() for x in dset]\n",
    "y2 = [x.median() for x in dset]\n",
    "\n",
    "tmp1 = pd.DataFrame(columns = x, data = [y1, y2], index = ['Mean', 'Median'])\n",
    "tmp1.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7464a",
   "metadata": {},
   "source": [
    "##### visualization - median rank and distribution with boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization - median rank and distribution\n",
    "data_frames = [df_twt, df_twt_mean, df_twt_med, df_twt_min]\n",
    "data_frames_non = [df_twt_non, df_twt_non_mean, df_twt_non_med, df_twt_non_min]\n",
    "\n",
    "titles = ['Each Group ranks of character', \"Player's mean rank\", \"Player's median rank\", \"Player's highest rank\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.boxplot([data_frames[i]['rank'], data_frames_non[i]['rank']],\n",
    "               widths=0.5,\n",
    "               labels=['Streaming', 'Normal'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.text(0.8, data_frames[i]['rank'].median(), data_frames[i]['rank'].median(),\n",
    "            size=13.5, weight='bold', color='#6441a5')\n",
    "    ax.text(1.8, data_frames_non[i]['rank'].median(), data_frames_non[i]['rank'].median(),\n",
    "            size=13.5, color='black')\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da5a03",
   "metadata": {},
   "source": [
    "## 2-6. Mann Whitney U test: Statistical significance\n",
    "\n",
    "The T-test is a test about a statistical comparison of the means of two independent samples, as you know. But these are rank scales, so it's hard to treat this data as a normal t-test case. (Of course, it's hard to say that the simple process of calculating the mean and median â€˜absolutelyâ€™ doesnâ€™t have a problemâ€¦) So I decided to use Mann Whitney U Test, which is a nonparametric method.\n",
    "\n",
    "*I don't think the statistical significance is not significant for this, especially with little size data. The data size is so little so we can't discuss Gaussian distribution or etc. But I think it's meaningful just to check even if it's not used somewhere.*\n",
    "\n",
    "What I was wondering about was which one I have to use among these to reach a conclusion, `df_twt`, `df_twt_mean`, `df_twt_med`, `df_twt_min`. They have each problem with themselves.\n",
    "\n",
    "1. First, I think the `df_twt` and `df_twt_non` have a critical problem in that there are multiple characters a single user has. It can't be a real answer to the meaning(intention) of question.  \n",
    "2. Second, in case of `df_twt_mean`, there is also a problem with the average rank by each player (not one character, but a user). It's also questionable that the average itself represents the user, which makes it easier to conflict with the concept of average because it's a rank, not a score.  \n",
    "3. Third, in case of `df_twt_med`, I think the median is not bad because it is â€˜realâ€™ value. But thereâ€™s also a problem. There is a tendency to add or subtract the existence of other details.  \n",
    "4. `df_twi_min`, indicating the highest performance of each player, can be a good indicator of the problem in the desired, correct direction of this question. However, considering that there is a difference in difficulty between modes(ladder), there is a problem in that it shouldn't be treated as the same rank is the same ability.\n",
    "\n",
    "\n",
    "After much consideration, we decided to count the number of drops and the degree of drops for Twitch users **who have a lower value than the mean of the normal user for each method**. I would be grateful if I can get advice about this. ðŸ˜š\n",
    "\n",
    "### 2-6-1. Normality test and equal-variance checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ced593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = [df_twt['rank'], df_twt_non['rank'], \n",
    "#        df_twt_mean['rank'], df_twt_non_mean['rank'], \n",
    "#        df_twt_med['rank'], df_twt_non_med['rank'],\n",
    "#        df_twt_min['rank'], df_twt_non_min['rank']]\n",
    "\n",
    "# x = ['Arithmetic mean - All Twitch_user', 'Arithmetic mean - All normal_user', \n",
    "#      'Mean of rank average - Twitch_user', 'Mean of rank average - normal_user', \n",
    "#      'Mean of rank median - Twitch_user', 'Mean of rank median - normal_user', \n",
    "#      'Mean of rank minimum - Twitch_user', 'Mean of rank minimum - normal_user']\n",
    "\n",
    "i1 = ['Arithmetic Mean', 'Arithmetic Mean', 'Mean of average','Mean of average', 'Mean of median','Mean of median', 'Mean of minimum', 'Mean of minimum']\n",
    "i2 = ['t', 'n']*4\n",
    "c1 = ['statistic', 'pval']\n",
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "tmp = pd.DataFrame(index = [i1, i2], columns = c1)\n",
    "\n",
    "\"\"\"=== Normal-test ===\"\"\"\n",
    "for i in range(len(dset)):\n",
    "    res1 = scipy.stats.normaltest(dset[i])\n",
    "    tmp.loc[(i1[i], i2[i]), 'statistic'] = res1[0]\n",
    "    tmp.loc[(i1[i], i2[i]), 'pval'] = res1[1]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d080c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = ['Arithmetic Mean', 'Mean of average', 'Mean of median', 'Mean of minimum']\n",
    "c1 = ['statistic', 'pval']\n",
    "tmp = pd.DataFrame(index = [i1], columns = c1)\n",
    "\n",
    "\"\"\"=== Equal-variance test ===\"\"\"\n",
    "for j in range(0, len(dset), 2):\n",
    "    res2 = scipy.stats.levene(dset[j], dset[j+1])\n",
    "    tmp.loc[i1[j//2], 'statistic'] = res2[0]\n",
    "    tmp.loc[i1[j//2], 'pval'] = res2[1]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4eed32",
   "metadata": {},
   "source": [
    "### 2-6-2. Mann-Whitney U Test, T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707eedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just all data divided twitch column\n",
    "scipy.stats.mannwhitneyu(x = dset[0], y = dset[1], alternative = 'two-sided', method = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6788bb0",
   "metadata": {},
   "source": [
    "And I addedd the T-test with mean dataset and median dataset, because they are composed by represetative values.  \n",
    "Letâ€™s put in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916dd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = ['Arithmetic Mean', 'Mean of average', 'Mean of median', 'Mean of minimum']\n",
    "c1 = ['statistic', 'pval']*2\n",
    "c2 = ['Mann_Whitney_U', 'Mann_Whitney_U', 'T_Test', 'T_Test']\n",
    "tmp = pd.DataFrame(index = [i1], columns = [c2, c1])\n",
    "\n",
    "\"\"\"=== Mann-Whitney-U Test, T-Test ===\"\"\"\n",
    "for i in range(0, len(dset), 2):\n",
    "    j = i//2\n",
    "    res3 = scipy.stats.mannwhitneyu(x = dset[i], y = dset[i+1], alternative = 'two-sided', method = 'auto')\n",
    "    res4 = scipy.stats.ttest_ind(a = dset[i], b = dset[i+1], equal_var = False, permutations = 0)\n",
    "    \n",
    "    tmp.loc[i1[j], (c2[0], c1[0])] = res3[0]\n",
    "    tmp.loc[i1[j], (c2[0], c1[1])] = res3[1]\n",
    "    tmp.loc[i1[j], (c2[2], c1[0])] = res4[0]\n",
    "    tmp.loc[i1[j], (c2[2], c1[1])] = res4[1]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68846f1e",
   "metadata": {},
   "source": [
    "All p-values are smaller than 0.05, so we can say that 'there's no basis to consider that there are no differences between Twitch streamers and normal players.'.  \n",
    "\n",
    "Interestingly, there is little difference in statistics in each t-test, whether using means or media. I think it is reasonable to say that whatever we use as a representative value is not very effective in this question.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388bcd8",
   "metadata": {},
   "source": [
    "### 2-6-3. Confidence interval \n",
    "I attach the confidence interval together. We can imagine from this, \"What numbers(rank) are mainly distributed in each group\".\n",
    "\n",
    "_code reference: https://jae-eun-ai.tistory.com/48_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, mean\n",
    "from scipy.stats import sem, t\n",
    "def mean_confidence_interval(data, confidence=.95):\n",
    "    a = 1.0 * array(data)\n",
    "    n = len(a)\n",
    "    m,se = mean(a),sem(a)\n",
    "    h = se*t._ppf((1 + confidence) / 2, n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "# dset = [df_twt['rank'], df_twt_non['rank'], \n",
    "#        df_twt_mean['rank'], df_twt_non_mean['rank'], \n",
    "#        df_twt_med['rank'], df_twt_non_med['rank']]\n",
    "\n",
    "llist = []\n",
    "for i in dset:\n",
    "    j = mean_confidence_interval(i)\n",
    "    llist.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ci = pd.DataFrame(data = llist)\n",
    "df_ci = df_ci.T\n",
    "df_ci.columns = ['twi', 'nor', 'twi_mean', 'nor_mean', 'twi_median', 'nor_median', 'twi_min', 'nor_min']\n",
    "df_ci.index = ['m', 'm-h', 'm+h']\n",
    "df_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331dc4e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize = (6,6))\n",
    "sns.scatterplot(data = df_ci.T, palette = 'rocket')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.gca().invert_yaxis()  # reverse the y axis!\n",
    "\n",
    "# text\n",
    "colors = ['#6441a5', 'black']\n",
    "for i in range(0, 8):\n",
    "    if i%2 ==0:\n",
    "        plt.text(i+0.1, df_ci.iloc[0, i]+15, s = round(df_ci.iloc[0, i], 2), size = 12, weight = 'bold', color = colors[0])\n",
    "    else:\n",
    "        plt.text(i+0.1, df_ci.iloc[0, i]+15, s = round(df_ci.iloc[0, i], 2), size = 12, color = colors[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdefddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize = (6,6))\n",
    "sns.scatterplot(data = df_ci.T, palette = 'rocket')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.gca().invert_yaxis()  # reverse the y axis!\n",
    "\n",
    "# text\n",
    "colors = ['#6441a5', 'black']\n",
    "for i in range(0, 8):\n",
    "    if i%2 ==0:\n",
    "        plt.text(i+0.1, df_ci.iloc[0, i]+15, s = round(df_ci.iloc[0, i], 2), size = 12, weight = 'bold', color = colors[0])\n",
    "    else:\n",
    "        plt.text(i+0.1, df_ci.iloc[0, i]+15, s = round(df_ci.iloc[0, i], 2), size = 12, color = colors[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f5bfb",
   "metadata": {},
   "source": [
    "### 2-6-4. [Answer] : \n",
    "I attach the confidence interval together. We can imagine from this, \"What numbers(rank) are mainly distributed in each group\".\n",
    "\n",
    "_code reference: https://jae-eun-ai.tistory.com/48_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049eced1",
   "metadata": {},
   "source": [
    "## 2-7. \"Who does not?\"\n",
    "\n",
    "I set the Twitch users' data frame and I add whether they are better or not in each case.   \n",
    "\n",
    "If there's not any worse rank in each case, they were dropped in the data frame.  \n",
    "If not, they remain in the data frame, and the number of cases when they were worse than normal users would be counted.\n",
    "\n",
    "\n",
    "```python\n",
    "# Let's divide the dataset as whether 'twitch' column is null or not\n",
    "\n",
    "# each id's rank\n",
    "df_twt = df[df['twitch'].isna() == False]\n",
    "df_twt_non = df[df['twitch'].isna() == True]\n",
    "\n",
    "# each user's mean rank\n",
    "# grouping by player and get the 'average' rank of each player streaming on twitch or not\n",
    "df_twt_mean = df_twt.pivot_table(index = 'twitch', values = 'rank', aggfunc = 'mean')\n",
    "df_twt_non_mean = df_twt_non.pivot_table(index = 'account', values = 'rank', aggfunc = 'mean')\n",
    "\n",
    "# each user's median rank\n",
    "# grouping by player and get the 'median' rank of each player streaming on twitch or not\n",
    "df_twt_med = df_twt.pivot_table(index = 'twitch', values = 'rank', aggfunc = 'median')\n",
    "df_twt_non_med = df_twt_non.pivot_table(index = 'account', values = 'rank', aggfunc = 'median')\n",
    "\n",
    "# each user's min(highest) rank\n",
    "# grouping by player and get the 'median' rank of each player streaming on twitch or not\n",
    "df_twt_min = df_twt.pivot_table(index = 'twitch', values = 'rank', aggfunc = 'min')\n",
    "df_twt_non_min = df_twt_non.pivot_table(index = 'account', values = 'rank', aggfunc = 'min')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0d741",
   "metadata": {},
   "source": [
    "sequences: \n",
    "1. Make all Twitch users list.\n",
    "2. Get Twitch users who are under-ranked than normal users' mean, in the case of `mean` is the user's representative.  \n",
    "    And make a column `case_mean`  with value `1`. (we'll use it as a value presenting how much we can say 'the Twitch user is not better than the normal users.')\n",
    "3. Get Twitch users who are under-ranked than normal users' mean, in the case of `median` is the user's representative.  \n",
    "    And make a column `case_med`, with the same methods as the previous one.\n",
    "4. Get Twitch users who are under-ranked than normal users' mean, in the case of `minimum` is the user's representative.  \n",
    "    And make a column `case_min`, just like the previous one.\n",
    "5. Delete the Twitch user's twitch id who doesn't have any `1` in new columns. And count the `1` for sort.  \n",
    "6. See \"who does not\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25da96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. All twitch users - the size is the number of all twitch users.\n",
    "df_q2 = pd.DataFrame(df_twt['twitch'].drop_duplicates())\n",
    "df_q2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fae56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use this value for comparing.\n",
    "df_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb69f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. In case of the mean is user's representative rank\n",
    "df_twt_mean.reset_index(inplace = True)\n",
    "tmp = df_twt_mean[df_twt_mean['rank'] > df_ci.loc['m', 'nor_mean']][['twitch']]\n",
    "tmp['case_mean'] = 1\n",
    "\n",
    "# merging \n",
    "df_q2 = pd.merge(left = df_q2, right = tmp[['twitch','case_mean']], how = 'left', on = 'twitch')\n",
    "\n",
    "# 3. In case of the median is user's representative rank\n",
    "df_twt_med.reset_index(inplace = True)\n",
    "tmp = df_twt_med[df_twt_med['rank'] > df_ci.loc['m', 'nor_median']][['twitch']]\n",
    "tmp['case_med'] = 1\n",
    "\n",
    "# merging \n",
    "df_q2 = pd.merge(left = df_q2, right = tmp[['twitch','case_med']], how = 'left', on = 'twitch')\n",
    "\n",
    "# 4. In case of the median is user's representative rank\n",
    "df_twt_min.reset_index(inplace = True)\n",
    "tmp = df_twt_min[df_twt_min['rank'] > df_ci.loc['m', 'nor_min']][['twitch']]\n",
    "tmp['case_min'] = 1\n",
    "\n",
    "# merging \n",
    "df_q2 = pd.merge(left = df_q2, right = tmp[['twitch','case_min']], how = 'left', on = 'twitch')\n",
    "df_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-1. deleting\n",
    "df_q2.dropna(axis = 0, how = 'all', subset = ['case_mean', 'case_med', 'case_min'], inplace = True)\n",
    "\n",
    "# 5-2. N/A processing\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "df_q2.fillna(0, inplace = True)\n",
    "\n",
    "# 5-3. counting\n",
    "df_q2['cnt'] = df_q2['case_mean'] + df_q2['case_med'] + df_q2['case_min']\n",
    "\n",
    "# 5-4. you can see 'the' Twitch users! (little ambiguous)\n",
    "df_q2[df_q2['cnt']!= 0].sort_values(by = 'cnt', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of 'the' Twitch users!\n",
    "\n",
    "# (1) these Twitch users are little ambiguous to be said 'not better than Normal users'!\n",
    "twt_list1 = list(df_q2[df_q2['cnt']!= 0]['twitch'])\n",
    "\n",
    "# (2) more robust methods to judging not good : these Twitch users are certain to be said 'not better than Normal users'!\n",
    "twt_list2 = list(df_q2[df_q2['cnt']== 3]['twitch'])\n",
    "\n",
    "# how much are they different?\n",
    "print(len(twt_list1), len(twt_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98b283",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### if you want to see the list of the twitch users, check this : \n",
    "# print(twt_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e54a22",
   "metadata": {},
   "source": [
    "## 2-8. Result and conclusion: Improvement Direction\n",
    "I wrote some ideas to improve in analyzing with this results.\n",
    "\n",
    "- (This is the same context we discussed before analyzing this question.) Existing data can define and analyze something new that can index 'ability(or skill)' based on whether `rank` is higher than `challenge` or experience.\n",
    "    \n",
    "    However, since this is â€˜characterâ€™-limited information, we can discuss at last whether there is a more accurate difference if we find a way to create an indicator with all accounts they have. (if we do this, we must have identified information with a person and his accounts)\n",
    "    \n",
    "- Since â€˜streamingâ€™ is not necessarily only for users who are good at playing, it would be better to analyze users first by selecting the streamers in the Path Of Exile category within Twitch, for getting insight. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "746.25px",
    "left": "22px",
    "top": "271.092px",
    "width": "360px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
