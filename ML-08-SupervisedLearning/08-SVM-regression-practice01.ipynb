{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# 서포트 벡터 머신 연습\n",
    "\n",
    "#####  \n",
    "\n",
    "서포트 벡터 머신을 공부하고 교재를 따라 와인을 분류하는 classifier 실습을 했었다.\n",
    "\n",
    "이번에는 서포트 벡터 회귀 모델을 이용하는 연습을 해보려고 한다.\n",
    "\n",
    "이전에 멜버른 집값을 예측해보는 것을 의사결정나무 regression 연습을 해보았으나 잘 안되긴 했었다.\n",
    "\n",
    "그것 말고 사이킷런에서 제공하는 보스턴 집값을 데리고 예측을 해보는 것으로 대신하기로 했다.\n",
    "\n",
    "그러나 버전에 따라 앞으로 없어질 데이터 셋이라고 하여, 안내에 따라 대신할 데이터를 직접 데려온다.\n",
    "\n",
    "이젠 혼자 부딪힐 때도 되었으니 검색을 최소최소 최~소 최소화하기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf1d3d",
   "metadata": {},
   "source": [
    "# Dataset import\n",
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393ce3e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Angela/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "raw_bostion = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7dfe47",
   "metadata": {},
   "source": [
    "이러한 데이터의 문제가 있다고 한다. 미래에는 없어진다고 하니 일단은 데려오되 나중에 다른 연습은  캘리포니아 집값 데이터를 데려와보도록 해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1e6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cddeea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3      4      5     6       7    8      9     10\n",
       "0    0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3\n",
       "1  396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "2    0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8\n",
       "3  396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "4    0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6878cb",
   "metadata": {},
   "source": [
    "알아볼 수 없게 생겨먹었다. target 데이터는 2번 열 즉 2라고 쓰여진 컬럼으로 보인다. 결측값이 있는지 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ffc49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3     506\n",
       "4     506\n",
       "5     506\n",
       "6     506\n",
       "7     506\n",
       "8     506\n",
       "9     506\n",
       "10    506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae3ad2",
   "metadata": {},
   "source": [
    "타깃 데이터는 1과 0으로 더미 변수 형태로 분류되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "# 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d631e3",
   "metadata": {},
   "source": [
    "## 트레이닝, 테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d674bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080bc7a",
   "metadata": {},
   "source": [
    "## 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9edad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X 트레이닝 데이터 기준으로 Xtn Xte 를 표준화한다.\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601f993",
   "metadata": {},
   "source": [
    "# 서포트 벡터 회귀 모델\n",
    "\n",
    "## 모델링\n",
    "### 데이터 학습 (kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "737a1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터를 보기 위해 일단 데려온다. kernel 은 이전에 실습했던대로 linear 부터 해본다.\n",
    "\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab13de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svr_lr = svm.SVR(kernel = 'linear')         # SVR 메소드를 이용해 분류 문제에 적용. 분류라면 SVC.\n",
    "clf_svr_lr.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da3921",
   "metadata": {},
   "source": [
    "kernel 종류는 SVC와 마찬가지로 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' 등이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219f45c",
   "metadata": {},
   "source": [
    "### 추정계수 및 상수항 확인\n",
    "\n",
    "결국 선형으로 된 수식을 이용하기 때문에 있을 것이라 생각하여 구해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e204c03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.15049832  0.85534947  0.02728933  0.38488671 -0.79987923  3.76542984\n",
      "  -0.77390534 -1.99956251  1.09154612 -1.53001125 -1.56212036  0.94397908\n",
      "  -2.26623114]]\n"
     ]
    }
   ],
   "source": [
    "# 추정계수 확인\n",
    "\n",
    "print(clf_svr_lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3771ed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.7753086]\n"
     ]
    }
   ],
   "source": [
    "# 상수항 확인\n",
    "\n",
    "print(clf_svr_lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05b96e",
   "metadata": {},
   "source": [
    "분류해야하는 각 클래스별로 존재하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedd1bd",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "077fc38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.52947544 20.35423732 26.47676448  9.74009208 21.0378301  18.85874\n",
      " 18.6263904  20.65306829 16.3571043  18.44120108  1.83859761 14.77921945\n",
      " 16.8165412   3.39294294 37.49176197 32.0579395  20.41257183 35.48866506\n",
      " 29.23822418 21.81376385 24.24218256 21.49031908 19.78380253 28.84780636\n",
      " 20.97310945  2.94925643 17.38496471 17.35019198 35.64837325 19.77476059\n",
      " 16.76254231 17.03973933 19.33992199 22.38892841 26.47086708 17.24991582\n",
      " 10.96895118 20.26465974 15.48478266 14.59886084 25.04138918 20.30869651\n",
      " 21.84126734 12.61710256 23.23369641 23.9581827  19.04474505 22.07247352\n",
      " 10.34109468 24.10934469 19.83491997 17.98123471 22.25735348 33.80415317\n",
      " 13.259881   21.24168918 20.21880666 16.07843483  7.97764789 20.30457994\n",
      " 18.49972329 21.32059799 31.99028068 29.44827917 15.72077258 30.38630497\n",
      " 18.92222309 20.03005074 17.82815151 22.29090848 21.61667513 23.091445\n",
      " 28.72776207 28.95497282 23.90385538  4.60649631 36.97482212 23.36941218\n",
      " 25.72850175 18.54598223 27.40793582 19.86014656 15.18471498 37.6128682\n",
      " 39.76343    23.74008339 23.16078472 12.95111752 25.36064317 16.27874763\n",
      " 16.72364287 13.76891972 23.85908861 29.89328886 21.14239531 20.35574411\n",
      " -1.09620565 25.12857353 15.20327905 17.17819096 24.99936221 21.7009279\n",
      " 30.05310794 21.46432155 27.3311633  22.13591371  4.65379212 11.45253977\n",
      " 21.57450236 28.05131797 30.4147949  11.51035866 19.71176369 19.19531367\n",
      " 13.02270872 22.13158152  6.2983039  19.94339887  7.88093486 43.10380765\n",
      " 29.54605184 11.50978723 16.92607965 20.75305189 21.80908183 19.37730243\n",
      " 33.73030213]\n"
     ]
    }
   ],
   "source": [
    "svr_lr_pred = clf_svr_lr.predict(X_te_std)\n",
    "print(svr_lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb179b",
   "metadata": {},
   "source": [
    "## 평가\n",
    "\n",
    "### R-square, MSE\n",
    "\n",
    "regression이기 때문에 r제곱값과 MSE로 모형 평가를 하도록 한다.\n",
    "\n",
    "r제곱값은 높은 값을 가질수록 좋은 성능을 의미하며, MSE는 작을수록 좋은 성능을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06b3222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5686388148506821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_te, svr_lr_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d2bbf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.24178412488141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_te, svr_lr_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcc2d5",
   "metadata": {},
   "source": [
    "좋은 성능은 아닌 것으로 확인되고 있다.\n",
    "\n",
    "이번에는 kernel = 'rbf' 로 하여 예측을 해보기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107d31c",
   "metadata": {},
   "source": [
    "# 실험: kernel = 'rbf' (default)\n",
    "\n",
    "전체 코드로 합한 셀로, 커널을 변경하여 진행해보기로 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "709a126b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [25.11552591 18.9218917  24.49975053 13.37293312 20.94372848 19.44272718\n",
      " 20.80813628 20.13594679 18.94818956 18.93638023 20.78396854 13.25219783\n",
      " 14.76024506 13.10287659 27.10999466 30.44442452 21.40174393 31.76106904\n",
      " 28.85926025 21.42968304 23.84957587 21.52043873 18.91123758 27.94572811\n",
      " 20.40071213 18.04642576 17.16332442 18.59776569 33.88304617 18.58811301\n",
      " 15.23207652 17.31310478 19.54779621 21.20809243 25.85119194 20.90186203\n",
      " 12.03908414 22.2813928  13.93809735 13.24894192 23.4775945  20.13773061\n",
      " 22.87694552 14.98038217 25.05705592 23.25137952 18.85683562 20.91449993\n",
      " 16.87507859 23.01042511 20.72783774 19.71440626 21.37960156 29.84633197\n",
      " 15.22269235 21.0068188  19.88423066 18.34631675 19.53985028 21.59504372\n",
      " 20.86863203 20.90511802 31.73719895 28.30955215 18.33960229 29.89367263\n",
      " 16.13817317 20.0411484  13.80402996 21.95356397 20.86701313 22.8551537\n",
      " 26.72354117 29.89005749 23.04121696 12.45945446 34.94386153 22.74739504\n",
      " 25.47262778 18.41839862 27.55888042 18.65121491 16.22203418 34.5694561\n",
      " 33.73659033 23.66321727 22.56789835 14.95904942 23.73265942 15.52807699\n",
      " 19.70334916 11.74587795 23.38195755 29.32363152 20.27770341 20.8659635\n",
      " 15.27262986 24.87425381 13.63088314 17.27473816 24.49798515 20.22563741\n",
      " 26.6939277  21.47307858 27.96316359 21.60254211 12.53660874 16.73822356\n",
      " 20.55682698 27.38687074 28.32125465 12.17700555 19.50838358 18.83034766\n",
      " 16.69705952 23.11090927 12.37256767 19.49169614 12.33267364 27.14278433\n",
      " 29.86300129 12.4224828  17.16278577 20.29266786 20.85293078 18.97813836\n",
      " 32.62448775]\n",
      "r2 score: 0.5084292459321271\n",
      "MSE:  40.16084662547563\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# raw_df\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "# feature, target data select\n",
    "X = data\n",
    "y = target\n",
    "\n",
    "# training data, test data division\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Data standardization for X\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# SVM Regressor Analyzing\n",
    "clf_svr_rbf = svm.SVR(kernel = 'rbf')\n",
    "clf_svr_rbf.fit(X_tn_std, y_tn)\n",
    "\n",
    "# # w, b(추정계수, 상수항) 출력 : only 'linear'에서만\n",
    "# print('coef: ', clf_svr_rbf.coef_)\n",
    "# print('intercept: ', clf_svr_rbf.intercept_)\n",
    "\n",
    "# predict y\n",
    "svr_rbf_pred = clf_svr_rbf.predict(X_te_std)\n",
    "print('pred: ',svr_rbf_pred)\n",
    "\n",
    "# r-square score\n",
    "r2 = r2_score(y_te, svr_rbf_pred)\n",
    "print('r2 score:', r2)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_te, svr_rbf_pred)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7e59f",
   "metadata": {},
   "source": [
    "r2 스코어는 거의 그대로이나 MSE는 더욱 증가하면서 나쁜(?) 모델이 되어버렸다. \n",
    "\n",
    "다량의 피처를 사용하는 경우 SVM이 오히려 좋지 않은걸까? 어떻게 하면 이들을 더 좋게 만들 수 있을까? \n",
    "\n",
    "고민의 답은 우선 다른 옵션들을 사용해보는 것이었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06408f73",
   "metadata": {},
   "source": [
    "# 실험2: kernel = 'poly' \n",
    "\n",
    "poly는 여럿을 보통 의미하는데 여기에 어울릴지도 모른다는 생각에 먼저 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1c42f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [23.69047173 19.97367218 25.52537979 11.88072596 21.75302115 21.51570662\n",
      " 20.84414913 21.97987054 21.5693947  21.47390908 10.82397144 12.21863918\n",
      " 15.75917658  5.058035   40.98348413 33.23280535 21.11964747 38.87343076\n",
      " 24.03474185 22.26234595 22.18887162 21.78393962 21.29762695 24.25537047\n",
      " 22.97257606 13.0258793  21.00847666 17.88624659 26.94162813 21.48271581\n",
      " 16.9848521  18.17960244 21.68205683 21.74022597 22.84500341 19.08113729\n",
      "  9.35097918 24.98616185 15.82260453 15.47205665 23.07804797 22.39164351\n",
      " 22.73216879 16.42894079 22.91501643 22.43382323 21.61678073 20.86496826\n",
      " 14.3386672  21.76493488 15.82004626 21.52498482 21.8934869  30.33650979\n",
      " 17.58387863 21.65094193 21.66339236 21.45653912 15.0710964  22.54031998\n",
      " 20.67767889 21.78720499 27.04631862 23.56191595 19.16509837 26.27389275\n",
      " 16.78071622 20.98031758 14.51209201 22.36211179 21.70010812 21.90883439\n",
      " 26.99520058 25.80289502 21.73447238  6.09855322 26.31793339 21.98687693\n",
      " 22.8654162  21.5195873  24.04892236 20.18960985 17.70112367 26.99103339\n",
      " 29.43194091 22.74182174 22.56457801 16.00202524 24.70448201 16.87851887\n",
      " 18.53913072 10.26685641 22.90446691 27.26507698 21.47670853 22.33483347\n",
      " -1.16989761 25.43422845 13.58816278 20.98523839 22.33238982 21.51392928\n",
      " 27.8435929  22.53673043 23.21328812 21.93403725 10.0003609  15.91907483\n",
      " 21.50586695 24.33467018 25.45857926 13.4412157  21.21100415 21.5835996\n",
      " 19.84517269 23.55050239  5.29784812 20.67908091  9.4028737  70.05977001\n",
      " 26.45397963 11.60157582 21.53301609 21.62979241 21.79283662 19.5822748\n",
      " 25.25596514]\n",
      "r2 score: 0.4660419539843009\n",
      "MSE:  43.623846644697394\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# raw_df\n",
    "# data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "# raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "# data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "# target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "# feature, target data select\n",
    "# X = data\n",
    "# y = target\n",
    "\n",
    "# training data, test data division\n",
    "# X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Data standardization for X\n",
    "# std_scale = StandardScaler()\n",
    "# std_scale.fit(X_tn)\n",
    "# X_tn_std = std_scale.transform(X_tn)\n",
    "# X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# SVM Regressor Analyzing\n",
    "clf_svr_poly = svm.SVR(kernel = 'poly')\n",
    "clf_svr_poly.fit(X_tn_std, y_tn)\n",
    "\n",
    "# # w, b(추정계수, 상수항) 출력 : only 'linear'에서만\n",
    "# print('coef: ', clf_svr_rbf.coef_)\n",
    "# print('intercept: ', clf_svr_rbf.intercept_)\n",
    "\n",
    "# predict y\n",
    "svr_poly_pred = clf_svr_poly.predict(X_te_std)\n",
    "print('pred: ',svr_poly_pred)\n",
    "\n",
    "# r-square score\n",
    "r2 = r2_score(y_te, svr_poly_pred)\n",
    "print('r2 score:', r2)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_te, svr_poly_pred)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc12ed",
   "metadata": {},
   "source": [
    "실제로 r2스코어는 감소하고 MSE는 오히려 증가하면서 더 나쁜(?) 모델이 되어버렸다. 하... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.975px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
