{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee0e18b",
   "metadata": {},
   "source": [
    "# 서포트 벡터 머신 연습\n",
    "\n",
    "#####  \n",
    "\n",
    "서포트 벡터 머신을 공부하고 교재를 따라 와인을 분류하는 classifier 실습을 했었다.\n",
    "\n",
    "이번에는 서포트 벡터 회귀 모델을 이용하는 연습을 해보려고 한다.\n",
    "\n",
    "이전에 멜버른 집값을 예측해보는 것을 의사결정나무 regression 연습을 해보았으나 잘 안되긴 했었다.\n",
    "\n",
    "그것 말고 사이킷런에서 제공하는 보스턴 집값을 데리고 예측을 해보는 것으로 대신하기로 했다.\n",
    "\n",
    "그러나 버전에 따라 앞으로 없어질 데이터 셋이라고 하여, 안내에 따라 대신할 데이터를 직접 데려온다.\n",
    "\n",
    "이젠 혼자 부딪힐 때도 되었으니 검색을 최소최소 최~소 최소화하기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf1d3d",
   "metadata": {},
   "source": [
    "# Dataset import\n",
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393ce3e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Angela/opt/anaconda3/envs/py3_8_5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "raw_bostion = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f50753",
   "metadata": {},
   "source": [
    "이러한 데이터의 문제가 있다고 한다. 미래에는 없어진다고 하니 일단은 데려오되 나중에 다른 연습은  캘리포니아 집값 데이터를 데려와보도록 해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fe2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b4e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "803ecbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3      4      5     6       7    8      9     10\n",
       "0    0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3\n",
       "1  396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "2    0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8\n",
       "3  396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "4    0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65d79d",
   "metadata": {},
   "source": [
    "알아볼 수 없게 생겨먹었다. target 데이터는 2번 열 즉 2라고 쓰여진 컬럼으로 보인다. 결측값이 있는지 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34c5c104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3     506\n",
       "4     506\n",
       "5     506\n",
       "6     506\n",
       "7     506\n",
       "8     506\n",
       "9     506\n",
       "10    506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae3ad2",
   "metadata": {},
   "source": [
    "타깃 데이터는 1과 0으로 더미 변수 형태로 분류되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0dae9",
   "metadata": {},
   "source": [
    "# 피처, 타깃 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d631e3",
   "metadata": {},
   "source": [
    "## 트레이닝, 테스트 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d674bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080bc7a",
   "metadata": {},
   "source": [
    "## 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9edad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X 트레이닝 데이터 기준으로 Xtn Xte 를 표준화한다.\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601f993",
   "metadata": {},
   "source": [
    "# 서포트 벡터 회귀 모델\n",
    "\n",
    "## 모델링\n",
    "### 데이터 학습 (kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42a83858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터를 보기 위해 일단 데려온다. kernel 은 이전에 실습했던대로 linear 부터 해본다.\n",
    "\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab13de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svr_lr = svm.SVR(kernel = 'linear')         # SVR 메소드를 이용해 분류 문제에 적용. 분류라면 SVC.\n",
    "clf_svr_lr.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da3921",
   "metadata": {},
   "source": [
    "kernel 종류는 SVC와 마찬가지로 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' 등이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219f45c",
   "metadata": {},
   "source": [
    "### 추정계수 및 상수항 확인\n",
    "\n",
    "결국 선형으로 된 수식을 이용하기 때문에 있을 것이라 생각하여 구해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e204c03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.15049832  0.85534947  0.02728933  0.38488671 -0.79987923  3.76542984\n",
      "  -0.77390534 -1.99956251  1.09154612 -1.53001125 -1.56212036  0.94397908\n",
      "  -2.26623114]]\n"
     ]
    }
   ],
   "source": [
    "# 추정계수 확인\n",
    "\n",
    "print(clf_svr_lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3771ed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.7753086]\n"
     ]
    }
   ],
   "source": [
    "# 상수항 확인\n",
    "\n",
    "print(clf_svr_lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05b96e",
   "metadata": {},
   "source": [
    "분류해야하는 각 클래스별로 존재하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedd1bd",
   "metadata": {},
   "source": [
    "### 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "077fc38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.52947544 20.35423732 26.47676448  9.74009208 21.0378301  18.85874\n",
      " 18.6263904  20.65306829 16.3571043  18.44120108  1.83859761 14.77921945\n",
      " 16.8165412   3.39294294 37.49176197 32.0579395  20.41257183 35.48866506\n",
      " 29.23822418 21.81376385 24.24218256 21.49031908 19.78380253 28.84780636\n",
      " 20.97310945  2.94925643 17.38496471 17.35019198 35.64837325 19.77476059\n",
      " 16.76254231 17.03973933 19.33992199 22.38892841 26.47086708 17.24991582\n",
      " 10.96895118 20.26465974 15.48478266 14.59886084 25.04138918 20.30869651\n",
      " 21.84126734 12.61710256 23.23369641 23.9581827  19.04474505 22.07247352\n",
      " 10.34109468 24.10934469 19.83491997 17.98123471 22.25735348 33.80415317\n",
      " 13.259881   21.24168918 20.21880666 16.07843483  7.97764789 20.30457994\n",
      " 18.49972329 21.32059799 31.99028068 29.44827917 15.72077258 30.38630497\n",
      " 18.92222309 20.03005074 17.82815151 22.29090848 21.61667513 23.091445\n",
      " 28.72776207 28.95497282 23.90385538  4.60649631 36.97482212 23.36941218\n",
      " 25.72850175 18.54598223 27.40793582 19.86014656 15.18471498 37.6128682\n",
      " 39.76343    23.74008339 23.16078472 12.95111752 25.36064317 16.27874763\n",
      " 16.72364287 13.76891972 23.85908861 29.89328886 21.14239531 20.35574411\n",
      " -1.09620565 25.12857353 15.20327905 17.17819096 24.99936221 21.7009279\n",
      " 30.05310794 21.46432155 27.3311633  22.13591371  4.65379212 11.45253977\n",
      " 21.57450236 28.05131797 30.4147949  11.51035866 19.71176369 19.19531367\n",
      " 13.02270872 22.13158152  6.2983039  19.94339887  7.88093486 43.10380765\n",
      " 29.54605184 11.50978723 16.92607965 20.75305189 21.80908183 19.37730243\n",
      " 33.73030213]\n"
     ]
    }
   ],
   "source": [
    "svr_lr_pred = clf_svr_lr.predict(X_te_std)\n",
    "print(svr_lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb179b",
   "metadata": {},
   "source": [
    "## 평가\n",
    "\n",
    "### R-square, MSE\n",
    "\n",
    "regression이기 때문에 r제곱값과 MSE로 모형 평가를 하도록 한다.\n",
    "\n",
    "r제곱값은 높은 값을 가질수록 좋은 성능을 의미하며, MSE는 작을수록 좋은 성능을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b3222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5686388148506821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_te, svr_lr_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d2bbf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.24178412488141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_te, svr_lr_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcc2d5",
   "metadata": {},
   "source": [
    "좋은 성능은 아닌 것으로 확인되고 있다.\n",
    "\n",
    "이번에는 kernel = 'rbf' 로 하여 예측을 해보기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107d31c",
   "metadata": {},
   "source": [
    "# 실험: kernel = 'rbf' (default)\n",
    "\n",
    "전체 코드로 합한 셀로, 커널을 변경하여 진행해보기로 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709a126b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [25.11552591 18.9218917  24.49975053 13.37293312 20.94372848 19.44272718\n",
      " 20.80813628 20.13594679 18.94818956 18.93638023 20.78396854 13.25219783\n",
      " 14.76024506 13.10287659 27.10999466 30.44442452 21.40174393 31.76106904\n",
      " 28.85926025 21.42968304 23.84957587 21.52043873 18.91123758 27.94572811\n",
      " 20.40071213 18.04642576 17.16332442 18.59776569 33.88304617 18.58811301\n",
      " 15.23207652 17.31310478 19.54779621 21.20809243 25.85119194 20.90186203\n",
      " 12.03908414 22.2813928  13.93809735 13.24894192 23.4775945  20.13773061\n",
      " 22.87694552 14.98038217 25.05705592 23.25137952 18.85683562 20.91449993\n",
      " 16.87507859 23.01042511 20.72783774 19.71440626 21.37960156 29.84633197\n",
      " 15.22269235 21.0068188  19.88423066 18.34631675 19.53985028 21.59504372\n",
      " 20.86863203 20.90511802 31.73719895 28.30955215 18.33960229 29.89367263\n",
      " 16.13817317 20.0411484  13.80402996 21.95356397 20.86701313 22.8551537\n",
      " 26.72354117 29.89005749 23.04121696 12.45945446 34.94386153 22.74739504\n",
      " 25.47262778 18.41839862 27.55888042 18.65121491 16.22203418 34.5694561\n",
      " 33.73659033 23.66321727 22.56789835 14.95904942 23.73265942 15.52807699\n",
      " 19.70334916 11.74587795 23.38195755 29.32363152 20.27770341 20.8659635\n",
      " 15.27262986 24.87425381 13.63088314 17.27473816 24.49798515 20.22563741\n",
      " 26.6939277  21.47307858 27.96316359 21.60254211 12.53660874 16.73822356\n",
      " 20.55682698 27.38687074 28.32125465 12.17700555 19.50838358 18.83034766\n",
      " 16.69705952 23.11090927 12.37256767 19.49169614 12.33267364 27.14278433\n",
      " 29.86300129 12.4224828  17.16278577 20.29266786 20.85293078 18.97813836\n",
      " 32.62448775]\n",
      "r2 score: 0.5084292459321271\n",
      "MSE:  40.16084662547563\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# raw_df\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "# feature, target data select\n",
    "X = data\n",
    "y = target\n",
    "\n",
    "# training data, test data division\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Data standardization for X\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# SVM Regressor Analyzing\n",
    "clf_svr_rbf = svm.SVR(kernel = 'rbf')\n",
    "clf_svr_rbf.fit(X_tn_std, y_tn)\n",
    "\n",
    "# # w, b(추정계수, 상수항) 출력 : only 'linear'에서만\n",
    "# print('coef: ', clf_svr_rbf.coef_)\n",
    "# print('intercept: ', clf_svr_rbf.intercept_)\n",
    "\n",
    "# predict y\n",
    "svr_rbf_pred = clf_svr_rbf.predict(X_te_std)\n",
    "print('pred: ',svr_rbf_pred)\n",
    "\n",
    "# r-square score\n",
    "r2 = r2_score(y_te, svr_rbf_pred)\n",
    "print('r2 score:', r2)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_te, svr_rbf_pred)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7e59f",
   "metadata": {},
   "source": [
    "r2 스코어는 거의 그대로이나 MSE는 더욱 증가하면서 나쁜(?) 모델이 되어버렸다. \n",
    "\n",
    "다량의 피처를 사용하는 경우 SVM이 오히려 좋지 않은걸까? 어떻게 하면 이들을 더 좋게 만들 수 있을까? \n",
    "\n",
    "고민의 답은 우선 다른 옵션들을 사용해보는 것이었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733d4c2",
   "metadata": {},
   "source": [
    "# 실험2: kernel = 'poly' \n",
    "\n",
    "poly는 여럿을 보통 의미하는데 여기에 어울릴지도 모른다는 생각에 먼저 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e2c2581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [23.69047173 19.97367218 25.52537979 11.88072596 21.75302115 21.51570662\n",
      " 20.84414913 21.97987054 21.5693947  21.47390908 10.82397144 12.21863918\n",
      " 15.75917658  5.058035   40.98348413 33.23280535 21.11964747 38.87343076\n",
      " 24.03474185 22.26234595 22.18887162 21.78393962 21.29762695 24.25537047\n",
      " 22.97257606 13.0258793  21.00847666 17.88624659 26.94162813 21.48271581\n",
      " 16.9848521  18.17960244 21.68205683 21.74022597 22.84500341 19.08113729\n",
      "  9.35097918 24.98616185 15.82260453 15.47205665 23.07804797 22.39164351\n",
      " 22.73216879 16.42894079 22.91501643 22.43382323 21.61678073 20.86496826\n",
      " 14.3386672  21.76493488 15.82004626 21.52498482 21.8934869  30.33650979\n",
      " 17.58387863 21.65094193 21.66339236 21.45653912 15.0710964  22.54031998\n",
      " 20.67767889 21.78720499 27.04631862 23.56191595 19.16509837 26.27389275\n",
      " 16.78071622 20.98031758 14.51209201 22.36211179 21.70010812 21.90883439\n",
      " 26.99520058 25.80289502 21.73447238  6.09855322 26.31793339 21.98687693\n",
      " 22.8654162  21.5195873  24.04892236 20.18960985 17.70112367 26.99103339\n",
      " 29.43194091 22.74182174 22.56457801 16.00202524 24.70448201 16.87851887\n",
      " 18.53913072 10.26685641 22.90446691 27.26507698 21.47670853 22.33483347\n",
      " -1.16989761 25.43422845 13.58816278 20.98523839 22.33238982 21.51392928\n",
      " 27.8435929  22.53673043 23.21328812 21.93403725 10.0003609  15.91907483\n",
      " 21.50586695 24.33467018 25.45857926 13.4412157  21.21100415 21.5835996\n",
      " 19.84517269 23.55050239  5.29784812 20.67908091  9.4028737  70.05977001\n",
      " 26.45397963 11.60157582 21.53301609 21.62979241 21.79283662 19.5822748\n",
      " 25.25596514]\n",
      "r2 score: 0.4660419539843009\n",
      "MSE:  43.623846644697394\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# raw_df\n",
    "# data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "# raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "# data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "# target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "# feature, target data select\n",
    "# X = data\n",
    "# y = target\n",
    "\n",
    "# training data, test data division\n",
    "# X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Data standardization for X\n",
    "# std_scale = StandardScaler()\n",
    "# std_scale.fit(X_tn)\n",
    "# X_tn_std = std_scale.transform(X_tn)\n",
    "# X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# SVM Regressor Analyzing\n",
    "clf_svr_poly = svm.SVR(kernel = 'poly')\n",
    "clf_svr_poly.fit(X_tn_std, y_tn)\n",
    "\n",
    "# # w, b(추정계수, 상수항) 출력 : only 'linear'에서만\n",
    "# print('coef: ', clf_svr_rbf.coef_)\n",
    "# print('intercept: ', clf_svr_rbf.intercept_)\n",
    "\n",
    "# predict y\n",
    "svr_poly_pred = clf_svr_poly.predict(X_te_std)\n",
    "print('pred: ',svr_poly_pred)\n",
    "\n",
    "# r-square score\n",
    "r2 = r2_score(y_te, svr_poly_pred)\n",
    "print('r2 score:', r2)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_te, svr_poly_pred)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23245e6",
   "metadata": {},
   "source": [
    "실제로 r2스코어는 감소하고 MSE는 오히려 증가하면서 더 나쁜(?) 모델이 되어버렸다. 하... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e671434",
   "metadata": {},
   "source": [
    "# 실험3: kernel = 'sigmoid' \n",
    "\n",
    "poly는 여럿을 보통 의미하는데 여기에 어울릴지도 모른다는 생각에 먼저 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b0ce36f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [25.21426612 15.57303569 29.47095609 11.29039627 21.67714617 19.86755338\n",
      " 13.08579288 21.49804511 14.49892597 15.06991619 14.14402877 15.31976434\n",
      " 15.48698077 11.76152265 38.88022077 25.92490403 14.46627208 27.09060709\n",
      " 28.91124326 22.17358147 25.03532378 20.78297199 18.88754861 28.6930696\n",
      " 21.55035338  8.6660176  17.66492054 16.0816438  33.98427561 19.53700589\n",
      " 13.36482407 14.20235312 22.31863392 24.62111758 27.3434229  15.90789513\n",
      " 13.3207633  15.53984519 13.50337243 12.75394443 25.49989137 20.75615249\n",
      " 23.31956207 10.56642216 26.30333379 25.75246665 20.5186916  23.53029465\n",
      " 11.87506157 24.30182495 20.06470653 16.74279198 22.05851222 29.4764891\n",
      " 12.85741089 23.13983997 22.68757753 18.61075909 11.29201684 22.19028719\n",
      " 20.55024852 22.06837617 29.59145205 28.49379537  9.79464672 29.34628814\n",
      " 16.53220642 22.93579817 15.38799635 22.32247477 21.80068128 23.64704159\n",
      " 25.42281146 28.51771805 18.11030988 11.93026063 35.00082723 24.01155579\n",
      " 26.60004287 18.41844581 27.44006058 19.58991604 12.63882528 35.56811626\n",
      " 36.74451459 24.48127865 23.91101985 10.55850092 25.2255664  14.08434934\n",
      " 21.41997981 16.20219307 22.6168934  27.08117083 22.28880973 22.33119728\n",
      " 12.58087444 23.17573685 16.11675401 19.71640391 25.11662719 21.49037376\n",
      " 31.09191128 21.63615957 27.93668747 24.86412542 12.40243362 11.94986582\n",
      " 22.37476805 27.3720578  30.65533758 12.10897384 22.62491945 17.99002289\n",
      " 13.99340742 23.43377034 15.43601563 20.02684808 11.79470415 28.25826399\n",
      " 28.2808807  13.33353732 18.2105296  20.45495575 22.6746618  18.13635767\n",
      " 33.02584705]\n",
      "r2 score: 0.42798469573438114\n",
      "MSE:  46.73308717398672\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# raw_df\n",
    "# data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "# raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "# data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "# target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "# feature, target data select\n",
    "# X = data\n",
    "# y = target\n",
    "\n",
    "# training data, test data division\n",
    "# X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Data standardization for X\n",
    "# std_scale = StandardScaler()\n",
    "# std_scale.fit(X_tn)\n",
    "# X_tn_std = std_scale.transform(X_tn)\n",
    "# X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# SVM Regressor Analyzing\n",
    "clf_svr_sig = svm.SVR(kernel = 'sigmoid')\n",
    "clf_svr_sig.fit(X_tn_std, y_tn)\n",
    "\n",
    "# # w, b(추정계수, 상수항) 출력 : only 'linear'에서만\n",
    "# print('coef: ', clf_svr_rbf.coef_)\n",
    "# print('intercept: ', clf_svr_rbf.intercept_)\n",
    "\n",
    "# predict y\n",
    "svr_sig_pred = clf_svr_sig.predict(X_te_std)\n",
    "print('pred: ',svr_sig_pred)\n",
    "\n",
    "# r-square score\n",
    "r2 = r2_score(y_te, svr_sig_pred)\n",
    "print('r2 score:', r2)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_te, svr_sig_pred)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db43911",
   "metadata": {},
   "source": [
    "점점 심각해지는 것을 보면서 kernel(추정방식?)의 문제가 아님을 꺠달았음\n",
    "\n",
    "혼나봐라 데이터야"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498fc2ee",
   "metadata": {},
   "source": [
    "# 실험4: epsilon = 0.1 -> 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426420cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [24.65577318 20.3861132  26.35074374  9.75495446 21.0473144  18.88964356\n",
      " 18.79780852 20.67343931 16.46096821 18.38568461  1.5330592  14.76812066\n",
      " 16.92083893  3.43396592 37.32284328 32.1136178  20.51930348 35.45369243\n",
      " 29.32908472 21.88691089 24.26241396 21.42802001 19.76281105 28.88287388\n",
      " 21.03127078  2.9954527  17.33415004 17.3895905  35.54641547 19.74763985\n",
      " 16.80599321 17.16467534 19.26072505 22.35588413 26.43173196 17.35089073\n",
      " 10.97439149 20.29578788 15.53742384 14.66010234 25.12153868 20.3744972\n",
      " 21.92900245 12.6777096  23.2415272  23.87763487 19.03087105 22.06340817\n",
      " 10.43190977 24.07858647 19.83802481 18.15782216 22.27823746 33.86616832\n",
      " 13.20988642 21.32964695 20.26677346 16.08633065  7.751596   20.17892143\n",
      " 18.55618167 21.35047424 32.06755549 29.57478211 15.84813976 30.4429359\n",
      " 19.01109813 19.95806287 17.81643259 22.401612   21.57036717 23.11948632\n",
      " 28.76742262 29.00585849 23.96681891  4.68791686 36.93183566 23.3844099\n",
      " 25.7116913  18.59472174 27.41896043 19.80448068 15.2258694  37.55122568\n",
      " 39.67947581 23.82043357 23.1281814  13.0595255  25.37166318 16.42398471\n",
      " 16.71976649 13.84522741 23.83053637 29.85125526 21.0977549  20.40097083\n",
      " -1.00130927 25.09858461 15.31486268 17.16462278 25.06893695 21.63480449\n",
      " 29.9485138  21.55252992 27.31064177 22.13687287  4.67745355 11.59768353\n",
      " 21.54336065 28.14369114 30.32580514 11.58915361 19.6387475  19.22900131\n",
      " 12.97026476 22.0885826   6.4147324  19.87900133  7.98760186 43.00935873\n",
      " 29.58503112 11.61773063 16.91371846 20.81262577 21.79118458 19.28262491\n",
      " 33.67408716]\n",
      "r2 score: 0.5689718149953056\n",
      "MSE:  35.21457834092495\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# raw_df\n",
    "# data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "# raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "# data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "# target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "# feature, target data select\n",
    "# X = data\n",
    "# y = target\n",
    "\n",
    "# training data, test data division\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Data standardization for X\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# SVM Regressor Analyzing\n",
    "clf_svr_lr_ep05 = svm.SVR(kernel = 'linear', epsilon = 0.05)\n",
    "clf_svr_lr_ep05.fit(X_tn_std, y_tn)\n",
    "\n",
    "# # w, b(추정계수, 상수항) 출력 : only 'linear'에서만\n",
    "# print('coef: ', clf_svr_rbf.coef_)\n",
    "# print('intercept: ', clf_svr_rbf.intercept_)\n",
    "\n",
    "# predict y\n",
    "svr_lr_ep05_pred = clf_svr_lr_ep05.predict(X_te_std)\n",
    "print('pred: ',svr_lr_ep05_pred)\n",
    "\n",
    "# r-square score\n",
    "r2 = r2_score(y_te, svr_lr_ep05_pred)\n",
    "print('r2 score:', r2)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_te, svr_lr_ep05_pred)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed6b83",
   "metadata": {},
   "source": [
    "혼내주려고(?) 엡실론을 반으로 줄였더니 r2 스코어가 올라가고, MSE는 줄어들었다. 하지만 어느정도가 적정값인지는 모른다.\n",
    "\n",
    "MSE야 데이터의 스케일에 따라 다른게 사실이지만, r2는 1에 가까울 수록 데이터를 잘 설명할 수 있는 설명력이 높아지는 것인데 너무 낮다.\n",
    "\n",
    "조금더 만져보기로 했다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af595b",
   "metadata": {},
   "source": [
    "# 실험5: epsilon = 0.05 -> 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e92852f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [24.65577318 20.3861132  26.35074374  9.75495446 21.0473144  18.88964356\n",
      " 18.79780852 20.67343931 16.46096821 18.38568461  1.5330592  14.76812066\n",
      " 16.92083893  3.43396592 37.32284328 32.1136178  20.51930348 35.45369243\n",
      " 29.32908472 21.88691089 24.26241396 21.42802001 19.76281105 28.88287388\n",
      " 21.03127078  2.9954527  17.33415004 17.3895905  35.54641547 19.74763985\n",
      " 16.80599321 17.16467534 19.26072505 22.35588413 26.43173196 17.35089073\n",
      " 10.97439149 20.29578788 15.53742384 14.66010234 25.12153868 20.3744972\n",
      " 21.92900245 12.6777096  23.2415272  23.87763487 19.03087105 22.06340817\n",
      " 10.43190977 24.07858647 19.83802481 18.15782216 22.27823746 33.86616832\n",
      " 13.20988642 21.32964695 20.26677346 16.08633065  7.751596   20.17892143\n",
      " 18.55618167 21.35047424 32.06755549 29.57478211 15.84813976 30.4429359\n",
      " 19.01109813 19.95806287 17.81643259 22.401612   21.57036717 23.11948632\n",
      " 28.76742262 29.00585849 23.96681891  4.68791686 36.93183566 23.3844099\n",
      " 25.7116913  18.59472174 27.41896043 19.80448068 15.2258694  37.55122568\n",
      " 39.67947581 23.82043357 23.1281814  13.0595255  25.37166318 16.42398471\n",
      " 16.71976649 13.84522741 23.83053637 29.85125526 21.0977549  20.40097083\n",
      " -1.00130927 25.09858461 15.31486268 17.16462278 25.06893695 21.63480449\n",
      " 29.9485138  21.55252992 27.31064177 22.13687287  4.67745355 11.59768353\n",
      " 21.54336065 28.14369114 30.32580514 11.58915361 19.6387475  19.22900131\n",
      " 12.97026476 22.0885826   6.4147324  19.87900133  7.98760186 43.00935873\n",
      " 29.58503112 11.61773063 16.91371846 20.81262577 21.79118458 19.28262491\n",
      " 33.67408716]\n",
      "r2 score: 0.5701796794193847\n",
      "MSE:  35.11589700669507\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# raw_df\n",
    "# data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "# raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "# data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "# target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "# feature, target data select\n",
    "# X = data\n",
    "# y = target\n",
    "\n",
    "# training data, test data division\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Data standardization for X\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std = std_scale.transform(X_te)\n",
    "\n",
    "# SVM Regressor Analyzing\n",
    "clf_svr_lr_ep02 = svm.SVR(kernel = 'linear', epsilon = 0.02)\n",
    "clf_svr_lr_ep02.fit(X_tn_std, y_tn)\n",
    "\n",
    "# # w, b(추정계수, 상수항) 출력 : only 'linear'에서만\n",
    "# print('coef: ', clf_svr_rbf.coef_)\n",
    "# print('intercept: ', clf_svr_rbf.intercept_)\n",
    "\n",
    "# predict y\n",
    "svr_lr_ep02_pred = clf_svr_lr_ep02.predict(X_te_std)\n",
    "print('pred: ',svr_lr_ep05_pred)\n",
    "\n",
    "# r-square score\n",
    "r2 = r2_score(y_te, svr_lr_ep02_pred)\n",
    "print('r2 score:', r2)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_te, svr_lr_ep02_pred)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5e808",
   "metadata": {},
   "source": [
    "r2 스코어가 약간은 올라간 것으로 보이지만, 여전히 문제가 좀 있어보인다.\n",
    "\n",
    "엡실론이 작아질수록 데이터 자체에 좀 더 fit되는 경향이 있는 것은 사실인 것으로 보인다.\n",
    "\n",
    "이쯤 되면 처음에 마음에 걸렸던 결측값들이 생각난다. 우선 결측값들이 거의 반이 되는데, 설명력이 50% 대에서 머무르는 것과 관련이 있지 않을까 하는 생각이다.\n",
    "\n",
    "문제는 데이터 코드 안에서 결측값들을 제거하고 진행하도록 되어있다는 것이다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59256d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.975px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
